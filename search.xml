<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/2018/7f180a5a20f2/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>

<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>Nginx配置详解</title>
    <url>/2019/a9837c71545f/</url>
    <content><![CDATA[<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">user</span> www www;</span><br><span class="line"></span><br><span class="line"><span class="comment">#nginx进程数，建议设置为等于CPU总核心数。</span></span><br><span class="line"><span class="attribute">worker_processes</span> <span class="number">8</span>;</span><br><span class="line"> </span><br><span class="line"><span class="comment">#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]</span></span><br><span class="line"><span class="attribute">error_log</span> /usr/local/nginx/logs/<span class="literal">error</span>.log <span class="literal">info</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">#进程pid文件</span></span><br><span class="line"><span class="attribute">pid</span> /usr/local/nginx/logs/nginx.pid;</span><br><span class="line"></span><br><span class="line"><span class="comment">#指定进程可以打开的最大描述符：数目</span></span><br><span class="line"><span class="comment">#工作模式与连接数上限</span></span><br><span class="line"><span class="comment">#这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。</span></span><br><span class="line"><span class="comment">#现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。</span></span><br><span class="line"><span class="comment">#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。</span></span><br><span class="line"><span class="attribute">worker_rlimit_nofile</span> <span class="number">65535</span>;</span><br><span class="line"></span><br><span class="line"><span class="section">events</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">#参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型</span></span><br><span class="line">    <span class="comment">#是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。</span></span><br><span class="line">    <span class="comment">#补充说明：</span></span><br><span class="line">    <span class="comment">#与apache相类，nginx针对不同的操作系统，有不同的事件模型</span></span><br><span class="line">    <span class="comment">#A）标准事件模型</span></span><br><span class="line">    <span class="comment">#Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll</span></span><br><span class="line">    <span class="comment">#B）高效事件模型</span></span><br><span class="line">    <span class="comment">#Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。</span></span><br><span class="line">    <span class="comment">#Epoll：使用于Linux内核2.6版本及以后的系统。</span></span><br><span class="line">    <span class="comment">#/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。</span></span><br><span class="line">    <span class="comment">#Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。</span></span><br><span class="line">    <span class="attribute">use</span> <span class="literal">epoll</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#单个进程最大连接数（最大连接数=连接数*进程数）</span></span><br><span class="line">    <span class="comment">#根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cpu跑到100%就行。每个进程允许的最多连接数，理论上每台nginx服务器的最大连接数为。</span></span><br><span class="line">    <span class="attribute">worker_connections</span> <span class="number">65535</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#keepalive超时时间。</span></span><br><span class="line">    <span class="attribute">keepalive_timeout</span> <span class="number">60</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。</span></span><br><span class="line">    <span class="comment">#分页大小可以用命令getconf PAGESIZE 取得。</span></span><br><span class="line">    <span class="comment">#[root@web001 ~]# getconf PAGESIZE</span></span><br><span class="line">    <span class="comment">#4096</span></span><br><span class="line">    <span class="comment">#但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。</span></span><br><span class="line">    <span class="attribute">client_header_buffer_size</span> <span class="number">4k</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。</span></span><br><span class="line">    <span class="attribute">open_file_cache</span> max=<span class="number">65535</span> inactive=<span class="number">60s</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#这个是指多长时间检查一次缓存的有效信息。</span></span><br><span class="line">    <span class="comment">#语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息.</span></span><br><span class="line">    <span class="attribute">open_file_cache_valid</span> <span class="number">80s</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。</span></span><br><span class="line">    <span class="comment">#语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location  这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态.</span></span><br><span class="line">    <span class="attribute">open_file_cache_min_uses</span> <span class="number">1</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件时记录cache错误.</span></span><br><span class="line">    <span class="attribute">open_file_cache_errors</span> <span class="literal">on</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">#设定http服务器，利用它的反向代理功能提供负载均衡支持</span></span><br><span class="line"><span class="section">http</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">#文件扩展名与文件类型映射表</span></span><br><span class="line">    <span class="attribute">include</span> mime.types;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#默认文件类型</span></span><br><span class="line">    <span class="attribute">default_type</span> application/octet-stream;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#默认编码</span></span><br><span class="line">    <span class="comment">#charset utf-8;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#服务器名字的hash表大小</span></span><br><span class="line">    <span class="comment">#保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小.</span></span><br><span class="line">    <span class="attribute">server_names_hash_bucket_size</span> <span class="number">128</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。</span></span><br><span class="line">    <span class="attribute">client_header_buffer_size</span> <span class="number">32k</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。</span></span><br><span class="line">    <span class="attribute">large_client_header_buffers</span> <span class="number">4</span> <span class="number">64k</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#设定通过nginx上传文件的大小</span></span><br><span class="line">    <span class="attribute">client_max_body_size</span> <span class="number">8m</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。</span></span><br><span class="line">    <span class="comment">#sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。</span></span><br><span class="line">    <span class="attribute">sendfile</span> <span class="literal">on</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#开启目录列表访问，合适下载服务器，默认关闭。</span></span><br><span class="line">    <span class="attribute">autoindex</span> <span class="literal">on</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用</span></span><br><span class="line">    <span class="attribute">tcp_nopush</span> <span class="literal">on</span>;</span><br><span class="line">     </span><br><span class="line">    <span class="attribute">tcp_nodelay</span> <span class="literal">on</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#长连接超时时间，单位是秒</span></span><br><span class="line">    <span class="attribute">keepalive_timeout</span> <span class="number">120</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。</span></span><br><span class="line">    <span class="attribute">fastcgi_connect_timeout</span> <span class="number">300</span>;</span><br><span class="line">    <span class="attribute">fastcgi_send_timeout</span> <span class="number">300</span>;</span><br><span class="line">    <span class="attribute">fastcgi_read_timeout</span> <span class="number">300</span>;</span><br><span class="line">    <span class="attribute">fastcgi_buffer_size</span> <span class="number">64k</span>;</span><br><span class="line">    <span class="attribute">fastcgi_buffers</span> <span class="number">4</span> <span class="number">64k</span>;</span><br><span class="line">    <span class="attribute">fastcgi_busy_buffers_size</span> <span class="number">128k</span>;</span><br><span class="line">    <span class="attribute">fastcgi_temp_file_write_size</span> <span class="number">128k</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#gzip模块设置</span></span><br><span class="line">    <span class="attribute">gzip</span> <span class="literal">on</span>; <span class="comment">#开启gzip压缩输出</span></span><br><span class="line">    <span class="attribute">gzip_min_length</span> <span class="number">1k</span>;    <span class="comment">#最小压缩文件大小</span></span><br><span class="line">    <span class="attribute">gzip_buffers</span> <span class="number">4</span> <span class="number">16k</span>;    <span class="comment">#压缩缓冲区</span></span><br><span class="line">    <span class="attribute">gzip_http_version</span> <span class="number">1</span>.<span class="number">0</span>;    <span class="comment">#压缩版本（默认1.1，前端如果是squid2.5请使用1.0）</span></span><br><span class="line">    <span class="attribute">gzip_comp_level</span> <span class="number">2</span>;    <span class="comment">#压缩等级</span></span><br><span class="line">    <span class="attribute">gzip_types</span> text/plain application/x-javascript text/css application/xml;    <span class="comment">#压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。</span></span><br><span class="line">    <span class="attribute">gzip_vary</span> <span class="literal">on</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#开启限制IP连接数的时候需要使用</span></span><br><span class="line">    <span class="comment">#limit_zone crawler $binary_remote_addr 10m;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#负载均衡配置</span></span><br><span class="line">    <span class="section">upstream</span> jh.w3cschool.cn &#123;</span><br><span class="line">     </span><br><span class="line">        <span class="comment">#upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。</span></span><br><span class="line">        <span class="attribute">server</span> <span class="number">192.168.80.121:80</span> weight=<span class="number">3</span>;</span><br><span class="line">        <span class="attribute">server</span> <span class="number">192.168.80.122:80</span> weight=<span class="number">2</span>;</span><br><span class="line">        <span class="attribute">server</span> <span class="number">192.168.80.123:80</span> weight=<span class="number">3</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#nginx的upstream目前支持4种方式的分配</span></span><br><span class="line">        <span class="comment">#1、轮询（默认）</span></span><br><span class="line">        <span class="comment">#每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。</span></span><br><span class="line">        <span class="comment">#2、weight</span></span><br><span class="line">        <span class="comment">#指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。</span></span><br><span class="line">        <span class="comment">#例如：</span></span><br><span class="line">        <span class="comment">#upstream bakend &#123;</span></span><br><span class="line">        <span class="comment">#    server 192.168.0.14 weight=10;</span></span><br><span class="line">        <span class="comment">#    server 192.168.0.15 weight=10;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line">        <span class="comment">#2、ip_hash</span></span><br><span class="line">        <span class="comment">#每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。</span></span><br><span class="line">        <span class="comment">#例如：</span></span><br><span class="line">        <span class="comment">#upstream bakend &#123;</span></span><br><span class="line">        <span class="comment">#    ip_hash;</span></span><br><span class="line">        <span class="comment">#    server 192.168.0.14:88;</span></span><br><span class="line">        <span class="comment">#    server 192.168.0.15:80;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line">        <span class="comment">#3、fair（第三方）</span></span><br><span class="line">        <span class="comment">#按后端服务器的响应时间来分配请求，响应时间短的优先分配。</span></span><br><span class="line">        <span class="comment">#upstream backend &#123;</span></span><br><span class="line">        <span class="comment">#    server server1;</span></span><br><span class="line">        <span class="comment">#    server server2;</span></span><br><span class="line">        <span class="comment">#    fair;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line">        <span class="comment">#4、url_hash（第三方）</span></span><br><span class="line">        <span class="comment">#按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。</span></span><br><span class="line">        <span class="comment">#例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法</span></span><br><span class="line">        <span class="comment">#upstream backend &#123;</span></span><br><span class="line">        <span class="comment">#    server squid1:3128;</span></span><br><span class="line">        <span class="comment">#    server squid2:3128;</span></span><br><span class="line">        <span class="comment">#    hash $request_uri;</span></span><br><span class="line">        <span class="comment">#    hash_method crc32;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#tips:</span></span><br><span class="line">        <span class="comment">#upstream bakend&#123;#定义负载均衡设备的Ip及设备状态&#125;&#123;</span></span><br><span class="line">        <span class="comment">#    ip_hash;</span></span><br><span class="line">        <span class="comment">#    server 127.0.0.1:9090 down;</span></span><br><span class="line">        <span class="comment">#    server 127.0.0.1:8080 weight=2;</span></span><br><span class="line">        <span class="comment">#    server 127.0.0.1:6060;</span></span><br><span class="line">        <span class="comment">#    server 127.0.0.1:7070 backup;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line">        <span class="comment">#在需要使用负载均衡的server中增加 proxy_pass http://bakend/;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#每个设备的状态设置为:</span></span><br><span class="line">        <span class="comment">#1.down表示单前的server暂时不参与负载</span></span><br><span class="line">        <span class="comment">#2.weight为weight越大，负载的权重就越大。</span></span><br><span class="line">        <span class="comment">#3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误</span></span><br><span class="line">        <span class="comment">#4.fail_timeout:max_fails次失败后，暂停的时间。</span></span><br><span class="line">        <span class="comment">#5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#nginx支持同时设置多组的负载均衡，用来给不用的server来使用。</span></span><br><span class="line">        <span class="comment">#client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug</span></span><br><span class="line">        <span class="comment">#client_body_temp_path设置记录文件的目录 可以设置最多3层目录</span></span><br><span class="line">        <span class="comment">#location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡</span></span><br><span class="line">    &#125;</span><br><span class="line">     </span><br><span class="line">    <span class="comment">#虚拟主机的配置</span></span><br><span class="line">    <span class="section">server</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">#监听端口</span></span><br><span class="line">        <span class="attribute">listen</span> <span class="number">80</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#域名可以有多个，用空格隔开</span></span><br><span class="line">        <span class="attribute">server_name</span> www.w3cschool.cn w3cschool.cn;</span><br><span class="line">        <span class="attribute">index</span> index.html index.htm index.php;</span><br><span class="line">        <span class="attribute">root</span> /data/www/w3cschool;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#对******进行负载均衡</span></span><br><span class="line">        <span class="section">location</span> <span class="regexp">~ .*.(php|php5)?$</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attribute">fastcgi_pass</span> <span class="number">127.0.0.1:9000</span>;</span><br><span class="line">            <span class="attribute">fastcgi_index</span> index.php;</span><br><span class="line">            <span class="attribute">include</span> fastcgi.conf;</span><br><span class="line">        &#125;</span><br><span class="line">         </span><br><span class="line">        <span class="comment">#图片缓存时间设置</span></span><br><span class="line">        <span class="section">location</span> <span class="regexp">~ .*.(gif|jpg|jpeg|png|bmp|swf)$</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attribute">expires</span> <span class="number">10d</span>;</span><br><span class="line">        &#125;</span><br><span class="line">         </span><br><span class="line">        <span class="comment">#JS和CSS缓存时间设置</span></span><br><span class="line">        <span class="section">location</span> <span class="regexp">~ .*.(js|css)?$</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attribute">expires</span> <span class="number">1h</span>;</span><br><span class="line">        &#125;</span><br><span class="line">         </span><br><span class="line">        <span class="comment">#日志格式设定</span></span><br><span class="line">        <span class="comment">#$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址；</span></span><br><span class="line">        <span class="comment">#$remote_user：用来记录客户端用户名称；</span></span><br><span class="line">        <span class="comment">#$time_local： 用来记录访问时间与时区；</span></span><br><span class="line">        <span class="comment">#$request： 用来记录请求的url与http协议；</span></span><br><span class="line">        <span class="comment">#$status： 用来记录请求状态；成功是200，</span></span><br><span class="line">        <span class="comment">#$body_bytes_sent ：记录发送给客户端文件主体内容大小；</span></span><br><span class="line">        <span class="comment">#$http_referer：用来记录从那个页面链接访问过来的；</span></span><br><span class="line">        <span class="comment">#$http_user_agent：记录客户浏览器的相关信息；</span></span><br><span class="line">        <span class="comment">#通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。</span></span><br><span class="line">        <span class="attribute">log_format</span> access <span class="string">&#x27;<span class="variable">$remote_addr</span> - <span class="variable">$remote_user</span> [<span class="variable">$time_local</span>] &quot;<span class="variable">$request</span>&quot; &#x27;</span></span><br><span class="line">        <span class="string">&#x27;<span class="variable">$status</span> <span class="variable">$body_bytes_sent</span> &quot;<span class="variable">$http_referer</span>&quot; &#x27;</span></span><br><span class="line">        <span class="string">&#x27;&quot;<span class="variable">$http_user_agent</span>&quot; <span class="variable">$http_x_forwarded_for</span>&#x27;</span>;</span><br><span class="line">         </span><br><span class="line">        <span class="comment">#定义本虚拟主机的访问日志</span></span><br><span class="line">        <span class="attribute">access_log</span>  /usr/local/nginx/logs/host.access.log  main;</span><br><span class="line">        <span class="attribute">access_log</span>  /usr/local/nginx/logs/host.access.<span class="number">404</span>.log  log404;</span><br><span class="line">         </span><br><span class="line">        <span class="comment">#对 &quot;/&quot; 启用反向代理</span></span><br><span class="line">        <span class="section">location</span> / &#123;</span><br><span class="line">            <span class="attribute">proxy_pass</span> http://127.0.0.1:88;</span><br><span class="line">            <span class="attribute">proxy_redirect</span> <span class="literal">off</span>;</span><br><span class="line">            <span class="attribute">proxy_set_header</span> X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">             </span><br><span class="line">            <span class="comment">#后端的Web服务器可以通过X-Forwarded-For获取用户真实IP</span></span><br><span class="line">            <span class="attribute">proxy_set_header</span> X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">             </span><br><span class="line">            <span class="comment">#以下是一些反向代理的配置，可选。</span></span><br><span class="line">            <span class="attribute">proxy_set_header</span> Host <span class="variable">$host</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#允许客户端请求的最大单文件字节数</span></span><br><span class="line">            <span class="attribute">client_max_body_size</span> <span class="number">10m</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#缓冲区代理缓冲用户端请求的最大字节数，</span></span><br><span class="line">            <span class="comment">#如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。</span></span><br><span class="line">            <span class="comment">#无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误</span></span><br><span class="line">            <span class="attribute">client_body_buffer_size</span> <span class="number">128k</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#表示使nginx阻止HTTP应答代码为400或者更高的应答。</span></span><br><span class="line">            <span class="attribute">proxy_intercept_errors</span> <span class="literal">on</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#后端服务器连接的超时时间_发起握手等候响应超时时间</span></span><br><span class="line">            <span class="comment">#nginx跟后端服务器连接超时时间(代理连接超时)</span></span><br><span class="line">            <span class="attribute">proxy_connect_timeout</span> <span class="number">90</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#后端服务器数据回传时间(代理发送超时)</span></span><br><span class="line">            <span class="comment">#后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据</span></span><br><span class="line">            <span class="attribute">proxy_send_timeout</span> <span class="number">90</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#连接成功后，后端服务器响应时间(代理接收超时)</span></span><br><span class="line">            <span class="comment">#连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）</span></span><br><span class="line">            <span class="attribute">proxy_read_timeout</span> <span class="number">90</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#设置代理服务器（nginx）保存用户头信息的缓冲区大小</span></span><br><span class="line">            <span class="comment">#设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小</span></span><br><span class="line">            <span class="attribute">proxy_buffer_size</span> <span class="number">4k</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#proxy_buffers缓冲区，网页平均在32k以下的设置</span></span><br><span class="line">            <span class="comment">#设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k</span></span><br><span class="line">            <span class="attribute">proxy_buffers</span> <span class="number">4</span> <span class="number">32k</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#高负荷下缓冲大小（proxy_buffers*2）</span></span><br><span class="line">            <span class="attribute">proxy_busy_buffers_size</span> <span class="number">64k</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长</span></span><br><span class="line">            <span class="comment">#设定缓存文件夹大小，大于这个值，将从upstream服务器传</span></span><br><span class="line">            <span class="attribute">proxy_temp_file_write_size</span> <span class="number">64k</span>;</span><br><span class="line">        &#125;         </span><br><span class="line">         </span><br><span class="line">        <span class="comment">#设定查看Nginx状态的地址</span></span><br><span class="line">        <span class="section">location</span> /NginxStatus &#123;</span><br><span class="line">            <span class="attribute">stub_status</span> <span class="literal">on</span>;</span><br><span class="line">            <span class="attribute">access_log</span> <span class="literal">on</span>;</span><br><span class="line">            <span class="attribute">auth_basic</span> <span class="string">&quot;NginxStatus&quot;</span>;</span><br><span class="line">            <span class="attribute">auth_basic_user_file</span> confpasswd;</span><br><span class="line">            <span class="comment">#htpasswd文件的内容可以用apache提供的htpasswd工具来产生。</span></span><br><span class="line">        &#125;</span><br><span class="line">         </span><br><span class="line">        <span class="comment">#本地动静分离反向代理配置</span></span><br><span class="line">        <span class="comment">#所有jsp的页面均交由tomcat或resin处理</span></span><br><span class="line">        <span class="section">location</span> <span class="regexp">~ .(jsp|jspx|do)?$</span> &#123;</span><br><span class="line">            <span class="attribute">proxy_set_header</span> Host <span class="variable">$host</span>;</span><br><span class="line">            <span class="attribute">proxy_set_header</span> X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">            <span class="attribute">proxy_set_header</span> X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">            <span class="attribute">proxy_pass</span> http://127.0.0.1:8080;</span><br><span class="line">        &#125;</span><br><span class="line">         </span><br><span class="line">        <span class="comment">#所有静态文件由nginx直接读取不经过tomcat或resin</span></span><br><span class="line">        <span class="section">location</span> <span class="regexp">~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|</span></span><br><span class="line">        pdf|xls|mp3|wma)$</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attribute">expires</span> <span class="number">15d</span>; </span><br><span class="line">        &#125;</span><br><span class="line">         </span><br><span class="line">        <span class="section">location</span> <span class="regexp">~ .*.(js|css)?$</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attribute">expires</span> <span class="number">1h</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>   原文： <a href="https://opstrip.com/2017/01/10/nginx-configuration-template/">https://opstrip.com/2017/01/10/nginx-configuration-template/</a></p>
</blockquote>
]]></content>
      <categories>
        <category>工具</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive压缩格式与存储格式</title>
    <url>/2020/45ed75ed362a/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>hive表常用的存储格式主要包括：orc、parquet、avro、rcfile、sqeuencefile几种，存储格式一般会选择综合性能最好的orc或者parquet，这两种都是列式存储格式。压缩格式一般会选择snappy、lzo、gizp，针对不同的应用场景使用不同的压缩方式。</p>
<span id="more"></span>

<p>  原文件：1403M</p>
<table>
<thead>
<tr>
<th>压缩格式</th>
<th>压缩大小</th>
<th>压缩时间</th>
<th>解压时间</th>
<th>是否可切分</th>
</tr>
</thead>
<tbody><tr>
<td>Snappy</td>
<td>/</td>
<td>6.4s</td>
<td>19.8s</td>
<td>不可切分</td>
</tr>
<tr>
<td>LZ4</td>
<td>693M</td>
<td>6.4s</td>
<td>2.36s</td>
<td>不可切分</td>
</tr>
<tr>
<td>LZO</td>
<td>684M</td>
<td>7.6s</td>
<td>11.1s</td>
<td>带序号可切分</td>
</tr>
<tr>
<td>GZIP</td>
<td>447M</td>
<td>85.6s</td>
<td>21.8s</td>
<td>不可切分</td>
</tr>
<tr>
<td>BZIP2</td>
<td>390M</td>
<td>142.3s</td>
<td>62.5s</td>
<td>可切分</td>
</tr>
</tbody></table>
<p>压缩比和压缩时间成反比，压缩比越小，耗费时间越大</p>
<blockquote>
<p>   总结： <strong>hive一般用orc，spark一般用parquet，snappy配合parquet性能最高。</strong></p>
</blockquote>
<h2 id="压缩方式选择（hive-table）："><a href="#压缩方式选择（hive-table）：" class="headerlink" title="压缩方式选择（hive table）："></a>压缩方式选择（hive table）：</h2><p>数据量大，计算性能要求不高的业务数据，一般用gzip（压缩比最高，压缩解压缩速度最慢）</p>
<p>计算性能要求较高，数据量不是特别大的业务数据，一般用lzo或者snappy （压缩比没有gzip高，但是压缩解压速度较快）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// snappy:</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;</span><br><span class="line">stored as orc tblproperties(&quot;orc.compress&quot;=&quot;SNAPPY&quot;);</span><br><span class="line"></span><br><span class="line">// lzo:</span><br><span class="line">stored as INPUTFORMAT&#x27;com.hadoop.mapred.DeprecatedLzoTextInputFormat&#x27;</span><br><span class="line">          OUTPUTFORMAT&#x27;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat&#x27;</span><br><span class="line">location &#x27;/user/pmp_bi/test/testlog/&#x27;</span><br></pre></td></tr></table></figure>

<p>MR阶段过程：</p>
<blockquote>
<p>input  -&gt; map   -&gt; shuffle  -&gt;  reduce  -&gt;  output</p>
</blockquote>
<p>shuffle 阶段几个重要内容：</p>
<blockquote>
<p>  分区   -&gt;  排序  -&gt; 分组   -&gt; combiner(map端的reduce)  -&gt; 压缩    -&gt;  map阶段输出</p>
</blockquote>
<p>compression压缩：</p>
<blockquote>
<p> map 输出  和   reduce 输出</p>
</blockquote>
<h4 id="1-中间数据压缩"><a href="#1-中间数据压缩" class="headerlink" title="1.中间数据压缩"></a>1.中间数据压缩</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.compress.intermediate<span class="operator">=</span><span class="literal">true</span>;    <span class="comment">-- 激活中间数据压缩功能，默认false</span></span><br><span class="line"><span class="comment">-- 设置Map 阶段输出压缩格式</span></span><br><span class="line"><span class="keyword">set</span> mapred.map.output.compression.codec<span class="operator">=</span>org.apache.hadoop.io.compress.SnappyCodec;</span><br><span class="line"><span class="keyword">set</span> mapred.map.output.compression.codec<span class="operator">=</span>com.hadoop.compression.lzo.LzoCodec;</span><br></pre></td></tr></table></figure>

<h4 id="1-最终数据压缩"><a href="#1-最终数据压缩" class="headerlink" title="1.最终数据压缩"></a>1.最终数据压缩</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.compress.output<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="comment">-- 设置Reduce 输出压缩格式</span></span><br><span class="line"><span class="keyword">set</span> mapred.output.compression.codec<span class="operator">=</span>org.apache.hadoop.io.compress.SnappyCodec;</span><br><span class="line"><span class="comment">-- 设置mapreduce最终数据输出压缩为块压缩</span></span><br><span class="line"><span class="keyword">set</span> mapreduce.output.fileoutputformat.compress.type<span class="operator">=</span>BLOCK;</span><br></pre></td></tr></table></figure>



<h2 id="存储方式选择（hive-table）："><a href="#存储方式选择（hive-table）：" class="headerlink" title="存储方式选择（hive table）："></a>存储方式选择（hive table）：</h2><p>Hive数据表的默认格式 <code>textfile</code> ，存储方式：行存储。</p>
<p>选择综合性能最优的两种存储格式：orc和parquet 。 </p>
<p>磁盘空间占用： <strong>orc&lt;parquet&lt;textfile</strong></p>
<p>查询速度和压缩比： <strong>orc&gt;parquet&gt;textfile</strong></p>
<blockquote>
<p><strong>hive一般用orc，spark一般用parquet，snappy配合parquet性能最高。</strong></p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- hive建表</span></span><br><span class="line">STORED <span class="keyword">AS</span> TEXTFILE;</span><br><span class="line">STORED <span class="keyword">AS</span> PARQUET;</span><br><span class="line">STORED <span class="keyword">AS</span> ORC ;</span><br><span class="line"><span class="comment">-- 不压缩</span></span><br><span class="line">STORED <span class="keyword">AS</span> orc tblproperties (&quot;orc.compress&quot;<span class="operator">=</span>&quot;NONE&quot;);</span><br><span class="line"><span class="comment">-- Snappy压缩</span></span><br><span class="line">STORED <span class="keyword">AS</span> orc tblproperties (&quot;orc.compress&quot;<span class="operator">=</span>&quot;Snappy&quot;);</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>Bigdata</category>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop调优</title>
    <url>/2020/e306b19f9a44/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Hadoop 集群的调优可以从四方面着手：</p>
<ol>
<li> Linux 调优</li>
<li> HDFS 调优</li>
<li> MapReduce 调优</li>
<li> YRAN 调优</li>
</ol>
<span id="more"></span>

<h2 id="一、Linux调优"><a href="#一、Linux调优" class="headerlink" title="一、Linux调优"></a>一、Linux调优</h2><h3 id="修改内核参数"><a href="#修改内核参数" class="headerlink" title="修改内核参数"></a>修改内核参数</h3><p>管理员通常会保持 Linux 服务器内核的默认设置，这并不是一个明智的做法，因为这有可能对集群的性能产生不利的影响!</p>
<p>下表给出了在 Hadoop 生产集群中推荐使用的 Linux 内核参数配置。</p>
<table>
<thead>
<tr>
<th>Linux 内核参数配置</th>
<th>参数说明</th>
</tr>
</thead>
<tbody><tr>
<td>fs.file-mx=6815744</td>
<td>文件描述符总数</td>
</tr>
<tr>
<td>fs.aio-max-nr=1048576</td>
<td>最大并发I/O请求数</td>
</tr>
<tr>
<td>net.core.rmem_default=262144</td>
<td>操作系统接收缓冲区的默认大小</td>
</tr>
<tr>
<td>net.core.wmem_default=262144</td>
<td>操作系统发送缓冲区的默认大小</td>
</tr>
<tr>
<td>net.core.rmem_max=16777216</td>
<td>系统接收缓冲区最大值</td>
</tr>
<tr>
<td>net.core.wmem_max=16777216</td>
<td>系统发送缓冲区最大值</td>
</tr>
<tr>
<td>net.ipv4.tcp_rmem=409626214416777216</td>
<td>接收窗口尺寸的最小、默认、最大值</td>
</tr>
<tr>
<td>net.ipv4.tcp_wmem=409626214416777216</td>
<td>发送窗口尺寸的最小、默认、最大值</td>
</tr>
</tbody></table>
<h3 id="增加文件限制"><a href="#增加文件限制" class="headerlink" title="增加文件限制"></a>增加文件限制</h3><p>为了避免集群中的任何<strong>文件描述符错误</strong>，需要增加单个用户或进程一次可以打开的文件数量的限制。</p>
<p>默认值只有 128 。</p>
<p>可以使用以下命令检査当前限制(第一个为软限制第二个为硬限制)。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop ~]# ulimit -Sn</span><br><span class="line">1024</span><br><span class="line">[root@hadoop ~]# ulimit -Hn</span><br><span class="line">4096</span><br><span class="line">[root@hadoop ~]#</span><br></pre></td></tr></table></figure>

<p>需要将 ulimit 值至少提高至4096( Hortonworks等推荐10000或者更多)。</p>
<p>可以通过编辑 /etc/security/limits.conf 文件来执行此操作，如下所示:</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">Soft nofile 4096 </span><br><span class="line">Hard nofile 4096 </span><br></pre></td></tr></table></figure>

<p>且更改了内核设置，则可以通过执行以下命令来动态加载新设置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop ~]# sysctl -p</span><br></pre></td></tr></table></figure>

<p>可以通过发出以下命令来确认新的内核设置:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop ~]# sysctl -a</span><br></pre></td></tr></table></figure>

<h3 id="磁盘设置"><a href="#磁盘设置" class="headerlink" title="磁盘设置"></a>磁盘设置</h3><p>确保在挂载所有磁盘时使用 <code>noatime</code> 时间以及挂载所有目录时使用 <code>nodir</code> 时间。</p>
<p>这样， 可以避免在对 Linux 文件系统中的文件或目录进行读取操作时的<strong>不必要写入操作</strong>，从而提高集群性能。</p>
<h3 id="测试磁盘I-O速度"><a href="#测试磁盘I-O速度" class="headerlink" title="测试磁盘I/O速度"></a>测试磁盘I/O速度</h3><p>使用 <code>hdparm -t</code> 命令测试磁盘速度，如下所示</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hdparm -t /dev/sdal</span></span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure>

<p>如果没有看到 <strong>70MB/S</strong> 以上的速度，这意味着有一个潜在的问题存在</p>
<h3 id="检查服务器的-BIOS-设置"><a href="#检查服务器的-BIOS-设置" class="headerlink" title="检查服务器的 BIOS 设置"></a>检查服务器的 BIOS 设置</h3><p>通过确保不启用磁盘驱动器的 IDE 仿真等功能来保证服务器 BIOS 为最佳性能配置。</p>
<p>存储和系统管理员会关注这个配置。</p>
<blockquote>
<p>  注意：在挂磁盘驱动器之前，将所有 Hadoop 目录下的文件权限更改为 700 这样在却驱动器时，向这些驱动器写入的任何进程都不会占满操作系统。</p>
</blockquote>
<h3 id="网卡绑定"><a href="#网卡绑定" class="headerlink" title="网卡绑定"></a>网卡绑定</h3><p>为了提高吞吐量和弹性，最好通过执行NC绑定来组合网络接口。</p>
<h3 id="启用-NTP"><a href="#启用-NTP" class="headerlink" title="启用 NTP"></a>启用 NTP</h3><p>确保集群所有节点的时钟是同步的。</p>
<p>如果集群无法访问 Intenet ，则必须将集群中的一个服务器设置为 NTP 服务器。</p>
<p>通过编辑 <code>/etc/sysconfig/ntpd</code> 文件启用 NTP 守护进程来同步所有集群节点上的网络时间同步所有集群节点上的网络时间对于诸如 ZooKeeper 、 Kerberos 和 HBase 之类的应用程序至关重要。</p>
<p>当通过日志文件对集群进行故障排除时，在集群中使用同步时间也很重要。</p>
<blockquote>
<p>  注意尽管不是必须的，但最好使用单独的虚拟局域网( VLAN )为 Hadoop 提供专用交换基础设施。</p>
</blockquote>
<blockquote>
<p>  在 CentOS8 中默认不再支持 ntp 软件包，时间同步将由 <strong>chrony</strong> 来实现，可以通过修改 /etc/chrony.conf 实现。</p>
</blockquote>
<h3 id="检查-DNS"><a href="#检查-DNS" class="headerlink" title="检查 DNS"></a>检查 DNS</h3><p>使用主机名而不是 IP 地址来标识集群节点。</p>
<p>在理想情况下，集群中的所有节点都必须被配置 DNS 和反向 DNS 。</p>
<p>确保将所有主机名设置为完全限定域名( FQDN )。</p>
<p>以下是一个例子</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hostname -- fqdn</span></span><br><span class="line">hadoop1.localdomain</span><br></pre></td></tr></table></figure>

<p>如果由于某些原因无法配置 DNS ，确保编辑所有节点的 /etc/hosts 文件，将集群中的所有节点列入其中。</p>
<p>每个主机必须能够执行正向查找(利用主机名)和反向査找(利用 IP 地址)。</p>
<p>主机命令可帮助验证正向和反向查找，如下所示</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">host hadoop1</span></span><br><span class="line">hadoop1.localdomain has address 10.192.2.29</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">host 10.192.2.29</span></span><br><span class="line">10.192.2.29 in-addr.arpa domain name pointer hadoop1.localdomain</span><br></pre></td></tr></table></figure>

<p>由于 Hadoop 大量使用基于网络的服务(如 DNS )，因此启用名称服务器缓存守护程序( nscd )以降低名称解析延迟是个好主意</p>
<h3 id="禁用-swap"><a href="#禁用-swap" class="headerlink" title="禁用 swap"></a>禁用 swap</h3><p>理想情况下，服务器都不应该 swap ，尤其是 DataNode 。</p>
<p>可以使用以下命令在这些服务器上完全禁用该功能。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">swapoff - a</span><br></pre></td></tr></table></figure>

<p>可以使用以下命令检查服务器上的 swap 状态</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">swapon - s</span><br></pre></td></tr></table></figure>

<p>默认情况下，大多数 Linux 操作系统的 <code>swappiness</code> 被设置为 60 。</p>
<p>如果 swappiness 设置为零，除非内存不足， Linux 将避免使用磁盘，而设置为 100 表示操作系统立即将程序切换到磁盘。</p>
<p>我们知道，设置为 60 意味着从内存使用量达到操作系统分配的内存的半左右的时间开始，操作系统会相当频繁地使用磁盘上的交换文件。</p>
<p>例如，如果将 swappiness 调低到 10 ，则只有当 RAM 占用率达到 90 %左右时，操作系统才会使用磁盘上的交换文件。</p>
<p>Linux 管理员可以将以下设置添加到 /etc/sysctl.conf 文件中来更改系统的 swappiness</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">vm.swappiness</span>=<span class="string">10</span></span><br></pre></td></tr></table></figure>

<p>管理员必须重新启动服务器才能使新的 swappiness 设置生效。</p>
<p>对于将 swappiness 值设置为多低，没有特别明确的强制规定。</p>
<p><code>Cloudera 专家建议将其设置为 1</code>。</p>
<h3 id="禁用-SELinux"><a href="#禁用-SELinux" class="headerlink" title="禁用 SELinux"></a>禁用 SELinux</h3><p>虽然这并不是一个绝对的要求，但 SELinux 有时会干扰 Hadoop 的安装，所以在开始安装 Hadoop 之前最好禁用 SELinux 。</p>
<p>此外， SELinux 会对集群造成 7 %~ 10 %的性能损失。</p>
<p>可以执行以下命令获取当前的 SELinux 状态</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">getenforce</span><br></pre></td></tr></table></figure>

<p>如果当前模式的值为 enforcing ，则 SELinux 处于启用状态。</p>
<p>可以将状态更改为 <code>permissive</code> 来禁用它，如下所示:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">setenforce 0</span><br></pre></td></tr></table></figure>

<h3 id="关闭-IPv6"><a href="#关闭-IPv6" class="headerlink" title="关闭 IPv6"></a>关闭 IPv6</h3><p>需要为某些网络相关的 Hadoop 配置参数设置值 0.0.0.0 ，将 Hadoop 绑定到服务器的 IPv6 地址。</p>
<p>如果没有连接到 IPv6 网络，则可以简单地禁用集群节点上的 IPv6 。</p>
<p>可以通过编辑 <code>/etc/sysctl.conf</code> 文件并在文件末尾添加以下行来禁用 IPv6 :</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">net.ipv6.conf.all.disable_ipv6</span> = <span class="string">1</span></span><br><span class="line"><span class="attr">net.ipv6.conf.default.disable_ipv6</span> = <span class="string">1</span></span><br><span class="line"><span class="attr">net.ipv6.conf.io.disable_ipv6</span> = <span class="string">1</span></span><br></pre></td></tr></table></figure>

<p><strong>对 sysctl.conf 文件进行更改后，必须重新启动服务器。</strong></p>
<p>重新启动后，执行以下命令来检查更改是否成功:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /proc/sys/net/ipv6/conf/all/disable_ipv6</span> </span><br></pre></td></tr></table></figure>

<p>如果禁用 IPv6 ，输出应该为 1 ，否则为 0 。</p>
<p>也可以通过为环境变量 HADOOP_OPTS 添加以下值来禁用 Hadoop 的 IPv6 。</p>
<p>将此行添加到集群的 hadoop-env.sh 文件中:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true </span><br></pre></td></tr></table></figure>

<h3 id="禁用-IP-表"><a href="#禁用-IP-表" class="headerlink" title="禁用 IP 表"></a>禁用 IP 表</h3><p>在安装 Hadoop 时，最好关掉网络防火墙(并进行检査)，如下所示</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">service iptables stop</span><br><span class="line">service iptables status</span><br></pre></td></tr></table></figure>

<p>安装完成后，可以重新启用 IP 表。</p>
<h3 id="设置-Limits"><a href="#设置-Limits" class="headerlink" title="设置 Limits"></a>设置 Limits</h3><p>可以通过 shell 来限制用户能利用的集群资源。</p>
<p>为此，可以编辑 <code>/etc/security/limits.conf</code> 文件，该文件规定了如何限制用户使用资源。</p>
<p>limits.conf 文件用于配置重要的操作系统属性的“软”和“硬”限制，如文件大小、堆栈大小和进程的优先级(精度)等，如下所示。</p>
<p>将以下行添加到 <code>/etc/security/limits.conf</code> 文件中:</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">soft nofile 32768</span><br><span class="line">hard nofile 32768</span><br><span class="line">soft nproc 32768</span><br><span class="line">soft nproc 32768</span><br></pre></td></tr></table></figure>

<p>nofile 属性限制每个用户进程打开的文件描述符的数量， nproc指定最大进程数。</p>
<p>软限制设置意味着<strong>警告</strong>，硬限制设置是<strong>实际的资源限制</strong>。</p>
<h3 id="关闭透明大页-THP-压缩"><a href="#关闭透明大页-THP-压缩" class="headerlink" title="关闭透明大页(THP)压缩"></a>关闭透明大页(THP)压缩</h3><p>据 Cloudera 和 Hortonworks 的专家介绍，THP压缩会降低 Hadoop的性能。</p>
<p>所以，禁用碎片整理是一个很好的做法，具体方法如下所示(将此行添加到 /etc/rc.local 文件):</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&#x27;never&#x27;</span>; defrag_file_pathname</span></span><br></pre></td></tr></table></figure>

<h3 id="检查连通性"><a href="#检查连通性" class="headerlink" title="检查连通性"></a>检查连通性</h3><p>检查节点之间的无密码连接，以确保对SSH进行了正确的配置。</p>
<h2 id="HDFS调优参数"><a href="#HDFS调优参数" class="headerlink" title="HDFS调优参数"></a>HDFS调优参数</h2><h3 id="1-hdfs-site-xml"><a href="#1-hdfs-site-xml" class="headerlink" title="1. hdfs-site.xml"></a>1. hdfs-site.xml</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">propertv</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.block.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>解释: 该参数表示 <strong>Hadoop 的文件块大小</strong>，通常设为128MB或者256MB。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.handler.count<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>40<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br></pre></td></tr></table></figure>

<p>解释: 该参数表示 <strong>NameNode 同时和 DataNode 通信的线程数</strong>，默认为10，将其增大为40。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.max.xcievers<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>65536<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br></pre></td></tr></table></figure>

<p>解释: dfs.datanode.max.xcievers 对于 DataNode 来说就 <strong>如同 Linux 上的文件句柄的限制</strong>，当 DataNode上面的连接数超过配置中的设置时， DataNode就会拒绝连接，修改设置为65536。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.balance.bandwidthPerSe<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>20485760<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>解释: 该参数表示执行 <strong>start-balancer.sh 的带宽</strong>，默认为1048576(1MB/s)，将其増大到20MB/s</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>解释: 该项参数表示控制HDFS文件的副本数，默认为3，当许多任务同时读取一个文件时，读取可能会造成瓶颈，这时增大副本数可以有效缓解这种情况，但是也会造成大量的磁盘空间占用，这时可以只修改 <strong>Hadoop 客户端</strong> 的配置，这样，从 Hadoop 客户端上传的文件的副本数将以 Hadoop 客户端的为准</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.max.transfer.threads<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>解释: 该参数表示设置 DataNode 在<strong>进行文件传输时最大线程数</strong>，通常设置为8192，如果集群中有某台 DataNode 主机的这个值比其他主机的大，那么出现的问题是，这台主机上存储的数据相对别的主机比较多，导致数据分布不均匀的问题，即使 balance 仍然会不均匀。</p>
<h3 id="2-core-site-xml"><a href="#2-core-site-xml" class="headerlink" title="2. core-site.xml"></a>2. core-site.xml</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>io.file.buffer.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>131072<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>解释: Hadoop的缓冲区大小用于 <strong>Hadoop 读HDFS的文件和写HDFS的文件，还有map 的中间结果输出都用到了这个缓冲区容量</strong>，默认为4KB，增加为128KB。</p>
<h2 id="MapReduce调优"><a href="#MapReduce调优" class="headerlink" title="MapReduce调优"></a>MapReduce调优</h2><p>使用 Hadoop 进行大数据运算，当数据量极大时，那么对 MapReduce 性能的调优重要性不言而喻，尤其是 Shuffle 过程中的参数配置对作业的总执行时间影响特别大。</p>
<p>MapReduce优化方法主要从六个方面考虑：数据输入、Map阶段、Reduce阶段、IO传输、数据倾斜问题和常用的调优参数。</p>
<h3 id="1-数据输入"><a href="#1-数据输入" class="headerlink" title="1. 数据输入"></a>1. 数据输入</h3><ol>
<li>  合并小文件：在执行MR任务前将小文件进行合并，大量的小文件会产生大量的Map任务，增大Map任务的装载次数，而任务的装载比较耗时，从而导致MR运行较慢。</li>
<li>  采用 ==CombineTextInputFormat== 来作为输入，解决输入端大量的小文件场景。</li>
</ol>
<h3 id="2-Map-阶段"><a href="#2-Map-阶段" class="headerlink" title="2. Map 阶段"></a>2. Map 阶段</h3><ol>
<li> 减少溢写( spill )次数: 通过调整 io.sort.mb 及 sort.spill.percent 参数值，增大触发 spill 的内存上限，减少 spill 次数，从而减少磁盘 I / O 。</li>
<li> 减少合并( merge )次数: 通过调整 io.sort. factor 参数，增大 merge 的文件数目，减少 merge 的次数，从而缩短 MR 处理时间。</li>
<li> 在 Map 之后，不影响业务逻辑前提下，先进行 combine 处理，减少 I / O </li>
</ol>
<h3 id="3-Reduce-阶段"><a href="#3-Reduce-阶段" class="headerlink" title="3. Reduce 阶段"></a>3. Reduce 阶段</h3><ol>
<li> 合理设置 Map 和 Reduce 数: 两个都不能设置太少，也不能设置太多。太少，会导致 task 等待，延长处理时间;太多，会导致 Map 和 Reduce 任务间竞争资源，造成处理超时等错误。</li>
<li> 设置 Map 和 Reduce 共存: 调整 slowstart.completedmaps 参数，使 Map 运行到定程度后， Reduce 也开始运行，减少 Reduce 的等待时间。</li>
<li> 规避使用 Reduce : 因为 Reduce 在用于连接数据集的时候将会产生大量的网络消耗。通过将 MapReduce 参数 setNumReduceTasks 设置为 0 来创建一个只有 Map 的作业</li>
<li> 合理设置 Reduce 端的 buffer : 默认情况下，数据达到一个國值的时候， buffer 中的数据就会写人磁盘，然后 Reduce 会从磁盘中获得所有的数据。也就是说， buffer 和 Reduce 是没有直接关联的，中间多一个写磁盘→读磁盘的过程，既然有这个弊端，那么就可以通过参数来配置，使得 buffer 中的一部分数据可以直接输送到 Reduce ，从而减少 I / O 开销。这样一来，设置 buffer 需要内存，读取数据需要内存， Reduce 计算也要内存，所以要根据作业的运行情况进行调整。</li>
</ol>
<h3 id="4、I-O传输"><a href="#4、I-O传输" class="headerlink" title="4、I/O传输"></a>4、I/O传输</h3><ol>
<li>  采用数据压缩的方式，减少网络IO的时间。安装Snappy和LZO压缩编码器。</li>
<li>  使用SequenceFile二进制文件。</li>
</ol>
<h3 id="5-数据倾斜问题"><a href="#5-数据倾斜问题" class="headerlink" title="5. 数据倾斜问题"></a>5. 数据倾斜问题</h3><ol>
<li><p>抽样和范围分区（预处理）：提前对原始数据进行抽样得到的结果集来预设分区边界值。</p>
<p>  简单来说就是对本身分布不均匀的数据进行预处理，比如<strong>提前过滤Key</strong>、<strong>预先对数据进行聚合</strong>、<strong>重新将Key打撒</strong>（hash）等。这种方式治标不治本，当原始数据改变还是容易出现数据倾斜。优点就是简单效果好。</p>
</li>
<li><p>  自定义分区：基于Key进行自定义分区，将导致倾斜的Key单独发送给一个Reduce处理。</p>
</li>
<li><p>  Combine：使用Combine可以大量减少小数据倾斜，Combine的目的就是聚合并精简数据。</p>
</li>
<li><p>  采用Map Join，精良避免Reduce Join。</p>
</li>
<li><p>  提高并行度：提高Reduce并行度本质还是打撒Key。</p>
</li>
</ol>
<p>没有一种方式能完美解决数据倾斜问题，更多的还是基于实际情况使用多种方案组合处理。</p>
<h3 id="6-调优参数"><a href="#6-调优参数" class="headerlink" title="6. 调优参数"></a>6. 调优参数</h3><p> Mapreduce还有一些基本的资源属性的配置，这些配置的相关参数都位于 mapred-default.xml 文件中，可以合理配置这些属性提高 Mapreduce性能，下表列举了部分调优属性。</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数说明</th>
</tr>
</thead>
<tbody><tr>
<td>mapreduce.map.memory.mb</td>
<td>一个MapTask可使用的资源上限（单位:MB），默认为1024。如果MapTask实际使用的资源量超过该值，则会被强制杀死。</td>
</tr>
<tr>
<td>mapreduce.reduce.memory.mb</td>
<td>一个ReduceTask可使用的资源上限（单位:MB），默认为1024。如果ReduceTask实际使用的资源量超过该值，则会被强制杀死。</td>
</tr>
<tr>
<td>mapreduce.map.cpu.vcores</td>
<td>每个MapTask可使用的最多cpu core数目，默认值: 1</td>
</tr>
<tr>
<td>mapreduce.reduce.cpu.vcores</td>
<td>每个ReduceTask可使用的最多cpu core数目，默认值: 1</td>
</tr>
<tr>
<td>mapreduce.reduce.shuffle.parallelcopies</td>
<td>每个Reduce去Map中取数据的并行数。默认值是5</td>
</tr>
<tr>
<td>mapreduce.reduce.shuffle.merge.percent</td>
<td>Buffer中的数据达到多少比例开始写入磁盘。默认值0.66</td>
</tr>
<tr>
<td>mapreduce.reduce.shuffle.input.buffer.percent</td>
<td>Buffer大小占Reduce可用内存的比例。默认值0.7</td>
</tr>
<tr>
<td>mapreduce.reduce.input.buffer.percent</td>
<td>指定多少比例的内存用来存放Buffer中的数据，默认值是0.0</td>
</tr>
</tbody></table>
<p>（2）Shuffle性能优化的关键参数，应在YARN启动之前就配置好（mapred-default.xml）</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数说明</th>
</tr>
</thead>
<tbody><tr>
<td>mapreduce.task.io.sort.mb</td>
<td>Shuffle的环形缓冲区大小，默认100m</td>
</tr>
<tr>
<td>mapreduce.map.sort.spill.percent</td>
<td>环形缓冲区溢出的阈值，默认80%</td>
</tr>
</tbody></table>
<h3 id="7、小文件处理"><a href="#7、小文件处理" class="headerlink" title="7、小文件处理"></a>7、小文件处理</h3><p>小文件的优化无非以下几种方式：</p>
<p>（1）在数据采集的时候，就将小文件或小批数据合成大文件再上传HDFS。</p>
<p>（2）在业务处理之前，在HDFS上使用MapReduce程序对小文件进行合并。</p>
<p>（3）在MapReduce处理时，可采用CombineTextInputFormat提高效率。</p>
<p>JVM优化小文件：对于大量小文件Job，可以开启JVM重用会减少45%的运行时间。</p>
<p>具体设置<code>mapreduce.job.jvm.numtasks</code> 值在10-20之间。</p>
<h2 id="YARN调优"><a href="#YARN调优" class="headerlink" title="YARN调优"></a>YARN调优</h2><h3 id="1-RM的内存资源配置，-配置的是资源调度相关"><a href="#1-RM的内存资源配置，-配置的是资源调度相关" class="headerlink" title="1. RM的内存资源配置， 配置的是资源调度相关"></a>1. RM的内存资源配置， 配置的是资源调度相关</h3><table>
<thead>
<tr>
<th>配置</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>yarn.scheduler.minimum-allocation-mb</td>
<td>分配给AM单个容器可申请的最小内存</td>
</tr>
<tr>
<td>yarn.scheduler.maximum-allocation-mb</td>
<td>分配给AM单个容器可申请的最大内存</td>
</tr>
<tr>
<td>yarn.scheduler.minimum-allocation-vcores</td>
<td>每个Container申请的最小CPU核数，默认值：1</td>
</tr>
<tr>
<td>yarn.scheduler.maximum-allocation-vcores</td>
<td>每个Container申请的最大CPU核数，默认值：32</td>
</tr>
</tbody></table>
<blockquote>
<p>  最小值可以计算一个节点最大Container数量；一旦设置，不可动态改变</p>
</blockquote>
<h3 id="2-NM的内存资源配置，配置的是硬件资源相关"><a href="#2-NM的内存资源配置，配置的是硬件资源相关" class="headerlink" title="2. NM的内存资源配置，配置的是硬件资源相关"></a>2. NM的内存资源配置，配置的是硬件资源相关</h3><table>
<thead>
<tr>
<th>配置</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>yarn.nodemanager.resource.memory-mb</td>
<td>节点最大可用内存</td>
</tr>
<tr>
<td>yarn.nodemanager.vmem-pmem-ratio</td>
<td>虚拟内存率，默认2.1</td>
</tr>
</tbody></table>
<blockquote>
<p>  RM1、RM2的值均不能大于NM1的值 NM1可以计算节点最大最大Container数量，max(Container)=NM1/RM1 一旦设置，不可动态改变</p>
</blockquote>
<h3 id="3-AM内存配置相关参数，配置的是任务相关"><a href="#3-AM内存配置相关参数，配置的是任务相关" class="headerlink" title="3. AM内存配置相关参数，配置的是任务相关"></a>3. AM内存配置相关参数，配置的是任务相关</h3><table>
<thead>
<tr>
<th>说明</th>
<th>配置</th>
</tr>
</thead>
<tbody><tr>
<td>分配给map Container的内存大小</td>
<td>mapreduce.map.memory.mb</td>
</tr>
<tr>
<td>分配给reduce Container的内存大小</td>
<td>mapreduce.reduce.memory.mb</td>
</tr>
</tbody></table>
<blockquote>
<p>  这两个值应该在RM1和RM2这两个值之间 AM2的值最好为AM1的两倍 这两个值可以在启动时改变</p>
</blockquote>
<table>
<thead>
<tr>
<th>配置</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>mapreduce.map.java.opts</td>
<td>运行map任务的jvm参数，如-Xmx，-Xms等选项</td>
</tr>
<tr>
<td>mapreduce.reduce.java.opts</td>
<td>运行reduce任务的jvm参数，如-Xmx，-Xms等选项</td>
</tr>
</tbody></table>
<blockquote>
<p>  这两个值应该在AM1和AM2之间</p>
</blockquote>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li>  <a href="https://juejin.cn/post/6987206232587108359">原文链接</a> </li>
</ul>
]]></content>
      <categories>
        <category>Bigdata</category>
        <category>Hadoop</category>
        <category>调优</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive调优</title>
    <url>/2020/9879f82753e1/</url>
    <content><![CDATA[<h2 id="Hive调优"><a href="#Hive调优" class="headerlink" title="Hive调优"></a>Hive调优</h2><h3 id="1、文件调优"><a href="#1、文件调优" class="headerlink" title="1、文件调优"></a>1、文件调优</h3><p>Hive支持的存储数据的格式主要有：TEXTFILE（行存储） 、SEQUENCEFILE（行存储） 、ORC（列存储） 、PARQUET（列存储） 。</p>
<span id="more"></span>

<ol>
<li><p>textfile格式</p>
<p>  Hive默认格式，数据不做压缩，磁盘开销大，数据解析开销大。可结合Gzip、Bzip2使用，但使用Gzip这种方式，hive不会对数据进行切分，从而无法对数据进行并行操作。</p>
</li>
<li><p>Orc格式</p>
<p>  是Hive 0.11版里引入的新的存储格式。</p>
</li>
<li><p>Parquet格式</p>
<p>  Parquet文件是以二进制方式存储的，所以是不可以直接读取的，文件中包括该文件的数据和元数据，因此Parquet格式文件是自解析的。</p>
</li>
</ol>
<h3 id="2、Fetch抓取"><a href="#2、Fetch抓取" class="headerlink" title="2、Fetch抓取"></a>2、Fetch抓取</h3><p>Hive中对某些情况的查询可以不必使用MapReduce计算。例如：SELECT * FROM employees;在这种情况下，Hive可以简单地读取employee对应的存储目录下的文件，然后输出查询结果到控制台。</p>
<p>在<code>hive-default.xml.template</code>文件中<code>hive.fetch.task.conversion</code>默认是more，老版本hive默认是minimal，该属性修改为more以后，在全局查找、字段查找、limit查找等都不走mapreduce。</p>
<h3 id="3、本地模式"><a href="#3、本地模式" class="headerlink" title="3、本地模式"></a>3、本地模式</h3><p>对于大多数这种情况，Hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。</p>
<p>用户可以通过设置<code>hive.exec.mode.local.auto</code>的值为true，来让Hive在适当的时候自动启动这个优化，默认是false。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set hive.exec.mode.local.auto=true;  //开启本地mr</span><br><span class="line">//设置local mr的最大输入数据量，当输入数据量小于这个值时采用local  mr的方式，默认为134217728，即128M</span><br><span class="line">set hive.exec.mode.local.auto.inputbytes.max=50000000;</span><br><span class="line">//设置local mr的最大输入文件个数，当输入文件个数小于这个值时采用local mr的方式，默认为4</span><br><span class="line">set hive.exec.mode.local.auto.input.files.max=10;</span><br></pre></td></tr></table></figure>

<h3 id="4、MapJoin"><a href="#4、MapJoin" class="headerlink" title="4、MapJoin"></a>4、MapJoin</h3><p>如果不指定MapJoin或者不符合MapJoin的条件，那么Hive解析器会将Join操作转换成Common Join，即：在Reduce阶段完成join。容易发生数据倾斜。可以用MapJoin把小表全部加载到内存在map端进行join，避免reducer处理。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 开启Mapjoin  ，默认为true</span><br><span class="line">set hive.auto.convert.join = true; </span><br><span class="line"># 大表小表的阈值设置（默认25M一下认为是小表）</span><br><span class="line">set hive.mapjoin.smalltable.filesize=25000000;</span><br></pre></td></tr></table></figure>

<h3 id="5、GroupBy"><a href="#5、GroupBy" class="headerlink" title="5、GroupBy"></a>5、GroupBy</h3><p>默认情况下，Map阶段同一Key数据分发给一个reduce，当一个key数据过大时就倾斜了。</p>
<p>并不是所有的聚合操作都需要在Reduce端完成，很多聚合操作都可以先在Map端进行部分聚合，最后在Reduce端得出最终结果。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 是否在Map端进行聚合，默认为True</span><br><span class="line">set hive.map.aggr = true</span><br><span class="line"># 在Map端进行聚合操作的条目数目</span><br><span class="line">set hive.groupby.mapaggr.checkinterval = 100000</span><br><span class="line"># 有数据倾斜的时候进行负载均衡（默认是false）</span><br><span class="line">set hive.groupby.skewindata = true</span><br></pre></td></tr></table></figure>

<h3 id="6、Count-Distinct-去重统计"><a href="#6、Count-Distinct-去重统计" class="headerlink" title="6、Count(Distinct) 去重统计"></a>6、Count(Distinct) 去重统计</h3><p>数据量小的时候无所谓，数据量大的情况下，由于COUNT DISTINCT的全聚合操作，即使设定了reduce task个数，<code>set mapred.reduce.tasks=100</code>； hive也只会启动一个reducer。，这就造成一个Reduce处理的数据量太大，导致整个Job很难完成，一般COUNT DISTINCT使用先 <strong>GROUP BY再COUNT的方式替换</strong>：</p>
<h3 id="7、避免笛卡尔积"><a href="#7、避免笛卡尔积" class="headerlink" title="7、避免笛卡尔积"></a>7、避免笛卡尔积</h3><p>尽量避免笛卡尔积，join的时候不加on条件，或者无效的on条件，Hive只能使用1个reducer来完成笛卡尔积。</p>
<h3 id="8、行列过滤"><a href="#8、行列过滤" class="headerlink" title="8、行列过滤"></a>8、行列过滤</h3><p>列处理：在SELECT中，只拿需要的列，如果有，尽量使用分区过滤，**少用SELECT ** 。</p>
<p>行处理：在分区剪裁中，当使用外关联时，如果将副表的过滤条件写在Where后面，那么就会先全表关联，之后再过滤。 简单说就是子查询先写where条件过滤之后在关联查询。</p>
<h3 id="9、动态分区调整"><a href="#9、动态分区调整" class="headerlink" title="9、动态分区调整"></a>9、动态分区调整</h3><p>关系型数据库中，对分区表Insert数据时候，数据库自动会根据分区字段的值，将数据插入到相应的分区中，Hive中也提供了类似的机制，即动态分区(Dynamic Partition)，只不过，使用Hive的动态分区，需要进行相应的配置。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 开启动态分区功能（默认true，开启）</span><br><span class="line">hive.exec.dynamic.partition=true</span><br><span class="line"># 设置为非严格模式（动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，</span><br><span class="line"># nonstrict模式表示允许所有的分区字段都可以使用动态分区。）</span><br><span class="line">hive.exec.dynamic.partition.mode=nonstrict</span><br><span class="line"># 在所有执行MR的节点上，最大一共可以创建多少个动态分区。默认1000</span><br><span class="line">hive.exec.max.dynamic.partitions=1000</span><br><span class="line"># 在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。</span><br><span class="line">hive.exec.max.dynamic.partitions.pernode=100</span><br><span class="line"># 整个MR Job中，最大可以创建多少个HDFS文件。默认100000</span><br><span class="line">hive.exec.max.created.files=100000</span><br><span class="line"># 当有空分区生成时，是否抛出异常。一般不需要设置。默认false</span><br><span class="line">hive.error.on.empty.partition=false</span><br></pre></td></tr></table></figure>

<h3 id="10、合理设置Map和Reduce数"><a href="#10、合理设置Map和Reduce数" class="headerlink" title="10、合理设置Map和Reduce数"></a>10、合理设置Map和Reduce数</h3><p><strong>调整Map数：</strong></p>
<p>Map数量决定因素：input的文件总个数，input的文件大小，集群设置的文件块大小。</p>
<p>增加map的方法为：根据<code>computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))=blocksize=128M</code>公式，调整maxSize最大值。让maxSize最大值低于blocksize就可以增加map的个数。</p>
<p><strong>调整Reduce数</strong>：</p>
<p>过多的启动和初始化reduce也会消耗时间和资源；</p>
<p>另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；</p>
<p>在设置reduce个数的时候也需要考虑这两个原则：处理大数据量利用合适的reduce数；使单个reduce任务处理数据量大小要合适；</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 方法一     公式：N=min(参数2，总输入数据量/参数1)</span><br><span class="line">hive.exec.reducers.bytes.per.reducer=256000000             # 每个Reduce处理的数据量默认是256MB</span><br><span class="line">hive.exec.reducers.max=1009                                # 每个任务最大的reduce数，默认为1009</span><br><span class="line"># 方法二</span><br><span class="line"># 在hadoop的mapred-default.xml文件中修改</span><br><span class="line">set mapreduce.job.reduces = 15; # 设置每个job的Reduce个数</span><br></pre></td></tr></table></figure>



<h3 id="11、合并小文件"><a href="#11、合并小文件" class="headerlink" title="11、合并小文件"></a>11、合并小文件</h3><ol>
<li><p>在map执行前合并小文件，减少map数：CombineHiveInputFormat具有对小文件进行合并的功能（系统默认的格式）。HiveInputFormat没有对小文件合并功能。</p>
  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set hive.input.format= org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span><br></pre></td></tr></table></figure></li>
<li><p>在Map-Reduce的任务结束时合并小文件的设置：</p>
  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在map-only任务结束时合并小文件，默认true</span><br><span class="line">SET hive.merge.mapfiles = true;</span><br><span class="line"># 在map-reduce任务结束时合并小文件，默认false</span><br><span class="line">SET hive.merge.mapredfiles = true;</span><br><span class="line"># 合并文件的大小，默认256M</span><br><span class="line">SET hive.merge.size.per.task = 268435456;</span><br><span class="line"># 当输出文件的平均大小小于该值时，启动一个独立的map-reduce任务进行文件merge</span><br><span class="line">SET hive.merge.smallfiles.avgsize = 16777216;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="11、并行执行"><a href="#11、并行执行" class="headerlink" title="11、并行执行"></a>11、并行执行</h3><p>通过设置参数hive.exec.parallel值为true，就可以开启并发执行。不过，在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。当然，得是在系统资源比较空闲的时候才有优势，否则，没资源，并行也起不来。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set hive.exec.parallel=true;              //打开任务并行执行</span><br><span class="line">set hive.exec.parallel.thread.number=16;  //同一个sql允许最大并行度，默认为8。</span><br></pre></td></tr></table></figure>

<h3 id="12、严格模式"><a href="#12、严格模式" class="headerlink" title="12、严格模式"></a>12、严格模式</h3><p>通过设置属性<code>hive.mapred.mode</code>值为默认是非严格模式nonstrict 。开启严格模式需要修改hive.mapred.mode值为strict，开启严格模式可以禁止3种类型的查询。</p>
<ol>
<li>  对于分区表，除非where语句中含有分区字段过滤条件来限制范围，否则不允许执行。</li>
<li>  对于使用了order by语句的查询，要求必须使用limit语句。</li>
<li>  限制笛卡尔积的查询。</li>
</ol>
<h3 id="13、JVM重用"><a href="#13、JVM重用" class="headerlink" title="13、JVM重用"></a>13、JVM重用</h3><p>这个功能的缺点是，开启JVM重用将一直占用使用到的task插槽，以便进行重用，直到任务完成后才能释放。如果某个“不平衡的”job中有某几个reduce task执行的时间要比其他Reduce task消耗的时间多的多的话，那么保留的插槽就会一直空闲着却无法被其他的job使用，直到所有的task都结束了才会释放。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!--可以在Hadoop的mapred-site.xml文件中进行配置。通常在10-20之间。--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.jvm.numtasks<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>10<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>How many tasks to run per jvm. If set to -1, there is</span><br><span class="line">  no limit. </span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="14、推测执行"><a href="#14、推测执行" class="headerlink" title="14、推测执行"></a>14、推测执行</h3><p>设置开启推测执行参数：Hadoop的mapred-site.xml文件中进行配置，默认是true</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.map.speculative&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;If true, then multiple instances of some map tasks </span><br><span class="line">               may be executed in parallel.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.reduce.speculative&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;If true, then multiple instances of some reduce tasks </span><br><span class="line">               may be executed in parallel.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Hive本身也可以设置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.mapred.reduce.tasks.speculative.execution&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;Whether speculative execution for reducers should be turned on. &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Bigdata</category>
        <category>Hive</category>
        <category>调优</category>
      </categories>
      <tags>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo+NexT搭建静态博客</title>
    <url>/2022/efac6801ae4b/</url>
    <content><![CDATA[<h2 id="一、搭建方案"><a href="#一、搭建方案" class="headerlink" title="一、搭建方案"></a>一、搭建方案</h2><blockquote>
<p>Hexo + Github + Github Pages</p>
</blockquote>
<span id="more"></span>

<h2 id="二、搭建准备"><a href="#二、搭建准备" class="headerlink" title="二、搭建准备"></a>二、搭建准备</h2><h3 id="1、安装Git"><a href="#1、安装Git" class="headerlink" title="1、安装Git"></a>1、安装Git</h3><p>Mac自带，无需安装</p>
<p>Windows 自行网上搜索安装</p>
<h3 id="2、安装NodeJS"><a href="#2、安装NodeJS" class="headerlink" title="2、安装NodeJS"></a>2、安装NodeJS</h3><p><code>Hexo</code>是基于<code>NodeJS</code>编写，Mac上建议先安装<code>homebrew</code>。</p>
<p> Node.js 版本需不低于 10.13，建议使用 Node.js 12.0 及以上版本</p>
<p><strong>Mac</strong>  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">brew install node    <span class="comment"># 安装node</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">npm -v &amp; node -v     <span class="comment"># 查看安装版本</span></span></span><br></pre></td></tr></table></figure>

<p><strong>Windows</strong></p>
<blockquote>
<p>官网下载安装并配置环境</p>
</blockquote>
<h3 id="3、Github"><a href="#3、Github" class="headerlink" title="3、Github"></a>3、Github</h3><p>Github 上创建一个新仓库。</p>
<p>仓库名必须是<code>&lt;用户名&gt;.github.io</code>，而且必须是<code>public</code>项目。</p>
<p>仓库创建完成在根目录新建一个<code>index.html</code>的文件并添加以下内容。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>Page Title<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>Jeremy的个人博客<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>创建完成之后点击：</p>
<blockquote>
<p>Settings -&gt; Pages -&gt; GitHub Pages  就可以看到个人博客的网址。</p>
<p>如果没有就等几分钟。</p>
</blockquote>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/github_Blog.png" alt="image-20220918140519443"></p>
<p>能打开网址就表示成功了，接下来就是安装静态网站框架了。</p>
<h2 id="三、安装Hexo"><a href="#三、安装Hexo" class="headerlink" title="三、安装Hexo"></a>三、安装Hexo</h2><p><a href="https://hexo.io/zh-cn/">Hexo</a> 是一个基于NodeJS的静态网站生成框架，优点是快速生成、部署方便、社区活跃、颜值高。</p>
<blockquote>
<p><a href="https://hexo.io/zh-cn/docs/">Hexo 官方文档</a>   </p>
</blockquote>
<h3 id="1、安装"><a href="#1、安装" class="headerlink" title="1、安装"></a>1、安装</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">npm install hexo-cli -g  <span class="comment"># 全局安装</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo -v                  <span class="comment"># 查看版本</span></span></span><br></pre></td></tr></table></figure>

<h3 id="2、初始化项目"><a href="#2、初始化项目" class="headerlink" title="2、初始化项目"></a>2、初始化项目</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo init blog-hexo        <span class="comment"># 初始化项目，文件夹目录具体可以查看官方文档</span></span></span><br><span class="line">INFO  Cloning hexo-starter https://github.com/hexojs/hexo-starter.git</span><br><span class="line">INFO  Install dependencies</span><br><span class="line">INFO  Start blogging with Hexo!</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> blog-hexo</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">npm install</span></span><br></pre></td></tr></table></figure>

<h3 id="3、启动"><a href="#3、启动" class="headerlink" title="3、启动"></a>3、启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo g         <span class="comment"># 生成静态文件，完整命令 hexo generate</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo s         <span class="comment"># 启动本地服务，完整命令 hexo server</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">访问网址为： http://localhost:4000/</span></span><br></pre></td></tr></table></figure>

<p>发布一篇文章试试：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hexo new &lt;title&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo new test_new_blog</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Hexo文件修改时会自动更新，无需重启 Hexo Server。</span></span><br></pre></td></tr></table></figure>

<img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/image-20220918151004923.png">



<h2 id="四、使用"><a href="#四、使用" class="headerlink" title="四、使用"></a>四、使用</h2><h3 id="1、创建页面"><a href="#1、创建页面" class="headerlink" title="1、创建页面"></a>1、创建页面</h3><p>默认情况下，Hexo 会使用文章的标题来决定文章文件的路径。对于独立页面来说，Hexo 会创建一个以<strong>标题为名字的目录</strong>，并在目录中放置一个 <code>index.md</code> 文件。</p>
<p> 1、创建新的页面</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo new page categories</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo new page tags</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo new page archives</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo new page about</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo new page links</span></span><br></pre></td></tr></table></figure>

<p>2、进入分类文件夹，并编辑文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> blog-hexo/source/categories</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vim index.md</span></span><br><span class="line">---</span><br><span class="line">title: categories</span><br><span class="line">date: 2021-09-18 18:23:51</span><br><span class="line">type: categories</span><br><span class="line">---</span><br></pre></td></tr></table></figure>

<p>注意：分类页面和标签页面需要添加 <code>type</code>。</p>
<p>3、添加页面链接。修改主题<code>_config.yml</code>配置文件，注意不是hexo的配置文件。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> blog-hexo/themes/next/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vim _config.yml</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">去掉相关注释</span></span><br><span class="line">menu:</span><br><span class="line">  home: / || fa fa-home</span><br><span class="line">  categories: /categories/ || fa fa-th</span><br><span class="line">  tags: /tags/ || fa fa-tags</span><br><span class="line">  archives: /archives/ || fa fa-archive</span><br><span class="line">  about: /about/ || fa fa-user</span><br></pre></td></tr></table></figure>

<h3 id="2、写作"><a href="#2、写作" class="headerlink" title="2、写作"></a>2、写作</h3><p>1、创建文章</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo new &lt;title&gt;</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">新建的文件在 <span class="built_in">source</span>/_post/  文件夹下</span></span><br><span class="line">---</span><br><span class="line">title: title</span><br><span class="line">date: 2020-12-22 12:39:04</span><br><span class="line">updated: 2020-12-22 12:39:04</span><br><span class="line">comments: true</span><br><span class="line">categories:</span><br><span class="line">  - [工具,Git]</span><br><span class="line">tags:</span><br><span class="line">  - git</span><br><span class="line">---</span><br></pre></td></tr></table></figure>

<p>2、打开文件开始写作</p>
<h3 id="3、本地发布"><a href="#3、本地发布" class="headerlink" title="3、本地发布"></a>3、本地发布</h3><blockquote>
<p>  Hexo配置文件修改需要重新发布，主题配置修改自动修改。</p>
</blockquote>
<p>1、生成静态页面</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo g</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>  生成页面在：<code>blog-hexo/public</code>目录下</p>
</blockquote>
<p>2、启动本地服务</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo s</span></span><br></pre></td></tr></table></figure>

<h3 id="4、部署到Github-pages"><a href="#4、部署到Github-pages" class="headerlink" title="4、部署到Github pages"></a>4、部署到Github pages</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo clean</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo d</span></span><br></pre></td></tr></table></figure>





<h2 id="五、目录结构和插件介绍"><a href="#五、目录结构和插件介绍" class="headerlink" title="五、目录结构和插件介绍"></a>五、目录结构和插件介绍</h2><h3 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── _config.yml               # 配置信息</span><br><span class="line">├── package.json              # 应用程序的依赖版本管理文件</span><br><span class="line">├── package-lock.json         # 锁定依赖版本文件</span><br><span class="line">├── scaffolds                 # 文章模版文件夹</span><br><span class="line">├── source                    # 资源文件夹</span><br><span class="line">|   ├── _drafts               # 草稿文件夹</span><br><span class="line">|   └── _posts                </span><br><span class="line">└── themes                    # 主题文件夹</span><br></pre></td></tr></table></figure>

<h3 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h3><p>安装和卸载插件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">npm install hexo-deployer-git --save</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">npm uninstall hexo-deployer-git</span> </span><br></pre></td></tr></table></figure>

<p>插件列表：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">npm <span class="built_in">ls</span>       <span class="comment"># 查看插件列表</span></span></span><br><span class="line">hexo-site@0.0.0 /Users/zhengfa.hu/Study/blog-hexo</span><br><span class="line">├── hexo-asset-image@0.0.5                             # 图片显示插件</span><br><span class="line">├── hexo-deployer-git@3.0.0                            # 自动部署插件</span><br><span class="line">├── hexo-generator-archive@1.0.0                       # Hexo自带插件</span><br><span class="line">├── hexo-generator-baidu-sitemap@0.1.9                 # 百度站点插件</span><br><span class="line">├── hexo-generator-category@1.0.0                      # Hexo自带插件</span><br><span class="line">├── hexo-generator-index@2.0.0                         # Hexo自带插件</span><br><span class="line">├── hexo-generator-searchdb@1.4.0                      # 本地搜索插件</span><br><span class="line">├── hexo-generator-sitemap@3.0.1                       # 站点地图插件</span><br><span class="line">├── hexo-generator-tag@1.0.0                           # Hexo自带插件</span><br><span class="line">├── hexo-neat@1.0.9                                    # 博文压缩插件</span><br><span class="line">├── hexo-renderer-ejs@2.0.0                            # Hexo自带插件</span><br><span class="line">├── hexo-renderer-marked@5.0.0                         # Hexo自带插件</span><br><span class="line">├── hexo-renderer-stylus@2.1.0                         # Hexo自带插件</span><br><span class="line">├── hexo-server@3.0.0                                  # Hexo自带插件</span><br><span class="line">├── hexo-theme-landscape@0.0.3                         # 自带主题插件</span><br><span class="line">└── hexo@6.3.0                                         # Hexo自带插件</span><br></pre></td></tr></table></figure>

<h2 id="六、修改主题"><a href="#六、修改主题" class="headerlink" title="六、修改主题"></a>六、修改主题</h2><h3 id="主题"><a href="#主题" class="headerlink" title="主题"></a>主题</h3><p><a href="https://hexo.io/themes/">主题官网</a> 选择一个自己喜欢的主题。推荐<code>NexT</code>、<code>butterfly</code>、 <code>Pure</code>、 <code>Huxblog</code>、 <code>Maupassant</code> ，个人喜欢<code>NexT</code>和<code>butterfly</code>。</p>
<blockquote>
<p>NexT 文档： <a href="https://github.com/next-theme/hexo-theme-next/blob/master/docs/zh-CN/README.md">https://github.com/next-theme/hexo-theme-next/blob/master/docs/zh-CN/README.md</a></p>
<p>butterfly 文档： <a href="https://butterfly.js.org/">https://butterfly.js.org/</a></p>
</blockquote>
<p>安装主题</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> blog-hexo</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">clone</span> https://github.com/next-theme/hexo-theme-next.git  themes/next</span>  </span><br></pre></td></tr></table></figure>

<p>安装完成之后，修改<code>_config.yml</code>配置文件，文件目录： blog-hexo/_config.yml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Extensions</span></span><br><span class="line"><span class="comment">## Plugins: https://hexo.io/plugins/</span></span><br><span class="line"><span class="comment">## Themes: https://hexo.io/themes/</span></span><br><span class="line"><span class="attr">theme:</span> <span class="string">next</span></span><br></pre></td></tr></table></figure>

<p>重启服务</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo -g</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo -s</span></span><br></pre></td></tr></table></figure>

<p>其他配置可以查看   <a href="https://theme-next.iissnan.com/">配置中文文档</a></p>
<h3 id="主题目录结构"><a href="#主题目录结构" class="headerlink" title="主题目录结构"></a>主题目录结构</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blog/themes/next/</span><br><span class="line">├── _config.yml             # 主题配置文件  </span><br><span class="line">├── languages               # 语言（国际化）</span><br><span class="line">├── layout                  # 布局文件夹。用于存放主题的模板文件</span><br><span class="line">├── scripts                 # 脚本文件夹。在启动时会加载这个文件夹</span><br><span class="line">└── source                  # 资源文件夹。例如js、css、images等文件</span><br></pre></td></tr></table></figure>



<h2 id="七、主题常用配置"><a href="#七、主题常用配置" class="headerlink" title="七、主题常用配置"></a>七、主题常用配置</h2><blockquote>
<p>  NexT主题设置文档： <a href="https://theme-next.iissnan.com/theme-settings.html">https://theme-next.iissnan.com/theme-settings.html</a></p>
</blockquote>
<h3 id="黑暗模式"><a href="#黑暗模式" class="headerlink" title="黑暗模式"></a>黑暗模式</h3><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Dark Mode  </span></span><br><span class="line"><span class="attr">darkmode:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h3 id="设置友链（推荐单独使用友链页面）"><a href="#设置友链（推荐单独使用友链页面）" class="headerlink" title="设置友链（推荐单独使用友链页面）"></a>设置友链（推荐单独使用友链页面）</h3><p>编辑<code>主题配置文件</code>：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">menu:</span></span><br><span class="line">  <span class="attr">links:</span> <span class="string">/links/</span> <span class="string">||</span> <span class="string">fa-link</span></span><br></pre></td></tr></table></figure>

<p>修改<code>languages/zh-CN.yml</code></p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">menu:</span></span><br><span class="line">  <span class="attr">links:</span> <span class="string">友链</span></span><br></pre></td></tr></table></figure>

<p>新建友链页面</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo new page links</span></span><br></pre></td></tr></table></figure>

<p>修改<code>links/index.md</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: 友情链接</span><br><span class="line">date: 2022-10-13 01:36:03</span><br><span class="line">type: links</span><br><span class="line">---</span><br><span class="line">------ </span><br><span class="line">&#123;% linkgrid %&#125;</span><br><span class="line">Jeremyhzf | https://jeremyhzf.com/ | 分享技术与生活. | https://jeremyhzf.com/images/avatar.png</span><br><span class="line">Jeremyhzf | https://jeremyhzf.com/ | 分享技术与生活. | https://jeremyhzf.com/images/avatar.png</span><br><span class="line">Test | https://jeremyhzf.com/ | 暂无介绍~ | https://jeremyhzf.com/images/avatar.png</span><br><span class="line">% Theme NexT | https://theme-next.js.org/ | Stay Simple. Stay NexT. | /images/apple-touch-icon-next.png</span><br><span class="line">&#123;% endlinkgrid %&#125;</span><br><span class="line">------</span><br><span class="line">&#123;% note success %&#125;</span><br><span class="line">**友链格式**</span><br><span class="line">- 名称：Jeremyhzf</span><br><span class="line">- 网址：[https://jeremyhzf.com](https://jeremyhzf.com)</span><br><span class="line">- 头像：[https://jeremyhzf.com/images/avatar.png](https://jeremyhzf.com/images/avatar.png)</span><br><span class="line">- 说明：分享技术与生活.</span><br><span class="line">&#123;% endnote %&#125;</span><br></pre></td></tr></table></figure>

<h3 id="设置文章代码高亮和代码块样式"><a href="#设置文章代码高亮和代码块样式" class="headerlink" title="设置文章代码高亮和代码块样式"></a>设置文章代码高亮和代码块样式</h3><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">codeblock:</span></span><br><span class="line">  <span class="comment"># Code Highlight theme     代码高亮主题</span></span><br><span class="line">  <span class="comment"># All available themes: https://theme-next.js.org/highlight/</span></span><br><span class="line">  <span class="attr">theme:</span></span><br><span class="line">    <span class="attr">light:</span> <span class="string">github</span></span><br><span class="line">    <span class="attr">dark:</span> <span class="string">github-dark</span></span><br><span class="line">  <span class="attr">prism:</span></span><br><span class="line">    <span class="attr">light:</span> <span class="string">prism</span></span><br><span class="line">    <span class="attr">dark:</span> <span class="string">prism-dark</span></span><br><span class="line">  <span class="comment"># Add copy button on codeblock  在代码块上添加复制按钮</span></span><br><span class="line">  <span class="attr">copy_button:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="comment"># Available values: default | flat | mac       代码块样式</span></span><br><span class="line">    <span class="attr">style:</span> <span class="string">mac</span></span><br></pre></td></tr></table></figure>

<h3 id="显示文章摘要"><a href="#显示文章摘要" class="headerlink" title="显示文章摘要"></a>显示文章摘要</h3><p>官方给出了三种生成摘要的方式</p>
<p>1、手动截断（推荐）</p>
<p>写博客是可是通过<!--more-->手动截断文章，并显示全文阅读链接</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: Hello World</span><br><span class="line">---</span><br><span class="line">Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).</span><br><span class="line"></span><br><span class="line">&lt;!--more--&gt;</span><br><span class="line"></span><br><span class="line">## Quick Start</span><br><span class="line">### Create a new post</span><br><span class="line">``` bash</span><br><span class="line">$ hexo new &quot;My New Post&quot;</span><br><span class="line">```</span><br><span class="line">More info: [Writing](https://hexo.io/docs/writing.html)</span><br></pre></td></tr></table></figure>

<p>2、通过<code>front-matter</code>添加<code>description</code></p>
<p>这种方式可以手动设置摘要显示的内容，进入文章详情后不会显示。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: Hello World</span><br><span class="line">description: 这里设置文章的摘要</span><br><span class="line">---</span><br><span class="line">Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).</span><br></pre></td></tr></table></figure>

<p>3、自动生成摘要（不推荐）</p>
<p>在主题配置文件中配置，默认截取长度 150 字符。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">auto_excerpt:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">length:</span> <span class="number">150</span></span><br></pre></td></tr></table></figure>

<h3 id="设置404错误页面"><a href="#设置404错误页面" class="headerlink" title="设置404错误页面"></a>设置404错误页面</h3><p>新建<code>404.html</code>放在<code>themes/next/source</code>目录下（注意目录别放错了），添加以下内容（腾讯公益）：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">HTML</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">&quot;content-type&quot;</span> <span class="attr">content</span>=<span class="string">&quot;text/html;charset=utf-8;&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">&quot;X-UA-Compatible&quot;</span> <span class="attr">content</span>=<span class="string">&quot;IE=edge,chrome=1&quot;</span> /&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">&quot;robots&quot;</span> <span class="attr">content</span>=<span class="string">&quot;all&quot;</span> /&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">&quot;robots&quot;</span> <span class="attr">content</span>=<span class="string">&quot;index,follow&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text/css&quot;</span> <span class="attr">href</span>=<span class="string">&quot;https://qzone.qq.com/gy/404/style/404style.css&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/plain&quot;</span> <span class="attr">src</span>=<span class="string">&quot;http://www.qq.com/404/search_children.js&quot;</span></span></span><br><span class="line"><span class="tag">          <span class="attr">charset</span>=<span class="string">&quot;utf-8&quot;</span> <span class="attr">homePageUrl</span>=<span class="string">&quot;/&quot;</span></span></span><br><span class="line"><span class="tag">          <span class="attr">homePageName</span>=<span class="string">&quot;回到我的主页&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://qzone.qq.com/gy/404/data.js&quot;</span> <span class="attr">charset</span>=<span class="string">&quot;utf-8&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://qzone.qq.com/gy/404/page.js&quot;</span> <span class="attr">charset</span>=<span class="string">&quot;utf-8&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h2 id="八、添加第三方插件"><a href="#八、添加第三方插件" class="headerlink" title="八、添加第三方插件"></a>八、添加第三方插件</h2><h3 id="1、评论系统"><a href="#1、评论系统" class="headerlink" title="1、评论系统"></a>1、评论系统</h3><p><code>gitalk</code> ： 推荐。gitalk基于Github的Issue。</p>
<p><code>Waline</code>： 推荐。</p>
<h3 id="2、统计与分析"><a href="#2、统计与分析" class="headerlink" title="2、统计与分析"></a>2、统计与分析</h3><p><strong>分析工具（全添加上）</strong>：</p>
<p><code>google_analytics</code> </p>
<p><code>baidu_analytics</code></p>
<p><code>Growingio Analytics</code> </p>
<p><code>cloudflare_analytics</code> </p>
<p><code>clarity_analytics（微软分析）</code></p>
<p><code>Matomo Analytics </code></p>
<p><strong>统计工具（统计只需要选择一种）</strong>：</p>
<p>推荐 <code>不蒜子统计</code> 或者 <code>LeanCloud</code></p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">busuanzi_count:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">total_visitors:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">total_visitors_icon:</span> <span class="string">fa</span> <span class="string">fa-user</span></span><br><span class="line">  <span class="attr">total_views:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">total_views_icon:</span> <span class="string">fa</span> <span class="string">fa-eye</span></span><br><span class="line">  <span class="attr">post_views:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">post_views_icon:</span> <span class="string">far</span> <span class="string">fa-eye</span></span><br></pre></td></tr></table></figure>

<h3 id="3、搜索服务"><a href="#3、搜索服务" class="headerlink" title="3、搜索服务"></a>3、搜索服务</h3><p>本地搜索和<code>Algolia</code></p>
<h2 id="十、更新"><a href="#十、更新" class="headerlink" title="十、更新"></a>十、更新</h2><h3 id="1、Hexo更新"><a href="#1、Hexo更新" class="headerlink" title="1、Hexo更新"></a>1、Hexo更新</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">检查升级npm本身</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">npm update -g</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">npm install -g npm             <span class="comment"># 更新 npm 版本</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">以下指令均在Hexo目录下操作</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo version                   <span class="comment"># 查看hexo当前版本</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">npm i hexo-cli -g              <span class="comment"># 全局更新</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用npm-check，检查系统中的插件是否有升级的。</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">npm install -g npm-check</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">npm-check</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用npm-upgrade，升级系统中的相关插件。</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">npm install -g npm-upgrade</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">npm-upgrade</span></span><br></pre></td></tr></table></figure>

<h3 id="2、主题更新"><a href="#2、主题更新" class="headerlink" title="2、主题更新"></a>2、主题更新</h3><blockquote>
<p>  主题使用Git更新</p>
</blockquote>
]]></content>
      <categories>
        <category>网站搭建</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>网站搭建</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式一致性</title>
    <url>/2021/624464ae38a0/</url>
    <content><![CDATA[<h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><p>分布式一致性，简单的说就是在一个或多个进程提议了一个值后，使系统中所有进程对这个值达成一致。</p>
<p>为了就某个值达成一致，每个进程都可以提出自己的提议，最终通过分布式一致性算法，所有正确运行的进程学习到相同的值。</p>
<span id="more"></span>

<p>工业界对分布式一致性的应用，都是为了构建多副本状态机模型（Replicated State Machine），实现高可用和强一致。</p>
<p>分布式一致性使多台机器具有相同的状态，运行相同的确定性状态机，在少数机器故障时整体仍能正常工作。</p>
<p>分布式系统的设计目标，一般包括如下几个方面：</p>
<ul>
<li>  可用性:可用性是分布式系统的核心需求,其用于衡量一个分布式系统持续对外提供服务的能力。</li>
<li>  可扩展性:增加机器后不会改变或极少改变系统行为,并且能获得近似线性的性能提升。</li>
<li>  容错性:系统发生错误时,具有对错误进行规避以及从错误中恢复的能力。</li>
<li>  性能:对外服务的响应延时和吞吐率要能满足用户的需求。</li>
</ul>
<h2 id="二、理论"><a href="#二、理论" class="headerlink" title="二、理论"></a>二、理论</h2><h3 id="1、ACID"><a href="#1、ACID" class="headerlink" title="1、ACID"></a>1、ACID</h3><p>数据库系统中为保证事务是正确可靠的，所必须具备的四个特性：原子性(atomicity)、一致性(consistency)、隔离性(isolation)、持久性(durability)。</p>
<ul>
<li>  原子性(atomicity)：一个事务（transaction）中的所有操作要么全部成功，要么全部回滚。</li>
<li>  一致性(consistency)：一个事务在执行前后，数据库都必须处于正确的状态，满足<a href="https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E7%BA%A6%E6%9D%9F">完整性约束</a>。</li>
<li>  隔离性(isolation)：多个事务并发执行时，一个事务的执行不应影响其他事务的执行。</li>
<li>  持久性(durability)：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</li>
</ul>
<blockquote>
<p>  事务隔离分为不同级别，包括未提交读（Read uncommitted）、提交读（read committed）、可重复读（repeatable read）和串行化（Serializable）。</p>
</blockquote>
<h3 id="2、CAP理论"><a href="#2、CAP理论" class="headerlink" title="2、CAP理论"></a>2、CAP理论</h3><p>在理论计算机科学中，CAP定理（CAP theorem），又被称作布鲁尔定理（Brewer’s theorem），它指出对于一个分布式计算系统来说，最多只能满足一下两点，不可能同时满足以下三点：</p>
<ul>
<li>  一致性（<strong>C</strong>onsistency） ：等同于所有节点访问同一份最新的数据副本。</li>
<li>  可用性（Availability）： 每次请求都能获取到非错的响应，但是不保证获取的数据为最新数据。</li>
<li>  分区容错性（Partition tolerance）： 分布式系统在遇到任何网络分区故障的时候,仍然需要能够保证对外提供满足一致性和可用性的服务,除非是整个网络环境都发生了故障。</li>
</ul>
<blockquote>
<p>  分布式系统必然会出现网络问题，所以必须保证分区容错，因此只能在 C 和 A 直接寻找平衡。</p>
</blockquote>
<h3 id="3、BASE理论"><a href="#3、BASE理论" class="headerlink" title="3、BASE理论"></a>3、BASE理论</h3><p>BASE 理论是 eBay 的架构师 Dan Pritchett 提出的，它的核心思想是：“即使无法做到强一致性，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性” 。</p>
<p>BASE 理论有三项指标：</p>
<ul>
<li>  <strong>基本可用（Basically Available）</strong>：是指分布式系统在出现不可预知故障的时候，允许损失部分可用性：比如响应时间、功能降级等；</li>
<li>  <strong>软状态（ Soft State）</strong>：也称为弱状态，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点之间进行数据同步的过程存在延时；</li>
<li>  <strong>最终一致性（ Eventual Consistency）</strong>：强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达成一致的状态。最终一致性是一种特殊的弱一致性</li>
</ul>
<blockquote>
<p>  BASE 理论面向的是大型高可用、可扩展的分布式系统。BASE 通过牺牲强一致性来获得可用性，并允许数据短时间内的不一致，但是最终达到一致状态。</p>
</blockquote>
<h2 id="三、分布式一致性"><a href="#三、分布式一致性" class="headerlink" title="三、分布式一致性"></a>三、分布式一致性</h2><blockquote>
<p>  注意分布式系统下的一致性和单机维度的一致性是不一样的。</p>
</blockquote>
<p>分布式系统中的一致性（strong consistency）按照对一致性要求的不同，主要分为：强一致性，弱一致性。</p>
<h3 id="1、强一致性"><a href="#1、强一致性" class="headerlink" title="1、强一致性"></a>1、强一致性</h3><p>分布式系统中某个节点数据发生改变，后续任何对该数据访问都能获得更新后的值，简而言之，在任意时刻，所有节点访问的数据是一样的。</p>
<p>常见的强一致性算法（共识算法）：  <code>Paxos</code>、<code>Raft</code> 、 <code>Zab</code> 。</p>
<h3 id="2、弱一致性"><a href="#2、弱一致性" class="headerlink" title="2、弱一致性"></a>2、弱一致性</h3><p>也叫<strong>最终一致性</strong>，是指系统并不保证后续访问都会返回最新的数据，但随着时间的推移，最终的数据是一致的。</p>
<p>常见的弱一致性算法： <code>Gossip</code>  、<code>distro</code> 。</p>
<blockquote>
<p>  对于非持久化数据，如需要客户端上报心跳进行服务实例续约，可以采用最终一致性共识算法，可以更多保障服务的可用性，常见Nacos服务注册采用的<code>distro</code> ；</p>
<p>  对于持久化数据，如分布式数据库，强一致性的共识算法保证了数据的正确性，不可避免的损失可用性，在系统数据同步期间是不能对外提供服务的，如Zookeeper的 <code>Zab</code>协议 。</p>
</blockquote>
<h2 id="四、一致性算法"><a href="#四、一致性算法" class="headerlink" title="四、一致性算法"></a>四、一致性算法</h2><p><strong>强一致性共识算法</strong>大致都差不多，采用选举投票机制。常见的有  <code>Paxos</code>、<code>Raft</code> 、 <code>Zab</code> 。</p>
<p>具体可以参考<a href="../%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper.md">Zookeeper</a>。</p>
<p><strong>最终一致性算法</strong>常见的有 DNS系统、<code>Gossip协议</code>，<code>distro</code>是在<code>Gossip协议</code>的基础上改进的 。</p>
<p>Gossip协议是基于六度分隔理论（Six Degrees of Separation）哲学的体现，简单的来说，一个人通过6个中间人可以认识世界任何人。</p>
<p>实现过程：</p>
<p>Gossip协议实现过程就是通过种子节点周期性的散播消息，每次随机散播给系统中的其他未发生过的节点，并且消息不回传散播，最终所有节点都会收到消息。</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/y16mvh0f28.gif" alt="img"></p>
<blockquote>
<p>  整个传播过程可能需要一定的时间，由于不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，因此它是一个<strong>最终一致性协议</strong>。</p>
</blockquote>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li>  <a href="https://zhuanlan.zhihu.com/p/41228196">https://zhuanlan.zhihu.com/p/41228196</a></li>
</ul>
]]></content>
      <categories>
        <category>理论</category>
      </categories>
      <tags>
        <tag>理论</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>接口幂等性</title>
    <url>/2018/efcdcd46bb1c/</url>
    <content><![CDATA[<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>接口幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因 为多次点击而系统造成改变。</p>
<span id="more"></span>

<h2 id="容易出现幂等性问题的场景"><a href="#容易出现幂等性问题的场景" class="headerlink" title="容易出现幂等性问题的场景"></a>容易出现幂等性问题的场景</h2><ol>
<li>  用户多次重复提交表单</li>
<li>  恶意刷单</li>
<li>  用户页面回退再次提交</li>
<li>  微服务互相调用，由于网络问题，导致请求失败。feign 触发重试机制</li>
<li>  消息中间件重复消费</li>
<li>  其他业务情况</li>
</ol>
<h2 id="幂等性解决方案"><a href="#幂等性解决方案" class="headerlink" title="幂等性解决方案"></a>幂等性解决方案</h2><h3 id="唯一约束"><a href="#唯一约束" class="headerlink" title="唯一约束"></a>唯一约束</h3><p>利用数据库主键唯一约束的特性实现幂等，解决了在 <strong>insert 和update 场景</strong>时幂等问题。但主键 要求不是自增的主键，这样就需要业务生成全局唯一的主键。例如订单场景使用订单号作为唯一约束。</p>
<p>如果是分库分表场景下，路由规则要保证相同请求下，落地在同一个数据库和同一表中，要 不然数据库主键约束就不起效果了，因为是不同的数据库和表主键不相关。</p>
<h3 id="锁机制"><a href="#锁机制" class="headerlink" title="锁机制"></a>锁机制</h3><h4 id="1、数据库悲观锁"><a href="#1、数据库悲观锁" class="headerlink" title="1、数据库悲观锁"></a>1、数据库悲观锁</h4><p>乐观锁主要使用于处理<strong>写多读少</strong>的场景。如果出现大量的读取操作，每次读取的时候都会进行加锁，这样会增加大量的锁的开销，降低了系统的吞吐量。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> xxxx <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span> <span class="keyword">for</span> <span class="keyword">update</span>;</span><br></pre></td></tr></table></figure>

<p>悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，需要根据实际情况选用。 另外要注意的是，id 字段一定是主键或者唯一索引，不然可能造成锁表的结果，处理起来会 非常麻烦。</p>
<h4 id="2、数据库乐观锁"><a href="#2、数据库乐观锁" class="headerlink" title="2、数据库乐观锁"></a>2、数据库乐观锁</h4><p>这种方法适合在更新的场景中，需要数据库对应业务表中添加额外字段。</p>
<p>乐观锁主要使用于处理<strong>读多写少</strong>的问题。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">update</span> t_goods <span class="keyword">set</span> count <span class="operator">=</span> count <span class="number">-1</span> , version <span class="operator">=</span> version <span class="operator">+</span> <span class="number">1</span> <span class="keyword">where</span> good_id<span class="operator">=</span><span class="number">2</span> <span class="keyword">and</span> version <span class="operator">=</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>根据 version 版本，也就是在操作库存前先获取当前商品的 version 版本号，然后操作的时候 带上此 version 号。</p>
<p>我们梳理下，我们第一次操作库存时，得到 version 为 1，调用库存服务 version 变成了 2;但返回给订单服务出现了问题，订单服务又一次发起调用库存服务，当订 单服务传如的 version 还是 1，再执行上面的 sql 语句时，就不会执行;因为 version 已经变 为 2 了，where 条件就不成立。这样就保证了不管调用几次，只会真正的处理一次。</p>
<h4 id="3、业务层分布式锁"><a href="#3、业务层分布式锁" class="headerlink" title="3、业务层分布式锁"></a>3、业务层分布式锁</h4><p>如果多个机器可能在同一时间同时处理相同的数据，比如多台机器<strong>定时任务</strong>都拿到了相同数 据处理，我们就可以加分布式锁，锁定此数据，处理完成后释放锁。获取到锁的必须先判断 这个数据是否被处理过。</p>
<h3 id="Token机制"><a href="#Token机制" class="headerlink" title="Token机制"></a>Token机制</h3><p>客户端连续点击或者调用方的超时重试等情况，就可以用 <code>Token</code> 的机制实现防止重复提交。</p>
<p>我们在分析业务的时候，哪些业务是存在幂等问题的， 就必须在执行业务前，先去获取 token，服务器会把 token 保存到 redis 中。</p>
<h4 id="流程："><a href="#流程：" class="headerlink" title="流程："></a>流程：</h4><ol>
<li>  服务端提供了获取token 的接口。</li>
<li>  客户端调用接口获取Token，然后服务端存储该 Token 到 Redis ，并设置过期时间。</li>
<li>  客户端调用业务接口请求时，把 token 携带过去，一般放在请求头部。</li>
<li>  服务端接收请求并判断 Token 是否存在 Redis 中，如果存在则表示第一次请求，删除 Token 继续执行业务。</li>
<li>  如果 Token 不存在 Redis 中，则表示重复标记信息。</li>
</ol>
<h4 id="Token机制危险性"><a href="#Token机制危险性" class="headerlink" title="Token机制危险性:"></a>Token机制危险性:</h4><h5 id="1、先删除-token-还是后删除-token"><a href="#1、先删除-token-还是后删除-token" class="headerlink" title="1、先删除 token 还是后删除 token;"></a>1、先删除 token 还是后删除 token;</h5><ol>
<li><p>  先删除可能导致，业务确实没有执行，重试还带上之前token，由于防重设计导致， 请求还是不能执行。</p>
</li>
<li><p>  后删除可能导致，业务处理成功，但是服务闪断，出现超时，没有删除token，别 人继续重试，导致业务被执行两边</p>
</li>
<li><p>  我们最好设计为先删除token，如果业务调用失败，就重新获取token再次请求。</p>
</li>
</ol>
<h5 id="2、Token-获取、比较和删除必须是原子性"><a href="#2、Token-获取、比较和删除必须是原子性" class="headerlink" title="2、Token 获取、比较和删除必须是原子性"></a>2、Token 获取、比较和删除必须是原子性</h5><ol>
<li><p>   redis.get(token) 、token.equals、redis.del(token)如果这两个操作不是原子，可能导 致，高并发下，都 get 到同样的数据，判断都成功，继续业务并发执行</p>
</li>
<li><p>   可以在redis使用lua脚本完成这个操作</p>
</li>
</ol>
<h3 id="全局唯一请求ID"><a href="#全局唯一请求ID" class="headerlink" title="全局唯一请求ID"></a>全局唯一请求ID</h3><p>调用接口时，生成一个唯一 id，redis 将数据保存到集合中(去重)，存在即处理过。 可以使用 nginx 设置每一个请求的唯一 id;</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">proxy_set_header X-Request-Id $request_id;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  <a href="https://pdai.tech/md/arch/arch-z-id.html">分布式系统全局唯一ID生成方案</a></p>
</blockquote>
<h3 id="防重表"><a href="#防重表" class="headerlink" title="防重表"></a>防重表</h3><p>这种也是网上找的方式，没怎么用过。</p>
<p>1、使用订单号 orderNo 做为去重表的唯一索引，把唯一索引插入去重表，再进行业务操作，且 他们在同一个事务中。这个保证了重复请求时，因为去重表有唯一约束，导致请求失败，避 免了幂等问题。这里要注意的是，去重表和业务表应该在同一库中，这样就保证了在同一个 事务，即使业务操作失败了，也会把去重表的数据回滚。这个很好的保证了数据一致性。</p>
<p>2、redis防重：很多数据需要处理，只能被处理一次，比如我们可以计算数据的 MD5 将其放入 redis 的 set，每次处理数据，先看这个 MD5 是否已经存在，存在就不处理。</p>
]]></content>
      <categories>
        <category>理论</category>
      </categories>
      <tags>
        <tag>理论</tag>
        <tag>业务</tag>
      </tags>
  </entry>
  <entry>
    <title>数仓建模</title>
    <url>/2021/d278397afa48/</url>
    <content><![CDATA[<h1 id="一、概念"><a href="#一、概念" class="headerlink" title="一、概念"></a>一、概念</h1><p>数据建模简单来说就是基于对业务的理解，将各种数据进行整合和关联，并最终使得这些数据可用性，可读性增强，让使用方能快速的获取到自己关心的有价值的信息并且及时的作出响应。</p>
<span id="more"></span>

<h1 id="二、目的"><a href="#二、目的" class="headerlink" title="二、目的"></a>二、目的</h1><p>大数据的数仓建模是通过建模的方法更好的组织、存储数据，以便在 性能、成本、效率和数据质量之间找到最佳平衡点。一般主要从下面四点考虑：</p>
<ol>
<li>高性能：能够快速查询所需的数据，减少数据I/O</li>
<li>低成本：减少不必要的数据冗余和重复计算，实现计算结果数据复用，降低存储成本和计算成本。</li>
<li>高效率：改善用户应用体验，提高使用数据的效率。</li>
<li>高质量：改善数据统计口径的不一致性，减少数据计算错误的可能性，提供高质量的、一致的数据访问平台。</li>
</ol>
<h1 id="三、数据建模的几种方式"><a href="#三、数据建模的几种方式" class="headerlink" title="三、数据建模的几种方式"></a>三、数据建模的几种方式</h1><h2 id="1-ER模型-范式建模"><a href="#1-ER模型-范式建模" class="headerlink" title="1.ER模型(范式建模)"></a>1.ER模型(范式建模)</h2><blockquote>
<ul>
<li>1NF：属性不可再分割（例如不能存在5台电脑的属性，坏处：表都没法用）</li>
<li>2NF：不能存在部分函数依赖（例如主键（学号+课名）–&gt;成绩，姓名，但学号–》姓名，所以姓名部分依赖于主键（学号+课名），所以要去除，坏处：数据冗余）</li>
<li>3NF：不能存在传递函数依赖（学号–》宿舍种类–》价钱，坏处：数据冗余和增删异常）</li>
</ul>
</blockquote>
<p><strong>MySQL关系模型</strong>：关系模型主要应用与OLTP系统中，为了保证数据的一致性以及避免冗余，所以大部分业务系统的表都是遵循第三范式的。</p>
<p><strong>Hive 维度模型</strong>：维度模型主要应用于OLAP系统中，因为关系模型虽然冗余少，</p>
<p>但是在大规模数据，跨表分析统计查询过程中，会造成多表关联，这会大大降低执行效率。</p>
<p>所以HIVE把相关各种表整理成两种：<strong>事实表和维度表</strong>两种。所有维度表围绕着事实表进行解释。</p>
<h2 id="2-维度建模"><a href="#2-维度建模" class="headerlink" title="2.维度建模"></a>2.维度建模</h2><h3 id="维度建模的分类"><a href="#维度建模的分类" class="headerlink" title="维度建模的分类"></a>维度建模的分类</h3><p>维度建模按数据组织类型划分可分为<strong>星型模型、雪花模型、星座模型</strong></p>
<p>星型模型（事实表+一级维度表），雪花（事实表+多级维度），星座模型（星型模型+多个事实表）</p>
<h3 id="维度表"><a href="#维度表" class="headerlink" title="维度表"></a>维度表</h3><p>一般是对事实的<strong>描述信息</strong>。每一张维表对应现实世界中的一个对象或者概念。  例如：用户、商品、日期、地区等。</p>
<h3 id="事实表"><a href="#事实表" class="headerlink" title="事实表"></a>事实表</h3><p>事实表作为数据仓库维度建模的核心，紧紧围绕着业务过程来设计。其包含与该业务过程有关的维度引用（维度表外键）以及该业务过程的度量（通常是可累加的数字类型字段）。</p>
<p>事实包含业务的度量，是定量的数据，如销售价格、销售数量、距离、速度、重量等是事实。</p>
<p><strong>事实表分类：</strong></p>
<ol>
<li><strong>事务型事实表</strong>: 事务事实表用来记录事务层面的事实（例如交易流水值、销售数量等），它保存的是各业务过程的原子操作事件，即最细粒度的操作事件。其数据在事务发生后发生，粒度为每一行数据。一旦数据写入成功，数据就不再进行更改，其更新方式为<strong>增量更新</strong>。</li>
<li><strong>周期型快照事实表</strong>: 周期快照事实表以具有规律性的、可预见的时间间隔来记录事实，主要用于分析一些存量型（例如商品库存，账户余额）或者状态型（空气温度，行驶速度）指标。</li>
<li><strong>累积型快照事实表</strong>:  <strong>累计快照事实表用于跟踪业务事实的变化。</strong>累计快照事实表是基于一个业务流程中的多个关键业务过程联合处理而构建的事实表，例如，数据仓库中可能需要累积或者存储订单从下订单开始，到订单商品被打包、运输、和签收的各个业务阶段的时间点数据来跟踪订单声明周期的进展情况。当这个业务过程进行时，事实表的记录也要不断更新。</li>
</ol>
<p><strong>事实类型：</strong></p>
<p>此处的事实类型是指<strong>度量值的类型</strong>，而非事实表的类型。事实（度量值）共分为三类，分别是可加事实，半可加事实和不可加事实。</p>
<ol>
<li>  可加事实</li>
</ol>
<p>可加事实是指可以按照与事实表相关的所有维度进行累加，例如事务型事实表中的事实。</p>
<ol start="2">
<li>  半可加事实</li>
</ol>
<p>半可加事实是指只能按照与事实表相关的一部分维度进行累加，例如周期型快照事实表中的事实。以上述各仓库中各商品的库存每天快照事实表为例，这张表中的库存事实可以按照仓库或者商品维度进行累加，但是不能按照时间维度进行累加，因为将每天的库存累加起来是没有任何意义的。</p>
<ol start="3">
<li>  不可加事实</li>
</ol>
<p>不可加事实是指完全不具备可加性，例如比率型事实。不可加事实通常需要转化为可加事实，例如比率可转化为分子和分母。</p>
<table>
<thead>
<tr>
<th>特点</th>
<th>事务型事实表</th>
<th>周期快照事实表</th>
<th>累积快照事实表</th>
</tr>
</thead>
<tbody><tr>
<td>时间/时期</td>
<td>离散事务时间点</td>
<td>有规律、可预测的间隔产生快照</td>
<td>时间跨度不确定的不断变化的工作流</td>
</tr>
<tr>
<td>粒度</td>
<td>每行代表实体的一个事务</td>
<td>每行代表一个时间周期的某个实体</td>
<td>每行代表实体的一个业务周期</td>
</tr>
<tr>
<td>事实表加载</td>
<td>新增</td>
<td>新增</td>
<td>新增和修改</td>
</tr>
<tr>
<td>事实表更新</td>
<td>不更新</td>
<td>不更新</td>
<td>业务过程变更时更新</td>
</tr>
<tr>
<td>时间维</td>
<td>业务日期</td>
<td>时期末</td>
<td>相关业务过程事实和时间间隔事实</td>
</tr>
<tr>
<td>事实</td>
<td>事务事实</td>
<td>累计事实</td>
<td>限定多个业务阶段内的绩效</td>
</tr>
<tr>
<td>举例</td>
<td>交易流水</td>
<td>每个时间段的库存数据</td>
<td>交易流程中下单、支付、发货、确认收货业务过程</td>
</tr>
</tbody></table>
<h3 id="维度表和事实表的区别"><a href="#维度表和事实表的区别" class="headerlink" title="维度表和事实表的区别"></a>维度表和事实表的区别</h3><ol>
<li>事实表就是你要关注的内容。</li>
<li>维度表就是你观察该事务的角度，是从哪个角度去观察这个内容的。</li>
</ol>
<p>​     例如，某地区商品的销量，是从地区这个角度观察商品销量的。事实表就是销量表(指标)，维度表就是地区表(维度)。</p>
<p><strong>同步策略</strong>：</p>
<ol>
<li>维度表，每日全量或者每月（更长时间）全量</li>
<li>事务型事实表：每日增量</li>
<li>周期性事实表：拉链表(或者全量表)</li>
</ol>
<h2 id="3-Data-Vault模型"><a href="#3-Data-Vault模型" class="headerlink" title="3.Data Vault模型"></a>3.Data Vault模型</h2><p>Data Vault Dan Linstedt 发起创建的一种模型，它是模型的衍生，其设计的出发点也是为了实现数据的整合，但不能直接用于数据分析决策。它强调建立一个可审计的基础数据层，也就是强调数据的历史性、可追溯性和原子性，而不要求对数据进行过度的一致性处理和整合；</p>
<p>同时它基于主题概念将企业数据进行结构化组织，并引入了更进一步的范式处理来优化模型，以应对源系统变更的扩展性。Data Vault 型由以下几部分组成。</p>
<p>•  Hub ：是企业的核心业务实体，由 实体 key 、数据仓库序列代理键、装载时间、数据来源组成。</p>
<p>•  Link ：代表 Hub 之间的关系。这里与 模型最大的区别是将关系作为一个独立的单元抽象，可以提升模型的扩展性。它可以直</p>
<p>接描述 1:1 1:n n:n 的关系，而不需要做任何变更。它由 Hub 的代理键、装载时间、数据来源组成。</p>
<p>•  Satellite ：是 Hub 的详细描述内容， 一个 Hub 可以有多个 Satellite它由 Hub 的代理键、装载时间、来源类型、详细的 Hub 描述信息组成。</p>
<p>Data Vault 模型比 ER 模型更容易设计和产出，它的 ETL 加工可实现配置化。</p>
<h2 id="4-Anchor模型"><a href="#4-Anchor模型" class="headerlink" title="4.Anchor模型"></a>4.Anchor模型</h2><h1 id="四、四种建模方法总结"><a href="#四、四种建模方法总结" class="headerlink" title="四、四种建模方法总结"></a>四、四种建模方法总结</h1><p>以上为四种基本的建模方法，当前主流建模方法为： ER模型、维度模型</p>
<ol>
<li>ER模型常用于OLTP数据库建模，应用到构建数仓时更偏重数据整合， 站在企业整体考虑，将各个系统的数据按相似性一致性、合并处理，为 数据分析、决策服务，但并不便于直接用来支持分析。缺陷：需要全面梳理企业所有的业务和数据流，周期长，人员要求高。</li>
<li>维度建模是面向分析场景而生，针对分析场景构建数仓模型；重点关注快 速、灵活的解决分析需求，同时能够提供大规模数据的快速响应性能。针对性 强，主要应用于数据仓库构建和OLAP引擎低层数据模型。优点：不需要完整的梳理企业业务流程和数据，实施周期根据主题边界而定，容易快速实现demo</li>
<li>数仓模型的选择是灵活的，不局限于某一种模型方法</li>
<li>数仓模型的设计也是灵活的，以实际需求场景为导向</li>
<li>模型设计要兼顾灵活性、可扩展，而对终端用户透明性</li>
<li>模型设计要考虑技术可靠性和实现成本</li>
</ol>
<h1 id="五、模型分层"><a href="#五、模型分层" class="headerlink" title="五、模型分层"></a>五、模型分层</h1><blockquote>
<p>数据仓库一般分为三层，自上而下分别为数据贴源层（ODS，Operation Data Store）、数据公共层（CDM，Common Data Model）和数据应用层（ADS，Application Data Service）。</p>
</blockquote>
<h3 id="1-ods层"><a href="#1-ods层" class="headerlink" title="1. ods层"></a>1. ods层</h3><ol>
<li>保持数据原貌不做任何修改，起到备份数据的作用。</li>
<li>数据采用压缩，减少磁盘存储空间（例如：原始数据100G，可以压缩到10G左右）</li>
<li>创建分区表，防止后续的全表扫描</li>
</ol>
<h3 id="2-cdm层"><a href="#2-cdm层" class="headerlink" title="2. cdm层"></a>2. cdm层</h3><blockquote>
<p><strong>维度建模一般按照以下四个步骤： 选择业务过程→声明粒度→确认维度→确认事实</strong></p>
</blockquote>
<p>数据公共层CDM（Common Data Model，又称通用数据模型层），包括DIM维度表、DWD,DW和DWS，由ODS层数据加工而成。主要完成数据加工与整合，建立一致性的维度，构建可复用的面向分析和统计的明细事实表，以及汇总公共粒度的指标</p>
<ul>
<li>公共维度层（DIM）：基于维度建模理念思想，建立企业一致性维度。<strong>降低数据计算口径和算法不统一风险</strong>。 公共维度层的表通常也被称为逻辑维度表，维度和维度逻 辑表通常一一对应。</li>
<li>明细粒度事实层（DWD）：对数据进行<strong>规范化编码转换</strong>，<strong>清洗</strong>，<strong>统一格式</strong>，<strong>脱敏</strong>等，不做横向整合</li>
<li>主题宽表层(DW)  ：对dwd各种信息进行整合，输出主题宽表(面 向业务过 程，不同业务过程的信息不冗余建设，采用外键形式)</li>
<li>公共汇总粒度事实层（DWS）：以分析的主题对象作为建模驱动，基于上层的应用和产品的指标需求，构建公共粒度的汇总指标事实表，以宽表化手段物理化模型。构建命名规范、口径一致的统计指标，为上层提供公共指标，建立汇总宽表、明细事实表。</li>
</ul>
<p>公共汇总粒度事实层的表通常也被称为汇总逻辑表，用于存放派生指标数据。</p>
<h3 id="3-ads层"><a href="#3-ads层" class="headerlink" title="3. ads层"></a>3. ads层</h3><p>数据应用层ADS（Application Data Service）：面向业务需求定制开发，存放数据产品个性化的统计指标数据。</p>
<h1 id="六、业务设计流程"><a href="#六、业务设计流程" class="headerlink" title="六、业务设计流程"></a>六、业务设计流程</h1><p><strong>选择业务过程→声明粒度→确认维度→确认事实。</strong></p>
<h1 id="六、分层的好处"><a href="#六、分层的好处" class="headerlink" title="六、分层的好处"></a>六、分层的好处</h1><ol>
<li>清晰数据结构：每一个数据分层都有它的作用域，这样我们在使用表的时候能更方便地定位和理解。</li>
<li>数据血缘追踪：简单来讲可以这样理解，我们最终给业务呈现的是一张能直接使用的张业务表，但是它的来源有很多，如果有一张来源表出问题了，我们希望能够快速准确地定位到问题，并清楚它的危害范围。</li>
<li>减少重复开发：规范数据分层，开发一些通用的中间层数据，能够减少极大的重复计算。</li>
<li>把复杂问题简单化：将一个复杂的任务分解成多个步骤来完成，每一层只处理单一的步骤，比较简单和容易理解。而且便于维护数据的准确性，当数据出现问题之后，可以不用修复所有的数据，只需要从有问题的步骤开始修复。</li>
</ol>
<h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><ul>
<li>  <a href="https://segmentfault.com/a/1190000038226620">https://segmentfault.com/a/1190000038226620</a></li>
</ul>
]]></content>
      <categories>
        <category>Bigdata</category>
        <category>理论</category>
      </categories>
      <tags>
        <tag>理论</tag>
        <tag>数仓</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql实战</title>
    <url>/2018/530d1b0c740e/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>MySQL 是应用最广泛的开源关系数据库，是许多常见网站、应用程序和商业产品使用的主要关系数据存储。MySQL 有 20 多年的社区开发和支持历史，是一种可靠、稳定而安全的基于 SQL 的数据库管理系统。MySQL 数据库适用于各种使用案例，包括任务关键型应用程序、动态网站以及用于软件、硬件和设备的嵌入式数据库。</p>
<span id="more"></span>

<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><blockquote>
<p>  <a href="https://downloads.mysql.com/archives/community/">官方下载地址</a></p>
</blockquote>
<p>软件包列表：</p>
<ul>
<li>  <code>MySQL-client-5.6.24-1.el6.x86_64.rpm</code></li>
<li>  <code>MySQL-server-5.6.24-1.el6.x86_64.rpm</code></li>
<li>  <code>mysql-connector-java-5.1.27.tar.gz</code> ： 操作系统选择<code>Platform Independent</code>（平台无关）</li>
</ul>
<h2 id="安装（Centos7）"><a href="#安装（Centos7）" class="headerlink" title="安装（Centos7）"></a>安装（Centos7）</h2><h3 id="1、卸载旧版本"><a href="#1、卸载旧版本" class="headerlink" title="1、卸载旧版本"></a>1、卸载旧版本</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rpm -qa|grep mysql                                  <span class="comment"># 查看</span></span></span><br><span class="line">mysql-libs-5.1.73-7.el6.x86_64</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rpm -e --nodeps mysql-libs-5.1.73-7.el6.x86_64      <span class="comment"># 卸载</span></span></span><br></pre></td></tr></table></figure>

<h3 id="2、安装服务端"><a href="#2、安装服务端" class="headerlink" title="2、安装服务端"></a>2、安装服务端</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rpm -ivh MySQL-server-5.6.24-1.el6.x86_64.rpm</span>   </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /root/.mysql_secret                             <span class="comment"># 查看安装产生的随机密码</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">service mysql status</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">service mysql start</span></span><br></pre></td></tr></table></figure>

<h3 id="3、安装客户端"><a href="#3、安装客户端" class="headerlink" title="3、安装客户端"></a>3、安装客户端</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rpm -ivh MySQL-client-5.6.24-1.el6.x86_64.rpm</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">mysql -uroot -pOEXaQuS8IWkG19Xs                     <span class="comment"># 连接mysql服务端</span></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">SET PASSWORD=PASSWORD(<span class="string">&#x27;000000&#x27;</span>);               <span class="comment">#修改密码</span></span></span><br></pre></td></tr></table></figure>

<h3 id="4、user配置"><a href="#4、user配置" class="headerlink" title="4、user配置"></a>4、user配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">mysql&gt;</span><span class="language-bash">use mysql;</span></span><br><span class="line"><span class="meta prompt_">mysql&gt;</span><span class="language-bash">select User, Host, Password from user;              <span class="comment"># 查询User表</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改Host，可以远程访问</span></span><br><span class="line"><span class="meta prompt_">mysql&gt;</span><span class="language-bash">update user <span class="built_in">set</span> host=<span class="string">&#x27;%&#x27;</span> <span class="built_in">where</span> host=<span class="string">&#x27;localhost&#x27;</span>;</span>    </span><br><span class="line"><span class="meta prompt_">mysql&gt;</span><span class="language-bash">delete from user <span class="built_in">where</span> Host=<span class="string">&#x27;hadoop102&#x27;</span>;</span></span><br><span class="line"><span class="meta prompt_">mysql&gt;</span><span class="language-bash">delete from user <span class="built_in">where</span> Host=<span class="string">&#x27;127.0.0.1&#x27;</span>;</span></span><br><span class="line"><span class="meta prompt_">mysql&gt;</span><span class="language-bash">delete from user <span class="built_in">where</span> Host=<span class="string">&#x27;::1&#x27;</span>;</span></span><br><span class="line"><span class="meta prompt_">mysql&gt;</span><span class="language-bash">flush privileges;                                    <span class="comment"># 刷新</span></span></span><br><span class="line"><span class="meta prompt_">mysql&gt;</span><span class="language-bash">quit;</span></span><br></pre></td></tr></table></figure>



<h3 id="5、配置文件"><a href="#5、配置文件" class="headerlink" title="5、配置文件"></a>5、配置文件</h3><p>配置文件位置，Linux默认在<code>/etc/my.cnf</code>，如果找不到通过一下命令查找：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">两种方式都可以查找my.cnf位置</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">locate my.cnf</span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">select @@basedir;</span></span><br></pre></td></tr></table></figure>

<p>修改配置文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[client]</span><br><span class="line">default-character-set=utf8mb4</span><br><span class="line">[mysql]</span><br><span class="line">default-character-set=utf8mb4</span><br><span class="line">[mysqld]</span><br><span class="line">init_connect=&#x27;SET collation_connection = utf8mb4_unicode_ci&#x27;</span><br><span class="line">init_connect=&#x27;SET NAMES utf8mb4&#x27;</span><br><span class="line">character-set-server=utf8mb4</span><br><span class="line">collation-server=utf8mb4_unicode_ci</span><br><span class="line"># 开启binlog</span><br><span class="line">log-bin=mysql-bin      </span><br><span class="line">server-id=1</span><br><span class="line"># 设置日志三种格式：STATEMENT、ROW、MIXED 。</span><br><span class="line">binlog_format = mixed</span><br><span class="line"># 开启binlog的库</span><br><span class="line">binlog-do-db=db_name1</span><br><span class="line">binlog-do-db=db_name2</span><br><span class="line"># 数据存放位置</span><br><span class="line">datadir=/var/lib/mysql</span><br><span class="line">socket=/var/lib/mysql.sock</span><br><span class="line">[mysql_safe]</span><br><span class="line">log-error=/var/log/mysqld.log</span><br><span class="line">pid-file=/var/run/mysqld/mysqld.pid</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  <code>log-bin=mysql-bin</code> 这个表示binlog日志的前缀是mysql-bin，以后生成的日志文件就是 mysql-bin.000001 的文件后面的数字按顺序生成，每次mysql重启或者到达单个文件大小的阈值时，新生一个文件，按顺序编号。</p>
</blockquote>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>TODO</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><h3 id="MYSQL执行顺序"><a href="#MYSQL执行顺序" class="headerlink" title="MYSQL执行顺序"></a>MYSQL执行顺序</h3><p>MySQL的语句一共分为11步，如下图所标注的那样，最先执行的总是FROM操作，最后执行的是LIMIT操作。其中每一个操作都会产生一张虚拟的表，这个虚拟的表作为一个处理的输入，只是这些虚拟的表对用户来说是透明的，但是只有最后一个虚拟的表才会被作为结果返回。如果没有在语句中指定某一个子句，那么将会跳过相应的步骤。</p>
<p>下面我们来具体分析一下查询处理的每一个阶段</p>
<ol>
<li>FORM: 对FROM的左边的表和右边的表计算笛卡尔积。产生虚表VT1。</li>
<li>ON: 对虚表VT1进行ON筛选，只有那些符合的行才会被记录在虚表VT2中。</li>
<li>JOIN： 如果指定了OUTER JOIN（比如left join、 right join），那么保留表中未匹配的行就会作为外部行添加到虚拟表VT2中，产生虚拟表VT3, rug from子句中包含两个以上的表的话，那么就会对上一个join连接产生的结果VT3和下一个表重复执行步骤1~3这三个步骤，一直到处理完所有的表为止。</li>
<li>WHERE： 对虚拟表VT3进行WHERE条件过滤。只有符合的记录才会被插入到虚拟表VT4中。</li>
<li>GROUP BY: 根据group by子句中的列，对VT4中的记录进行分组操作，产生VT5。</li>
<li>CUBE | ROLLUP: 对表VT5进行cube或者rollup操作，产生表VT6。</li>
<li>HAVING： 对虚拟表VT6应用having过滤，只有符合的记录才会被 插入到虚拟表VT7中。</li>
<li>SELECT： 执行select操作，选择指定的列，插入到虚拟表VT8中。</li>
<li>DISTINCT： 对VT8中的记录进行去重。产生虚拟表VT9。</li>
<li>ORDER BY: 将虚拟表VT9中的记录按照进行排序操作，产生虚拟表VT10。</li>
<li>LIMIT：取出指定行的记录，产生虚拟表VT11, 并将结果返回。</li>
</ol>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SQL</span>查询处理的步骤序号： </span><br><span class="line">(<span class="number">8</span>) <span class="keyword">SELECT</span> (<span class="number">9</span>) <span class="keyword">DISTINCT</span> (<span class="number">11</span>) <span class="operator">&lt;</span>TOP_specification<span class="operator">&gt;</span> <span class="operator">&lt;</span>select_list<span class="operator">&gt;</span></span><br><span class="line">(<span class="number">1</span>) <span class="keyword">FROM</span> <span class="operator">&lt;</span>left_table<span class="operator">&gt;</span></span><br><span class="line">(<span class="number">3</span>) <span class="operator">&lt;</span>join_type<span class="operator">&gt;</span> <span class="keyword">JOIN</span> <span class="operator">&lt;</span>right_table<span class="operator">&gt;</span></span><br><span class="line">(<span class="number">2</span>) <span class="keyword">ON</span> <span class="operator">&lt;</span>join_condition<span class="operator">&gt;</span></span><br><span class="line">(<span class="number">4</span>) <span class="keyword">WHERE</span> <span class="operator">&lt;</span>where_condition<span class="operator">&gt;</span></span><br><span class="line">(<span class="number">5</span>) <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="operator">&lt;</span>group_by_list<span class="operator">&gt;</span></span><br><span class="line">(<span class="number">6</span>) <span class="keyword">WITH</span> &#123;<span class="keyword">CUBE</span> <span class="operator">|</span> <span class="keyword">ROLLUP</span>&#125;</span><br><span class="line">(<span class="number">7</span>) <span class="keyword">HAVING</span> <span class="operator">&lt;</span>having_condition<span class="operator">&gt;</span></span><br><span class="line">(<span class="number">10</span>) <span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="operator">&lt;</span>order_by_list<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="Mysql的binlog"><a href="#Mysql的binlog" class="headerlink" title="Mysql的binlog"></a>Mysql的binlog</h3><h4 id="binlog介绍"><a href="#binlog介绍" class="headerlink" title="binlog介绍"></a>binlog介绍</h4><p>MySQL的二进制日志可以说MySQL最重要的日志了，它记录了所有的DDL和DML(除了数据查询语句)语句，以事件形式记录，还包含语句所执行的消耗的时间，MySQL的二进制日志是事务安全型的。</p>
<p>一般来说开启二进制日志大概会有1%的性能损耗。二进制有两个最重要的使用场景:</p>
<ol>
<li>  MySQL Replication在Master端开启binlog，Master把它的二进制日志传递给slaves来达到master-slave数据一致的目的。</li>
<li>  数据恢复，通过使用mysqlbinlog工具来使恢复数据。</li>
</ol>
<p>二进制日志包括两类文件：二进制日志索引文件（文件名后缀为.index）用于记录所有的二进制文件，二进制日志文件（文件名后缀为.00000*）记录数据库所有的DDL和DML(除了数据查询语句)语句事件。</p>
<h4 id="Binlog的分类"><a href="#Binlog的分类" class="headerlink" title="Binlog的分类"></a>Binlog的分类</h4><blockquote>
<p>  <a href="https://www.jianshu.com/p/8e7e288c41b1">参考博客</a></p>
</blockquote>
<p>binlog的格式也有三种：<code>STATEMENT</code>、<code>ROW</code>、<code>MIXED</code>。</p>
<ul>
<li><code>STATMENT</code>模式：基于SQL语句的复制(statement-based replication, SBR)，每一条会修改数据的sql语句会记录到binlog中。<br>  优点：不需要记录每一条SQL语句与每行的数据变化，这样子binlog的日志也会比较少，减少了磁盘IO，提高性能。<br>  缺点：在某些情况下会导致master-slave中的数据不一致(比如：<code>delete from t where a&gt;=4 and t_modified&lt;=&#39;2018-11-10&#39; limit 1;</code>在主库执行这个语句的时候，如果使用的是a索引，会删除<code>(4,4,&#39;2018-11-10&#39;)</code>这条记录，如果使用的是t_modified的索引则会删除<code>insert into t values(5,5,&#39;2018-11-09&#39;);</code>所以在执行这条sql语句的时候提示：<br>  <code>Unsafe statement written to the binary log using statement format since BINLOG_FORMAT = STATEMENT. The statement is unsafe because it uses a LIMIT clause. This is unsafe because the set of rows included cannot be predicted.</code><br>  由于 statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：在主库执行这条 SQL 语句的时候，用的是索引 a；而在备库执行这条 SQL 语句的时候，却使用了索引 t_modified。因此，MySQL 认为这样写是有风险的。<br>  <code>sleep()</code>函数， <code>last_insert_id()</code>，以及<code>user-defined functions(udf)</code>等也会出现问题)；</li>
<li><code>ROW</code>基于行的复制(row-based replication, RBR)格式：不记录每一条SQL语句的上下文信息，仅需记录哪条数据被修改了，修改成了什么样子了。<br>  优点：不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题。<br>  缺点：会产生大量的日志，尤其是alter table的时候会让日志暴涨。</li>
<li>  <code>MIXED</code>混合模式复制(mixed-based replication, MBR)：以上两种模式的混合使用，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog，MySQL会根据执行的SQL语句选择日志保存方式。</li>
</ul>
<blockquote>
<p>  可以看到<code>ROW</code>模式下，binlog日志中的begin和commit之间并没有sql语句。<br>  在<code>STATEMENT</code>模式下，binlog日志中的begin和commit之间是一条sql语句。</p>
</blockquote>
<h3 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h3><p>详情见：  <a href="../%E7%90%86%E8%AE%BA/%E6%9C%AC%E5%9C%B0%E4%BA%8B%E5%8A%A1.md">本地事务.md</a> </p>
<h2 id="主从同步"><a href="#主从同步" class="headerlink" title="主从同步"></a>主从同步</h2><h3 id="主服务器配置"><a href="#主服务器配置" class="headerlink" title="主服务器配置"></a>主服务器配置</h3><p>配置：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">$ vim my.cnf</span><br><span class="line">#主数据库端ID号</span><br><span class="line">server_id <span class="operator">=</span> <span class="number">1</span>           </span><br><span class="line"> #开启二进制日志                  </span><br><span class="line">log<span class="operator">-</span>bin <span class="operator">=</span> mysql<span class="operator">-</span>bin    </span><br><span class="line">#需要复制的数据库名，如果复制多个数据库，重复设置这个选项即可                  </span><br><span class="line">binlog<span class="operator">-</span>do<span class="operator">-</span>db <span class="operator">=</span> db        </span><br><span class="line">#将从服务器从主服务器收到的更新记入到从服务器自己的二进制日志文件中                 </span><br><span class="line">log<span class="operator">-</span>slave<span class="operator">-</span>updates                        </span><br><span class="line">#控制binlog的写入频率。每执行多少次事务写入一次(这个参数性能消耗很大，但可减小MySQL崩溃造成的损失) </span><br><span class="line">sync_binlog <span class="operator">=</span> <span class="number">1</span>                    </span><br><span class="line">#这个参数一般用在主主同步中，用来错开自增值, 防止键值冲突</span><br><span class="line">auto_increment_offset <span class="operator">=</span> <span class="number">1</span>           </span><br><span class="line">#这个参数一般用在主主同步中，用来错开自增值, 防止键值冲突</span><br><span class="line">auto_increment_increment <span class="operator">=</span> <span class="number">1</span>            </span><br><span class="line">#二进制日志自动删除的天数，默认值为<span class="number">0</span>,表示“没有自动删除”，启动时和二进制日志循环时可能删除  </span><br><span class="line">expire_logs_days <span class="operator">=</span> <span class="number">7</span>                    </span><br><span class="line">#将函数复制到slave  </span><br><span class="line">log_bin_trust_function_creators <span class="operator">=</span> <span class="number">1</span>  </span><br></pre></td></tr></table></figure>

<p>授权：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 允许从服务器同步数据的账户 <span class="keyword">user</span> <span class="number">123456</span></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">GRANT</span> replication slave <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="keyword">user</span>@<span class="string">&#x27;192.168.64.23&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;123456&#x27;</span>;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> master status; # 查看主服务器状态，获取到日志名和偏移量</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  <code>show master status</code>获取到日志名和偏移量，在从数据库启动后从这个点开始进行数据恢复。</p>
</blockquote>
<h3 id="从服务器配置"><a href="#从服务器配置" class="headerlink" title="从服务器配置"></a>从服务器配置</h3><p>配置：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">$ vim my.cnf</span><br><span class="line">server_id <span class="operator">=</span> <span class="number">2</span></span><br><span class="line">log<span class="operator">-</span>bin <span class="operator">=</span> mysql<span class="operator">-</span>bin</span><br><span class="line">log<span class="operator">-</span>slave<span class="operator">-</span>updates</span><br><span class="line">sync_binlog <span class="operator">=</span> <span class="number">0</span></span><br><span class="line">#log buffer将每秒一次地写入log file中，并且log file的flush(刷到磁盘)操作同时进行。该模式下在事务提交的时候，不会主动触发写入磁盘的操作</span><br><span class="line">innodb_flush_log_at_trx_commit <span class="operator">=</span> <span class="number">0</span>        </span><br><span class="line">#指定slave要复制哪个库</span><br><span class="line">replicate<span class="operator">-</span>do<span class="operator">-</span>db <span class="operator">=</span> db         </span><br><span class="line">#MySQL主从复制的时候，当Master和Slave之间的网络中断，但是Master和Slave无法察觉的情况下（比如防火墙或者路由问题）。Slave会等待slave_net_timeout设置的秒数后，才能认为网络出现故障，然后才会重连并且追赶这段时间主库的数据</span><br><span class="line">slave<span class="operator">-</span>net<span class="operator">-</span>timeout <span class="operator">=</span> <span class="number">60</span>                    </span><br><span class="line">log_bin_trust_function_creators <span class="operator">=</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>执行同步：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> change master <span class="keyword">to</span> master_user<span class="operator">=</span><span class="string">&#x27;user&#x27;</span>,   # 授权用户</span><br><span class="line">     <span class="operator">&gt;</span> master_password<span class="operator">=</span><span class="string">&#x27;123456&#x27;</span>,</span><br><span class="line">     <span class="operator">&gt;</span> master_host<span class="operator">=</span><span class="string">&#x27;192.168.64.23&#x27;</span>,           # 主服务器地址</span><br><span class="line">     <span class="operator">&gt;</span> master_log_file<span class="operator">=</span><span class="string">&#x27;mysql-bin.000003&#x27;</span>,    # 主服务器使用的二进制日志（）</span><br><span class="line">     <span class="operator">&gt;</span> master_log_pos<span class="operator">=</span><span class="string">&#x27;257&#x27;</span>;                  # 主服务器日志偏移量</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">start</span> slave;                 # 开启同步    </span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> slave status\G;         # 查看从服务器的内容</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">               Slave_IO_State: Waiting <span class="keyword">for</span> master <span class="keyword">to</span> send event</span><br><span class="line">                  Master_Host: <span class="number">10.10</span><span class="number">.20</span><span class="number">.111</span></span><br><span class="line">                  Master_User: account</span><br><span class="line">                  Master_Port: <span class="number">3306</span></span><br><span class="line">                Connect_Retry: <span class="number">60</span></span><br><span class="line">              Master_Log_File: mysql<span class="operator">-</span>bin<span class="number">.000033</span></span><br><span class="line">          Read_Master_Log_Pos: <span class="number">337523</span></span><br><span class="line">               Relay_Log_File: db2<span class="operator">-</span>relay<span class="operator">-</span>bin<span class="number">.000002</span></span><br><span class="line">                Relay_Log_Pos: <span class="number">337686</span></span><br><span class="line">        Relay_Master_Log_File: mysql<span class="operator">-</span>bin<span class="number">.000033</span></span><br><span class="line">             Slave_IO_Running: Yes</span><br><span class="line">            Slave_SQL_Running: Yes</span><br><span class="line">              Replicate_Do_DB:</span><br><span class="line">          Replicate_Ignore_DB:</span><br><span class="line">          ...</span><br><span class="line"># Slave_IO_Running及Slave_SQL_Running进程必须正常运行，即Yes状态，否则说明同步失败</span><br></pre></td></tr></table></figure>

<h2 id="其他配置"><a href="#其他配置" class="headerlink" title="其他配置"></a>其他配置</h2><h3 id="开启远程访问权限"><a href="#开启远程访问权限" class="headerlink" title="开启远程访问权限"></a>开启远程访问权限</h3><h4 id="一、开启mysql远程访问"><a href="#一、开启mysql远程访问" class="headerlink" title="一、开启mysql远程访问"></a>一、开启mysql远程访问</h4><p>授予用户user 密码 passwd 所有权限 所有主机IP可访问</p>
<ul>
<li>授权语句：Grant &lt;权限&gt; on 表名[(列名)] to 用户 With grant option或 GRANT &lt;权限&gt; ON &lt;数据对象&gt; FROM &lt;数据库用户&gt;</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;user&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;passwd&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br></pre></td></tr></table></figure>

<ul>
<li>ALL PRIVILEGES表示所有权限，*.*表示所有数据库和表，<code>%</code>表示所有IP，WITH GRANT OPTION授予授权权限,如果想让授权的用户，也可以将这些权限 grant 给其他用户，需要选项 “grant option“。<br>  只能访问数据库gogs的所有权</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> gogs.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;user2&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;passwd2&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br></pre></td></tr></table></figure>

<p>分别授予用户所有主机IP可访问，分别拥有增删改查权限</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">select</span> <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;user1&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;passwd1&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">insert</span> <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;user2&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;passwd2&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br><span class="line"><span class="keyword">GRANT</span> updata <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;user3&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;passwd3&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">delete</span> <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;user4&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;passwd4&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br></pre></td></tr></table></figure>

<p>查询用户具有的权限,因为只给了查询权限，所以只有Select_priv: Y。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">GRANT</span> <span class="keyword">select</span> <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;user&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;passwd&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected, <span class="number">1</span> warning (<span class="number">0.02</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> mysql.user <span class="keyword">where</span> <span class="keyword">user</span><span class="operator">=</span><span class="string">&#x27;user&#x27;</span>\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">                  Host: <span class="operator">%</span></span><br><span class="line">                  <span class="keyword">User</span>: <span class="keyword">user</span></span><br><span class="line">           Select_priv: Y</span><br><span class="line">           Insert_priv: N</span><br><span class="line">           Update_priv: N</span><br><span class="line">           Delete_priv: N</span><br><span class="line">           Create_priv: N</span><br><span class="line">             Drop_priv: N</span><br><span class="line">       </span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">ERROR: </span><br><span class="line"><span class="keyword">No</span> query specified</span><br></pre></td></tr></table></figure>

<h4 id="二、撤销已经赋予给-MySQL-用户权限的权限。"><a href="#二、撤销已经赋予给-MySQL-用户权限的权限。" class="headerlink" title="二、撤销已经赋予给 MySQL 用户权限的权限。"></a>二、撤销已经赋予给 MySQL 用户权限的权限。</h4><p>revoke 跟 grant 的语法差不多，只需要把关键字 “to” 换成 “from” 即可：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">on</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">to</span> dba<span class="variable">@localhost</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">revoke</span> <span class="keyword">all</span> <span class="keyword">on</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">from</span> dba<span class="variable">@localhost</span>; </span><br></pre></td></tr></table></figure>

<p>grant, revoke 用户权限后，该用户只有重新连接 MySQL 数据库，权限才能生效。</p>
<h3 id="三、对数据库开启只读权限，用于数据库热备份"><a href="#三、对数据库开启只读权限，用于数据库热备份" class="headerlink" title="三、对数据库开启只读权限，用于数据库热备份"></a>三、对数据库开启只读权限，用于数据库热备份</h3><p>1、 对于MySQL单实例数据库和master库，如果需要设置为只读状态，需要进行如下操作和设置：<br>将MySQL设置为只读状态的命令:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> <span class="keyword">global</span> variables <span class="keyword">like</span> &quot;%read_only%&quot;;</span><br><span class="line">mysql<span class="operator">&gt;</span> flush tables <span class="keyword">with</span> read lock;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">set</span> <span class="keyword">global</span> read_only<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> <span class="keyword">global</span> variables <span class="keyword">like</span> &quot;%read_only%&quot;;</span><br></pre></td></tr></table></figure>

<p>将MySQL从只读状态设置为读写状态的命令:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> unlock tables;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">set</span> <span class="keyword">global</span> read_only<span class="operator">=</span><span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>2)、对于需要保证master-slave主从同步的salve库<br>将slave从库设置为只读状态，需要执行的命令为:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">set</span> <span class="keyword">global</span> read_only<span class="operator">=</span><span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p>将salve库从只读状态变为读写状态，需要执行的命令是:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">set</span> <span class="keyword">global</span> read_only<span class="operator">=</span><span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<h3 id="授权"><a href="#授权" class="headerlink" title="授权"></a>授权</h3><h4 id="授权格式："><a href="#授权格式：" class="headerlink" title="授权格式："></a>授权格式：</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="operator">&lt;</span>privileges<span class="operator">&gt;</span> <span class="keyword">ON</span> <span class="operator">&lt;</span>dbName.tableName<span class="operator">&gt;</span>  <span class="keyword">TO</span> <span class="operator">&lt;</span><span class="keyword">user</span><span class="operator">&gt;</span> [IDENTIFIED <span class="keyword">BY</span> &quot;&lt;password&gt;&quot;]  [<span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION];</span><br></pre></td></tr></table></figure>

<h4 id="授权参数讲解："><a href="#授权参数讲解：" class="headerlink" title="授权参数讲解："></a>授权参数讲解：</h4><p><strong>privilegesCode</strong>表示授予的权限类型，常用的有以下几种类型：</p>
<ul>
<li>all privileges：所有权限。</li>
<li>select：读取权限。</li>
<li>delete：删除权限。</li>
<li>update：更新权限。</li>
<li>create：创建权限。</li>
<li>drop：删除数据库、数据表权限。</li>
</ul>
<p><strong>dbName.tableName</strong>表示授予权限的具体库或表，常用的有以下几种选项：</p>
<ul>
<li><p>*.*：授予该数据库服务器所有数据库的权限。</p>
</li>
<li><p>dbName.*：授予dbName数据库所有表的权限。</p>
</li>
<li><p>dbName.dbTable：授予数据库dbName中dbTable表的权限。</p>
</li>
</ul>
<p><strong>username@host</strong> 表示授予的用户以及允许该用户登录的IP地址。其中Host有以下几种类型：</p>
<ul>
<li><strong>localhost：</strong>只允许该用户在本地登录，不能远程登录。</li>
<li><strong>%：</strong>允许在除本机之外的任何一台机器远程登录。</li>
<li><strong>192.168.52.32：</strong>具体的IP表示只允许该用户从特定IP登录。</li>
</ul>
<p><strong>password</strong>指定该用户登录时的面。</p>
<p><strong>flush privileges</strong>表示刷新权限变更。</p>
<h4 id="1、查看所有用户以及授权主机"><a href="#1、查看所有用户以及授权主机" class="headerlink" title="1、查看所有用户以及授权主机"></a>1、查看所有用户以及授权主机</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="keyword">User</span>,Host <span class="keyword">from</span> mysql.user;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-----------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">User</span>   <span class="operator">|</span> Host      <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-----------+</span></span><br><span class="line"><span class="operator">|</span> user2  <span class="operator">|</span> <span class="operator">%</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> zabbix <span class="operator">|</span> <span class="operator">%</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> root   <span class="operator">|</span> localhost <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-----------+</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<h4 id="2、查看某个用户的授权情况"><a href="#2、查看某个用户的授权情况" class="headerlink" title="2、查看某个用户的授权情况"></a>2、查看某个用户的授权情况</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> grants <span class="keyword">for</span> <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Grants <span class="keyword">for</span> root<span class="variable">@localhost</span>                                           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">GRANT</span> PROXY <span class="keyword">ON</span> <span class="string">&#x27;&#x27;</span>@<span class="string">&#x27;&#x27;</span> <span class="keyword">TO</span> <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION        <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------------------------------------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>或者</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> grants <span class="keyword">for</span> <span class="string">&#x27;zabbix&#x27;</span>@<span class="string">&#x27;%&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Grants <span class="keyword">for</span> zabbix@<span class="operator">%</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">GRANT</span> USAGE <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;zabbix&#x27;</span>@<span class="string">&#x27;%&#x27;</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<h4 id="3、授权"><a href="#3、授权" class="headerlink" title="3、授权"></a>3、授权</h4><ul>
<li>授权所有权限</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;user&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;passwd&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br></pre></td></tr></table></figure>

<ul>
<li>授权单个gogs库权限</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> gogs.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;user2&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;passwd2&#x27;</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>授权单个user表权限</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> gogs.user <span class="keyword">TO</span> <span class="string">&#x27;user2&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;passwd2&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br></pre></td></tr></table></figure>

<ul>
<li>单独授权增删改查权限，而不是所有权限</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">grant</span> <span class="keyword">select</span>, <span class="keyword">insert</span>, <span class="keyword">update</span>, <span class="keyword">delete</span> <span class="keyword">on</span> gogs.<span class="operator">*</span> <span class="keyword">to</span> <span class="keyword">user</span>@<span class="string">&#x27;%&#x27;</span>；</span><br></pre></td></tr></table></figure>

<ul>
<li>授权某个固定主机权限</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">grant</span> <span class="keyword">select</span>, <span class="keyword">insert</span>, <span class="keyword">update</span>, <span class="keyword">delete</span> <span class="keyword">on</span> gogs.<span class="operator">*</span> <span class="keyword">to</span> <span class="keyword">user</span>@<span class="string">&#x27;172.16.3.200&#x27;</span>；</span><br></pre></td></tr></table></figure>

<h4 id="4、取消授权"><a href="#4、取消授权" class="headerlink" title="4、取消授权"></a>4、取消授权</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">revoke</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">from</span> <span class="string">&#x27;user&#x27;</span>@<span class="string">&#x27;%&#x27;</span>;</span><br><span class="line">flush  privileges;</span><br></pre></td></tr></table></figure>

<h4 id="5、删除用户"><a href="#5、删除用户" class="headerlink" title="5、删除用户"></a>5、删除用户</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">user</span> <span class="keyword">user</span>@&quot;%&quot;;</span><br></pre></td></tr></table></figure>

<h3 id="快速到出大量数据"><a href="#快速到出大量数据" class="headerlink" title="快速到出大量数据"></a>快速到出大量数据</h3><p>一、导出数据</p>
<p>1、mysqldump</p>
<p>2、重命名压缩</p>
<p>3、scp传输</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">scp msn.sql.zip root@172.105.xx.xx:/root/</span></span><br></pre></td></tr></table></figure>

<p>二、导入数据</p>
<p>1、解压</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">unzip msn.sql.zip</span></span><br></pre></td></tr></table></figure>

<p>2、连接数据库</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -umsn_block -p password</span><br><span class="line">mysql -umsn_mall -p  password</span><br></pre></td></tr></table></figure>

<p>3、设置参数</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">#设置参数</span><br><span class="line"><span class="keyword">set</span> autocommit<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line">use msn_block;</span><br><span class="line"><span class="keyword">START</span> TRANSACTION;</span><br><span class="line">#导入数据库</span><br><span class="line">source <span class="operator">/</span>root<span class="operator">/</span>msn.sql;</span><br><span class="line">#提交事务</span><br><span class="line"><span class="keyword">COMMIT</span>;</span><br></pre></td></tr></table></figure>

<h3 id="单机备份"><a href="#单机备份" class="headerlink" title="单机备份"></a>单机备份</h3><p>mybackup.conf</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">username<span class="operator">=</span>数据库用户名</span><br><span class="line">password<span class="operator">=</span>数据库密码</span><br><span class="line">backupnode<span class="operator">=</span><span class="keyword">full</span></span><br><span class="line">（备份方式）</span><br></pre></td></tr></table></figure>

<p>myback.sh</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">#<span class="operator">/</span>usr<span class="operator">/</span>bin<span class="operator">/</span>env bash</span><br><span class="line">BASEDIR<span class="operator">=</span>&quot;/home&quot;</span><br><span class="line">username<span class="operator">=</span>`cat $&#123;BASEDIR&#125;<span class="operator">/</span>mybackup.conf <span class="operator">|</span> grep &quot;username&quot; <span class="operator">|</span> awk <span class="operator">-</span>F <span class="string">&#x27;=&#x27;</span> <span class="string">&#x27;&#123;print $2&#125;&#x27;</span>`</span><br><span class="line">password<span class="operator">=</span>`cat $&#123;BASEDIR&#125;<span class="operator">/</span>mybackup.conf <span class="operator">|</span> grep &quot;password&quot; <span class="operator">|</span> awk <span class="operator">-</span>F <span class="string">&#x27;=&#x27;</span> <span class="string">&#x27;&#123;print $2&#125;&#x27;</span>`</span><br><span class="line"><span class="type">time</span><span class="operator">=</span>` <span class="type">date</span> <span class="operator">+</span><span class="operator">%</span>Y_<span class="operator">%</span>m_<span class="operator">%</span>d_<span class="operator">%</span>H_<span class="operator">%</span>M_<span class="operator">%</span>S `</span><br><span class="line">db_name<span class="operator">=</span>new_retail_back</span><br><span class="line">dbname<span class="operator">=</span>pro_wallet_back</span><br><span class="line">#db<span class="operator">=</span>fitment_back</span><br><span class="line">#dbb<span class="operator">=</span>wjjx_pro_wallet_back</span><br><span class="line">dbyqf<span class="operator">=</span>yqf_back</span><br><span class="line">dbdmk<span class="operator">=</span>duoduoke</span><br><span class="line">dbgw<span class="operator">=</span>buhuo3</span><br><span class="line">dbwz<span class="operator">=</span>web_duomaike</span><br><span class="line">dbbhpro<span class="operator">=</span>buhuopro</span><br><span class="line">backupdir<span class="operator">=</span>&quot;/mnt/data/mysql&quot;</span><br><span class="line">echo &quot;username and password&quot;</span><br><span class="line">echo $&#123;username&#125;</span><br><span class="line">echo $&#123;password&#125;</span><br><span class="line">echo &quot;begin to backup&quot;</span><br><span class="line">#mysqldump <span class="operator">-</span>hlocalhost <span class="operator">-</span>u$&#123;username&#125; <span class="operator">-</span>p$&#123;password&#125; <span class="operator">-</span>F <span class="comment">--databases new_retail | gzip &gt; $backupdir/$db_name$time.sql.gz</span></span><br><span class="line">mysqldump <span class="operator">-</span>hlocalhost <span class="operator">-</span>u$&#123;username&#125; <span class="operator">-</span>p$&#123;password&#125; <span class="comment">--databases pro_wallet | gzip &gt; $backupdir/$dbname$time.sql.gz</span></span><br><span class="line">mysqldump <span class="operator">-</span>hlocalhost <span class="operator">-</span>u$&#123;username&#125; <span class="operator">-</span>p$&#123;password&#125; <span class="comment">--databases yqf | gzip &gt; $backupdir/$dbyqf$time.sql.gz</span></span><br><span class="line">mysqldump <span class="operator">-</span>hlocalhost <span class="operator">-</span>u$&#123;username&#125; <span class="operator">-</span>p$&#123;password&#125; <span class="comment">--databases duoduoke | gzip &gt; $backupdir/$dbdmk$time.sql.gz</span></span><br><span class="line">mysqldump <span class="operator">-</span>hlocalhost <span class="operator">-</span>u$&#123;username&#125; <span class="operator">-</span>p$&#123;password&#125; <span class="comment">--databases buhuo3 | gzip &gt; $backupdir/$dbgw$time.sql.gz</span></span><br><span class="line">mysqldump <span class="operator">-</span>hlocalhost <span class="operator">-</span>u$&#123;username&#125; <span class="operator">-</span>p$&#123;password&#125; <span class="comment">--databases web_duomaike | gzip &gt; $backupdir/$dbwz$time.sql.gz</span></span><br><span class="line">mysqldump <span class="operator">-</span>hlocalhost <span class="operator">-</span>u$&#123;username&#125; <span class="operator">-</span>p$&#123;password&#125; <span class="comment">--databases buhuopro | gzip &gt; $backupdir/$dbbhpro$time.sql.gz</span></span><br><span class="line">#删除三天之前的备份</span><br><span class="line">#find <span class="operator">/</span>home<span class="operator">/</span>data<span class="operator">/</span>mysql <span class="operator">-</span>name $db_name&quot;*.sql.gz&quot; <span class="operator">-</span>type f <span class="operator">-</span>mtime <span class="number">2</span> <span class="operator">-</span><span class="keyword">exec</span> rm <span class="operator">-</span>rf &#123;&#125; \; <span class="operator">&gt;</span> <span class="operator">/</span>dev<span class="operator">/</span><span class="keyword">null</span> <span class="number">2</span><span class="operator">&gt;</span><span class="operator">&amp;</span><span class="number">1</span></span><br><span class="line">find <span class="operator">/</span>mnt<span class="operator">/</span>data<span class="operator">/</span>mysql <span class="operator">-</span>name $dbname&quot;*.sql.gz&quot; <span class="operator">-</span>type f <span class="operator">-</span>mtime <span class="number">2</span> <span class="operator">-</span><span class="keyword">exec</span> rm <span class="operator">-</span>rf &#123;&#125; \; <span class="operator">&gt;</span> <span class="operator">/</span>dev<span class="operator">/</span><span class="keyword">null</span> <span class="number">2</span><span class="operator">&gt;</span><span class="operator">&amp;</span><span class="number">1</span></span><br><span class="line">find <span class="operator">/</span>mnt<span class="operator">/</span>data<span class="operator">/</span>mysql <span class="operator">-</span>name $dbyqf&quot;*.sql.gz&quot; <span class="operator">-</span>type f <span class="operator">-</span>mtime <span class="number">2</span> <span class="operator">-</span><span class="keyword">exec</span> rm <span class="operator">-</span>rf &#123;&#125; \; <span class="operator">&gt;</span> <span class="operator">/</span>dev<span class="operator">/</span><span class="keyword">null</span> <span class="number">2</span><span class="operator">&gt;</span><span class="operator">&amp;</span><span class="number">1</span></span><br><span class="line">find <span class="operator">/</span>mnt<span class="operator">/</span>data<span class="operator">/</span>mysql <span class="operator">-</span>name $dbdmk&quot;*.sql.gz&quot; <span class="operator">-</span>type f <span class="operator">-</span>mtime <span class="number">2</span> <span class="operator">-</span><span class="keyword">exec</span> rm <span class="operator">-</span>rf &#123;&#125; \; <span class="operator">&gt;</span> <span class="operator">/</span>dev<span class="operator">/</span><span class="keyword">null</span> <span class="number">2</span><span class="operator">&gt;</span><span class="operator">&amp;</span><span class="number">1</span></span><br><span class="line">find <span class="operator">/</span>mnt<span class="operator">/</span>data<span class="operator">/</span>mysql <span class="operator">-</span>name $dbgw&quot;*.sql.gz&quot; <span class="operator">-</span>type f <span class="operator">-</span>mtime <span class="number">2</span> <span class="operator">-</span><span class="keyword">exec</span> rm <span class="operator">-</span>rf &#123;&#125; \; <span class="operator">&gt;</span> <span class="operator">/</span>dev<span class="operator">/</span><span class="keyword">null</span> <span class="number">2</span><span class="operator">&gt;</span><span class="operator">&amp;</span><span class="number">1</span></span><br><span class="line">find <span class="operator">/</span>mnt<span class="operator">/</span>data<span class="operator">/</span>mysql <span class="operator">-</span>name $dbwz&quot;*.sql.gz&quot; <span class="operator">-</span>type f <span class="operator">-</span>mtime <span class="number">2</span> <span class="operator">-</span><span class="keyword">exec</span> rm <span class="operator">-</span>rf &#123;&#125; \; <span class="operator">&gt;</span> <span class="operator">/</span>dev<span class="operator">/</span><span class="keyword">null</span> <span class="number">2</span><span class="operator">&gt;</span><span class="operator">&amp;</span><span class="number">1</span></span><br><span class="line">find <span class="operator">/</span>mnt<span class="operator">/</span>data<span class="operator">/</span>mysql <span class="operator">-</span>name $dbbhpro&quot;*.sql.gz&quot; <span class="operator">-</span>type f <span class="operator">-</span>mtime <span class="number">2</span> <span class="operator">-</span><span class="keyword">exec</span> rm <span class="operator">-</span>rf &#123;&#125; \; <span class="operator">&gt;</span> <span class="operator">/</span>dev<span class="operator">/</span><span class="keyword">null</span> <span class="number">2</span><span class="operator">&gt;</span><span class="operator">&amp;</span><span class="number">1</span></span><br><span class="line">#删除一分钟之前的备份</span><br><span class="line">#find $backup_dir <span class="operator">-</span>name $db_name&quot;*.sql.gz&quot; <span class="operator">-</span>type f <span class="operator">-</span>mmin <span class="operator">+</span><span class="number">1</span> <span class="operator">-</span><span class="keyword">exec</span> rm <span class="operator">-</span>rf &#123;&#125; \; <span class="operator">&gt;</span> <span class="operator">/</span>dev<span class="operator">/</span><span class="keyword">null</span> <span class="number">2</span><span class="operator">&gt;</span><span class="operator">&amp;</span><span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>异地备份<br>remote_backup.sh</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">#！bin<span class="operator">/</span>bash</span><br><span class="line">#The author : RoES</span><br><span class="line">#<span class="type">date</span>:<span class="number">2019</span><span class="operator">/</span><span class="number">6</span><span class="operator">/</span><span class="number">3</span></span><br><span class="line">#Used <span class="keyword">for</span>:mysql remote_backup</span><br><span class="line">#用于数据库异地备份</span><br><span class="line"></span><br><span class="line">basefile<span class="operator">=</span><span class="operator">/</span>mnt<span class="operator">/</span>data<span class="operator">/</span>mysql<span class="operator">/</span></span><br><span class="line">ip<span class="operator">=</span><span class="number">112.74</span><span class="number">.53</span><span class="number">.175</span></span><br><span class="line"></span><br><span class="line"><span class="type">date</span></span><br><span class="line">echo &quot;becoming remote_backup&quot;</span><br><span class="line">echo &quot;---start backup-------&quot;</span><br><span class="line">rsync <span class="operator">-</span>avz <span class="operator">/</span>mnt<span class="operator">/</span>data<span class="operator">/</span>mysql<span class="comment">/* root@112.74.53.175:/home/data/mysql/</span></span><br><span class="line"><span class="comment">echo &quot;backup complete&quot;</span></span><br><span class="line"><span class="comment">exit $?</span></span><br></pre></td></tr></table></figure>

<h3 id="binlog日志"><a href="#binlog日志" class="headerlink" title="binlog日志"></a>binlog日志</h3><h4 id="1、显示mysqlbinlog日志是否开启，以及存储位置"><a href="#1、显示mysqlbinlog日志是否开启，以及存储位置" class="headerlink" title="1、显示mysqlbinlog日志是否开启，以及存储位置"></a>1、显示mysqlbinlog日志是否开启，以及存储位置</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;log_%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<h4 id="2、查看所有binlog日志列表"><a href="#2、查看所有binlog日志列表" class="headerlink" title="2、查看所有binlog日志列表"></a>2、查看所有binlog日志列表</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> master logs;</span><br></pre></td></tr></table></figure>

<h4 id="3、查看master状态，即最后-最新-一个binlog日志的编号名称，及其最后一个操作事件pos结束点-Position-值"><a href="#3、查看master状态，即最后-最新-一个binlog日志的编号名称，及其最后一个操作事件pos结束点-Position-值" class="headerlink" title="3、查看master状态，即最后(最新)一个binlog日志的编号名称，及其最后一个操作事件pos结束点(Position)值"></a>3、查看master状态，即最后(最新)一个binlog日志的编号名称，及其最后一个操作事件pos结束点(Position)值</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> master status;</span><br></pre></td></tr></table></figure>

<h4 id="4、刷新log日志，自此刻开始产生一个新编号的binlog日志文件"><a href="#4、刷新log日志，自此刻开始产生一个新编号的binlog日志文件" class="headerlink" title="4、刷新log日志，自此刻开始产生一个新编号的binlog日志文件"></a>4、刷新log日志，自此刻开始产生一个新编号的binlog日志文件</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> flush logs;</span><br></pre></td></tr></table></figure>

<p>注：每当mysqld服务重启时，会自动执行此命令，刷新binlog日志；在mysqldump备份数据时加 -F 选项也会刷新binlog日志；</p>
<h4 id="5、重置-清空-所有binlog日志"><a href="#5、重置-清空-所有binlog日志" class="headerlink" title="5、重置(清空)所有binlog日志"></a>5、重置(清空)所有binlog日志</h4><p><strong>此命令切勿随便执行。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> reset master;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouese实战</title>
    <url>/2022/7a7f43d783c4/</url>
    <content><![CDATA[<h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><p>ClickHouse 是俄罗斯的Yandex于2016年开源的<strong>列式存储数据库</strong>（DBMS），使用C++语言编写，主要用于在线分析处理查询（OLAP），能够使用<strong>SQL查询实时</strong>生成分析数据报告。</p>
<span id="more"></span>

<p><strong>优点</strong>：</p>
<ol>
<li>  列式存储（适合聚合操作）</li>
<li>  支持SQL语法</li>
<li>  高吞吐写入（LSM Tree、顺序写）</li>
<li>  多种引擎</li>
<li>  数据分区和并行处理（不利于并发查询）</li>
<li>  单表查询快（单表查询优于关联查询）</li>
</ol>
<p><strong>总结</strong>：适合单表查询且qps低的实时聚合查询业务。</p>
<h2 id="二、安装"><a href="#二、安装" class="headerlink" title="二、安装"></a>二、安装</h2><h3 id="1、系统要求"><a href="#1、系统要求" class="headerlink" title="1、系统要求"></a>1、系统要求</h3><p>ClickHouse可以在任何具有x86_64，AArch64或PowerPC64LE CPU架构的Linux，FreeBSD或Mac OS X上运行。</p>
<p>官方预构建的二进制文件通常针对x86_64进行编译，并利用<code>SSE 4.2</code>指令集，因此，除非另有说明，支持它的CPU使用将成为额外的系统需求。下面是检查当前CPU是否支持SSE 4.2的命令:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ grep -q sse4_2 /proc/cpuinfo &amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;SSE 4.2 supported&quot;</span> || <span class="built_in">echo</span> <span class="string">&quot;SSE 4.2 not supported&quot;</span></span><br></pre></td></tr></table></figure>

<p>要在不支持<code>SSE 4.2</code>或<code>AArch64</code>，<code>PowerPC64LE</code>架构的处理器上运行ClickHouse，您应该通过适当的配置调整从<a href="https://clickhouse.com/docs/zh/getting-started/install#from-sources">源代码构建ClickHouse</a>。</p>
<h3 id="2、环境准备"><a href="#2、环境准备" class="headerlink" title="2、环境准备"></a>2、环境准备</h3><p>主机三台：</p>
<table>
<thead>
<tr>
<th>Host</th>
<th>OS</th>
</tr>
</thead>
<tbody><tr>
<td>clinkhouse101</td>
<td>Centos7</td>
</tr>
<tr>
<td>clinkhouse102</td>
<td>Centos7</td>
</tr>
<tr>
<td>clinkhouse103</td>
<td>Centos7</td>
</tr>
<tr>
<td>zookeeper</td>
<td>Centos7</td>
</tr>
</tbody></table>
<p>关闭linux文件数限制</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ vim /etc/security/limits.conf</span><br><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 65536</span><br><span class="line">* soft <span class="built_in">nproc</span> 131072</span><br><span class="line">* hard <span class="built_in">nproc</span> 131072</span><br><span class="line">$ vim /etc/security/limits.d/20-nproc.conf</span><br><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 65536</span><br><span class="line">* soft <span class="built_in">nproc</span> 131072</span><br><span class="line">* hard <span class="built_in">nproc</span> 131072</span><br></pre></td></tr></table></figure>

<p>安装依赖</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install -y libtool</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install -y *unixODBC*</span></span><br></pre></td></tr></table></figure>

<p>取消SELINUX</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vim /etc/selinux/config</span></span><br><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure>

<h3 id="3、安装"><a href="#3、安装" class="headerlink" title="3、安装"></a>3、安装</h3><blockquote>
<p>  <a href="https://clickhouse.com/docs/zh/getting-started/install#from-rpm-packages">官方文档</a></p>
</blockquote>
<p>安装包列表：</p>
<ul>
<li>  <code>clickhouse-common-static</code> — ClickHouse编译的二进制文件。</li>
<li>  <code>clickhouse-server</code> — 创建<code>clickhouse-server</code>软连接，并安装默认配置服务</li>
<li>  <code>clickhouse-client</code> — 创建<code>clickhouse-client</code>客户端工具软连接，并安装客户端配置文件。</li>
<li>  <code>clickhouse-common-static-dbg</code> — 带有调试信息的ClickHouse二进制文件。</li>
</ul>
<p>离线安装：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://packages.clickhouse.com/rpm/stable/clickhouse-client-21.11.11.1-2.noarch.rpm</span><br><span class="line">wget https://packages.clickhouse.com/rpm/stable/clickhouse-common-static-21.11.11.1.x86_64.rpm</span><br><span class="line">wget https://packages.clickhouse.com/rpm/stable/clickhouse-common-static-dbg-21.11.11.1-2.x86_64.rpm</span><br><span class="line">wget https://packages.clickhouse.com/rpm/stable/clickhouse-server-221.11.11.1-2.noarch.rpm</span><br><span class="line"></span><br><span class="line">yum install -y clickhouse-*</span><br></pre></td></tr></table></figure>

<p>在线安装：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum install -y yum-utils</span><br><span class="line">sudo yum-config-manager --add-repo https://packages.clickhouse.com/rpm/clickhouse.repo</span><br><span class="line">sudo yum install -y clickhouse-server clickhouse-client</span><br><span class="line"></span><br><span class="line">sudo /etc/init.d/clickhouse-server start</span><br><span class="line">clickhouse-client # or &quot;clickhouse-client --password&quot; if you set up a password.</span><br></pre></td></tr></table></figure>

<p>如果您想使用最新的版本，请用<code>testing</code>替代<code>stable</code>(我们只推荐您用于测试环境)。<code>prestable</code>有时也可用。</p>
<p>注意： 三台机器都要安装</p>
<h3 id="4、配置"><a href="#4、配置" class="headerlink" title="4、配置"></a>4、配置</h3><h4 id="1、修改-etc-clickhouse-server-config-xml-文件"><a href="#1、修改-etc-clickhouse-server-config-xml-文件" class="headerlink" title="1、修改  /etc/clickhouse-server/config.xml 文件"></a>1、修改  <code>/etc/clickhouse-server/config.xml</code> 文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ vim /etc/clickhouse-server/config.xml</span><br><span class="line">&lt;http_port&gt;9123&lt;/http_port&gt;</span><br><span class="line">&lt;tcp_port&gt;9000&lt;/tcp_port&gt;</span><br><span class="line"><span class="comment"># 打开注释，放开允许本机以外的机器访问</span></span><br><span class="line">&lt;listen_host&gt;::&lt;/listen_host&gt;</span><br><span class="line"><span class="comment"># 数据文件路径配置</span></span><br><span class="line">&lt;path&gt;/var/lib/clickhouse/&lt;/path&gt;</span><br><span class="line"><span class="comment"># 日志文件路径哦配置</span></span><br><span class="line">&lt;<span class="built_in">log</span>&gt;/var/log/clickhouse-server/clickhouse-server.log&lt;/log&gt;</span><br><span class="line">&lt;zookeeper incl=<span class="string">&quot;zookeeper-servers&quot;</span> optional=<span class="string">&quot;true&quot;</span> /&gt;</span><br><span class="line">&lt;macros incl=<span class="string">&quot;macros&quot;</span> optional=<span class="string">&quot;true&quot;</span> /&gt;</span><br><span class="line"><span class="comment"># 修改metrika.xml配置路径</span></span><br><span class="line">&lt;include_from&gt;/etc/clickhouse-server/config.d/metrika.xml&lt;/include_from&gt;</span><br></pre></td></tr></table></figure>

<h4 id="2、创建-etc-clickhouse-server-config-d-metrika-xml文件"><a href="#2、创建-etc-clickhouse-server-config-d-metrika-xml文件" class="headerlink" title="2、创建 /etc/clickhouse-server/config.d/metrika.xml文件"></a>2、创建 <code>/etc/clickhouse-server/config.d/metrika.xml</code>文件</h4><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">yandex</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">remote_servers</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--ck集群名称--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">test_ck_cluster</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 集群分片1 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">shard</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">weight</span>&gt;</span>1<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">internal_replication</span>&gt;</span>true<span class="tag">&lt;/<span class="name">internal_replication</span>&gt;</span></span><br><span class="line">             <span class="comment">&lt;!-- 该分片的副本 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">host</span>&gt;</span>clinkhouse101<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">user</span>&gt;</span>default<span class="tag">&lt;/<span class="name">user</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">password</span>&gt;</span><span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">compression</span>&gt;</span>true<span class="tag">&lt;/<span class="name">compression</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">host</span>&gt;</span>clinkhouse102<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">user</span>&gt;</span>default<span class="tag">&lt;/<span class="name">user</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">password</span>&gt;</span><span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">compression</span>&gt;</span>true<span class="tag">&lt;/<span class="name">compression</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 集群分片2 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">shard</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">weight</span>&gt;</span>1<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">internal_replication</span>&gt;</span>true<span class="tag">&lt;/<span class="name">internal_replication</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 该分片的副本 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">host</span>&gt;</span>clinkhouse102<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">user</span>&gt;</span>default<span class="tag">&lt;/<span class="name">user</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">password</span>&gt;</span><span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">compression</span>&gt;</span>true<span class="tag">&lt;/<span class="name">compression</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">host</span>&gt;</span>clinkhouse103<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">user</span>&gt;</span>default<span class="tag">&lt;/<span class="name">user</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">password</span>&gt;</span><span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">compression</span>&gt;</span>true<span class="tag">&lt;/<span class="name">compression</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 集群分片3 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">shard</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">weight</span>&gt;</span>1<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">internal_replication</span>&gt;</span>true<span class="tag">&lt;/<span class="name">internal_replication</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 该分片的副本 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">host</span>&gt;</span>clinkhouse101<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">user</span>&gt;</span>default<span class="tag">&lt;/<span class="name">user</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">password</span>&gt;</span><span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">compression</span>&gt;</span>true<span class="tag">&lt;/<span class="name">compression</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">host</span>&gt;</span>clinkhouse103<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">user</span>&gt;</span>default<span class="tag">&lt;/<span class="name">user</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">password</span>&gt;</span><span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">compression</span>&gt;</span>true<span class="tag">&lt;/<span class="name">compression</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">test_ck_cluster</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">remote_servers</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- zookeeper --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">zookeeper</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">node</span> <span class="attr">index</span>=<span class="string">&quot;1&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">host</span>&gt;</span>zookeeper<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">port</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">node</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">node</span> <span class="attr">index</span>=<span class="string">&quot;2&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">host</span>&gt;</span>example_host<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">port</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">node</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">node</span> <span class="attr">index</span>=<span class="string">&quot;3&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">host</span>&gt;</span>example_host<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">port</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">node</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">zookeeper</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 注意修改不同机器上的配置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">macros</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">shard</span>&gt;</span>01<span class="tag">&lt;/<span class="name">shard</span>&gt;</span>   <span class="comment">&lt;!--指定的是集群分片信息中的配置，不同机器放的分片数不一样--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">replica</span>&gt;</span>clinkhouse102<span class="tag">&lt;/<span class="name">replica</span>&gt;</span>  <span class="comment">&lt;!--配置当前节点的备份同步节点信息--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">layer</span>&gt;</span>test_ck_cluster<span class="tag">&lt;/<span class="name">layer</span>&gt;</span> <span class="comment">&lt;!--指定我们的集群标志--&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">macros</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">yandex</span>&gt;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>   注意：这里是学习用，生产环境注意分片和副本的配置</p>
<p>   <a href="https://clickhouse.com/docs/zh/operations/server-configuration-parameters/settings">其他配置</a></p>
</blockquote>
<h4 id="3、分片集群配置问题"><a href="#3、分片集群配置问题" class="headerlink" title="3、分片集群配置问题"></a>3、分片集群配置问题</h4><p>副本虽然能够提高数据的可用性，降低丢失风险，但是每台服务器实际上必须容纳全量数据，对数据的横向扩容没有解决。</p>
<p>要解决数据水平切分的问题，需要引入分片的概念。通过分片把一份完整的数据进行切分，不同的分片分布到不同的节点上，再通过Distributed表引擎把数据拼接起来一同使用。</p>
<p>Distributed表引擎本身不存储数据，有点类似于MyCat之于MySql，成为一种中间件，通过分布式逻辑表来写入、分发、路由来操作多台节点不同分片的分布式数据。</p>
<p>注意：ClickHouse的集群是表级别的，实际企业中，大部分做了高可用，但是没有用分片，避免降低查询性能以及操作集群的复杂性。</p>
<h4 id="4、优化"><a href="#4、优化" class="headerlink" title="4、优化"></a>4、优化</h4><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/161242274">集群分片规划</a></p>
<p>  <a href="https://clickhouse.com/docs/zh/operations/tips">官方使用建议</a></p>
</blockquote>
<h2 id="三、操作"><a href="#三、操作" class="headerlink" title="三、操作"></a>三、操作</h2><h3 id="1、启动"><a href="#1、启动" class="headerlink" title="1、启动"></a>1、启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl start clickhouse-server</span></span><br></pre></td></tr></table></figure>

<h3 id="2、连接"><a href="#2、连接" class="headerlink" title="2、连接"></a>2、连接</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">clickhouse-client -m</span></span><br></pre></td></tr></table></figure>

<p><code>-m</code> :可以在命令窗口输入多行命令</p>
<h3 id="3、查询"><a href="#3、查询" class="headerlink" title="3、查询"></a>3、查询</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">clickhouse-client -h clinkhouse101 --port 9000 --multiquery --query=<span class="string">&quot;select * from test&quot;</span></span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>  <a href="https://clickhouse.com/docs/zh/guides/improving-query-performance">优化查询性能</a></p>
</blockquote>
<h3 id="4、创建ReplicatedMergeTree表"><a href="#4、创建ReplicatedMergeTree表" class="headerlink" title="4、创建ReplicatedMergeTree表"></a>4、创建ReplicatedMergeTree表</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> default.test <span class="keyword">ON</span> CLUSTER test_ck_cluster</span><br><span class="line">(</span><br><span class="line">    `id` Int64 <span class="keyword">DEFAULT</span> <span class="number">0</span> COMMENT <span class="string">&#x27;id&#x27;</span>,</span><br><span class="line">    `name` Nullable(String) COMMENT <span class="string">&#x27;名字&#x27;</span>,</span><br><span class="line">    `create_time` Datetime <span class="keyword">DEFAULT</span> toDateTime(now()) COMMENT <span class="string">&#x27;创建时间&#x27;</span>  </span><br><span class="line">)</span><br><span class="line">ENGINE <span class="operator">=</span> ReplicatedMergeTree(<span class="string">&#x27;/clickhouse/tables/replicated/&#123;shard&#125;/test&#x27;</span>, <span class="string">&#x27;&#123;replica&#125;&#x27;</span>)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMMDD(create_time)</span><br><span class="line"><span class="keyword">primary</span> key (id)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id</span><br></pre></td></tr></table></figure>

<p>参数：</p>
<ul>
<li>  <code>/clickhouse/tables/</code> 这一部分指定的是在ZK上创建的路径地址，可随意变换只要记得即可</li>
<li>  <code>&#123;shard&#125;</code> 指的是分片的标志，同一个分片内的所有机器应该保持相同（不然会导致数据不全）。建议使用使用的是集群名+分片名的配置也就是<code>&#123;layer&#125;-&#123;shard&#125;</code>，这里的数据就是在<code>macros</code>中配置的属性</li>
<li>  <code>test</code> 建议使用表名称</li>
<li>  <code>&#123;replica&#125;</code> 参数建议在<code>macros</code>配置成机器的hostname，因为每台机器的hostname都是不一样的，因此就能确保每个表的识别符都是唯一的了</li>
</ul>
<h3 id="5、创建-Distribute-分布式表"><a href="#5、创建-Distribute-分布式表" class="headerlink" title="5、创建 Distribute 分布式表"></a>5、创建 Distribute 分布式表</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> default.test2 <span class="keyword">on</span> cluster test_ck_cluster</span><br><span class="line">(</span><br><span class="line">    `id` Int64 <span class="keyword">DEFAULT</span> <span class="number">0</span> COMMENT <span class="string">&#x27;id&#x27;</span>,</span><br><span class="line">    `name` Nullable(String) COMMENT <span class="string">&#x27;名字&#x27;</span>,</span><br><span class="line">    `create_time` Datetime <span class="keyword">DEFAULT</span> toDateTime(now()) COMMENT <span class="string">&#x27;创建时间&#x27;</span>  </span><br><span class="line">)engine <span class="operator">=</span> Distributed(test_ck_cluster,<span class="keyword">default</span>, test2,rand());</span><br></pre></td></tr></table></figure>

<p>参数：</p>
<ul>
<li>  <code>test_ck_cluster</code> 集群名称</li>
<li>  <code>default</code>    数据库名称</li>
<li>  <code>test2 </code>   表名</li>
<li>  <code>rand()</code>     分片键（可选）。必须是整型数字，如果没有则是配置中的weight权重。</li>
</ul>
<p>注意： Distributed虽然也可以插入，但是主要用于查询。</p>
]]></content>
      <categories>
        <category>Clickhouse</category>
      </categories>
      <tags>
        <tag>Clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>滴滴数据指标体系建设实践（转）</title>
    <url>/2021/15296aba43c3/</url>
    <content><![CDATA[<p><strong>导读</strong>： 指标体系是什么？如何使用 OSM 模型和 AARRR 模型搭建指标体系？如何统一流程、规范化、工具化管理指标体系？本文会对建设的方法论结合滴滴数据指标体系建设实践进行解答分析。</p>
<span id="more"></span>

<h2 id="01-什么是指标体系"><a href="#01-什么是指标体系" class="headerlink" title="01 什么是指标体系"></a>01 什么是指标体系</h2><h3 id="1-指标体系定义"><a href="#1-指标体系定义" class="headerlink" title="1. 指标体系定义"></a>1. 指标体系定义</h3><p>‍指标体系是将零散单点的具有相互联系的指标，系统化的组织起来，通过单点看全局，通过全局解决单点的问题。它主要由指标和体系两部分组成。</p>
<p>指标是指将业务单元细分后量化的度量值，它使得业务目标可描述、可度量、可拆解，它是业务和数据的结合，是统计的基础，也是量化效果的重要依据。</p>
<p>指标主要分为结果型和过程型：</p>
<ul>
<li>  结果型指标</li>
<li>  用于衡量用户发生某个动作后所产生的结果，通常是延后知道的，很难进行干预。结果型指标更多的是监控数据异常，或者是监控某个场景下用户需求是否被满足</li>
<li>  过程型指标</li>
<li>  用户在做某个动作时候所产生的指标，可以通过某些运营策略来影响这个过程指标，从而影响最终的结果，过程型指标更加关注用户的需求为什么被满足或没被满足</li>
</ul>
<p>体系是由不同的维度组成，而维度是指用户观察、思考与表述某事物的“思维角度”，维度是指标体系的核心，没有维度，单纯说指标是没有任何意义的。</p>
<p>维度主要分为定性维度和定量维度，定性维度，主要是偏文字描述类如城市、性别、职业等;定量维度，主要是数值类描述如收入、年龄等，对定量维度需要做数值分组处理。</p>
<h3 id="2-指标体系生命周期"><a href="#2-指标体系生命周期" class="headerlink" title="2. 指标体系生命周期"></a>2. 指标体系生命周期</h3><p>生命周期主要包含定义、生产、消费、下线四个阶段。针对整个生命周期要持续做指标运维、质量保障，同时为了提高指标数据复用度，降低用户使用成本需要做对应的数据运营工作。</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/8bcf9e46784c07c3061fa2yy4288d2ae.png" alt="img"></p>
<h3 id="3-综合使用场景"><a href="#3-综合使用场景" class="headerlink" title="3. 综合使用场景"></a>3. 综合使用场景</h3><p>指标体系主要是结合用户的业务场景来进行使用，多个不同的指标和维度可以组合起来进行业务的综合分析，用户可通过指标的变化看到整体业务的变化，并能够快速发现问题、定位问题。常用的场景一种是决策分析的场景，通过数据看清业务现状进行战略决策支持，另一种是运营分析场景，无论是做用户运营、产品运营还是活动运营都需要各类指标数据的支撑去看清问题、分析问题和指导解决问题。</p>
<h2 id="02-为什么搭建指标体系"><a href="#02-为什么搭建指标体系" class="headerlink" title="02 为什么搭建指标体系"></a>02 为什么搭建指标体系</h2><p><strong>衡量业务发展质量</strong>：</p>
<p>指标体系可以反映业务客观事实，看清业务发展现状，通过指标对业务质量进行衡量，把控业务发展情况，针对发现的业务问题聚焦解决，促进业务有序增长</p>
<p><strong>建立指标因果关系</strong>：</p>
<p>主要明确结果型指标和过程型指标关系，通过结果指标回溯过程指标，找到解决问题的核心原因</p>
<p><strong>指导用户分析工作</strong>：</p>
<p>目的建立产品评估体系、活动效果评估体系、智能运营分析体系</p>
<p><strong>指导基础数据建设</strong>：</p>
<p>明确基础数据建设方向，集中资源，避免过程和结果分析指标数据的遗漏或缺失</p>
<p><strong>指导内容产品建设</strong>：</p>
<p>结合用户的业务场景来进行使用，多个不同的指标和维度可以组合起来进行业务的综合分析，用户可通过指标的变化看到整体业务的变化，并能够快速发现问题、定位问题</p>
<p><strong>统一指标消费口径</strong>：</p>
<p>企业内统一关键指标业务口径及计算口径，统一企业业务目标，实现自上而下目标驱动</p>
<h2 id="03-如何搭建指标体系"><a href="#03-如何搭建指标体系" class="headerlink" title="03 如何搭建指标体系"></a>03 如何搭建指标体系</h2><p>指标体系建设的常用方法是通过场景化进行指标体系的搭建，以用户的视角场景化思考，自上而下业务驱动指标体系建设，所以要在特定场景下做好指标体系建设，需要先选好指标，然后用科学的方法搭建指标体系。</p>
<h3 id="1-科学方法选指标"><a href="#1-科学方法选指标" class="headerlink" title="1. 科学方法选指标"></a>1. 科学方法选指标</h3><p>选指标常用方法是指标分级方法和 OSM 模型。</p>
<p>指标分级主要是指标内容纵向的思考，根据企业战略目标、组织及业务过程进行自上而下的指标分级，对指标进行层层剖析，主要分为三级 T1、T2、T3。</p>
<p><strong>T1 指标：公司战略层面指标</strong></p>
<p>用于衡量公司整体目标达成情况的指标，主要是决策类指标，T1 指标使用通常服务于公司战略决策层</p>
<p><strong>T2 指标：业务策略层面指标</strong></p>
<p>为达成 T1 指标的目标，公司会对目标拆解到业务线或事业群，并有针对性做出一系列运营策略，T2 指标通常反映的是策略结果属于支持性指标同时也是业务线或事业群的核心指标。T2 指标是 T1 指标的纵向的路径拆解，便于 T1 指标的问题定位，T2 指标使用通常服务业务线或事业群</p>
<p><strong>T3 指标：业务执行层面指标</strong></p>
<p>T3 指标是对 T2 指标的拆解，用于定位 T2 指标的问题。T3 指标通常也是业务过程中最多的指标。根据各职能部门目标的不同，其关注的指标也各有差异。T3 指标的使用通常可以指导一线运营或分析人员开展工作，内容偏过程性指标，可以快速引导一线人员做出相应的动作。</p>
<p>例如：成交率的指标分级</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/f7aeeaf7a6bfea39b4b1ccca8230f275.png" alt="img"></p>
<p>OSM 模型（Obejective，Strategy，Measurement）是指标体系建设过程中辅助确定核心的重要方法，包含业务目标、业务策略、业务度量，是指标内容横向的思考。</p>
<ul>
<li>  O</li>
<li>  用户使用产品的目标是什么？产品满足了用户的什么需求？主要从用户视角和业务视角确定目标，原则是切实可行、易理解、可干预、正向有益</li>
<li>  S</li>
<li>  为了达成上述目标我采取的策略是什么？</li>
<li>  M</li>
<li>  这些策略随之带来的数据指标变化有哪些？</li>
</ul>
<p>以滴滴网约车为例，按照 OSM 模型，它的指标是什么样的？</p>
<ul>
<li>  O：用户来使用滴滴这个产品，需求和目标是什么？</li>
<li>  用户需求及目标是便捷、快速打到车，安全到达目的地</li>
</ul>
<p>那如何让用户感受到自己的需求被满足了呢？</p>
<ul>
<li>  S：滴滴做的策略是：</li>
<li>  便捷方面，提供了独立 APP 版本、小程序版本，还可以多渠道打到车，例如在高德、微信、支付宝都有打车入口；起始、目的地地图智能精准定位；最优路线选择等</li>
<li>  快速方面，针对不同人群不同诉求提供了多品类产品选择，例如快车、优享、拼车、出租车等业务，根据早晚高峰提高热点区域运力，减少用户排队时间</li>
<li>  安全方面，司机准入机制，司机合规机制，司机画像</li>
<li>  M：我们需要针对这些策略去做指标，在这里面我们的指标分别是结果指标和过程指标：</li>
<li>  结果指标：渠道转化完成率、乘客取消率、供需比、司机服务分</li>
<li>  过程指标：渠道发单数、渠道完单数、排队乘客数、乘客排队时长、司机好评率、司机接单量、司机取消数等</li>
</ul>
<p>指标选取之后，下面就是最重要的分析维度选择了，前面指标体系定义里讲过维度是指标体系的核心，没有维度，单纯说指标是没有任何意义的。所以维度选择层面主要通过数据分析视角结合实际分析业务场景来确定。例如城市维度、商圈维度、渠道维度、时间维度、用户标签维度等。</p>
<h3 id="2-用分析模型搭建指标体系"><a href="#2-用分析模型搭建指标体系" class="headerlink" title="2. 用分析模型搭建指标体系"></a>2. 用分析模型搭建指标体系</h3><p>在《精益数据分析》一书中给出了两套比较常用的指标体系建设方法论，其中一个就是比较有名的海盗指标法，也就是我们经常听到的 AARRR 海盗模型。海盗模型是用户分析的经典模型，它反映了增长是系统性地贯穿于用户生命周期各个阶段的：用户拉新(Acquisition)、用户激活(Activation)、用户留存(Retention)、商业变现(Revenue)、用户推荐(Referral)。</p>
<p><strong>AARRR 模型</strong></p>
<ul>
<li>  A 拉新</li>
<li>  通过各种推广渠道，以各种方式获取目标用户，并对各种营销渠道的效果评估，不断优化投入策略，降低获客成本。涉及关键指标例如新增注册用户数、激活率、注册转化率、新客留存率、下载量、安装量等</li>
<li>  A 活跃</li>
<li>  活跃用户指真正开始使用了产品提供的价值，我们需要掌握用户的行为数据，监控产品健康程度。这个模块主要反映用户进入产品的行为表现，是产品体验的核心所在。涉及关键指标例如 DAU/MAU 、日均使用时长、启动 APP 时长、启动 APP 次数等</li>
<li>  R 留存</li>
<li>  衡量用户粘性和质量的指标。涉及关键指标例如留存率、流失率等</li>
<li>  R 变现</li>
<li>  主要用来衡量产品商业价值。涉及关键指标例如生命周期价值(LTV)、客单价、GMV 等</li>
<li>  R 推荐</li>
<li>  衡量用户自传播程度和口碑情况。涉及关键指标例如邀请率、裂变系数等</li>
</ul>
<p>可以根据实际业务场景，结合使用 OSM 和 AARRR 模型，来系统性的选择不同阶段所需要的核心数据指标。</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/0e9yy3b440ececfe15909c4e295e28c0.png" alt="img"></p>
<h3 id="3-场景化搭建指标体系"><a href="#3-场景化搭建指标体系" class="headerlink" title="3. 场景化搭建指标体系"></a>3. 场景化搭建指标体系</h3><p>目前阶段互联网业务比较流行的一种通用抽象场景“人、货、场”，实际就是我们日常所说的用户、产品、场景，在通俗点讲就是谁在什么场景下使用了什么产品，不同的商业模式会有不同的组合模式。</p>
<p>以滴滴实际场景为例：哪些场景（此处场景定义为终端，如 Native，微信，支付宝）的什么人（乘客）在平台上使用了哪些货（平台业务线，如快车/专车等），进而为评估用户增长的价值和效果。</p>
<p><strong>“人”的视角</strong></p>
<p>从”人”的视角，我们比较关心的是什么乘客在什么时间打的车，排了多长时间，等了多长时间上车，周期内第几次打车，打车花了多少钱，是否有投诉和取消行为，具体到数据指标主要看发单用户数、完单用户数、客单价、周期内完单订单数、取消订单数、评价订单数等。</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/3c4a65da1b8bd186ec17f8d0af4441f2.png" alt="img"></p>
<p><strong>“货”的视角</strong></p>
<p>从”货”的视角，我们比较关心的就是成交了多少，交易额多少，花了多少，到具体数据指标主要会看 GMV、成交率、取消率指标，在进一步会细分到城市、区域，一级品类、二级品类。数据的效果通过目标对比，横向对比、历史比较等方式进行分析确定。</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/ceb60ff2fd9b77e5e999e941ef9237c1.png" alt="img"></p>
<p><strong>“场”的视角</strong></p>
<p>从”场”的视角，我们比较关心的就是哪个渠道用户点击量大曝光率大，带来了多少新用户，完成多少交易订单，客单价是多少；或者是哪个活动拉新或促活效果怎么样转化率多少，结合场景数据实际情况制定对应策略。</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/yyafc4d3167aba4f74f9088ee3c0192a.png" alt="img"></p>
<p>以上分别从”人”、“货”、”场”三个角度进行了数据指标和分析维度的提炼，下面我们把三类指标结合指标分级方法进行分解关联。</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/8561bfbc8592033a02fc2c958b7d5b6c.png" alt="img"></p>
<h2 id="04-怎么管理指标体系"><a href="#04-怎么管理指标体系" class="headerlink" title="04 怎么管理指标体系"></a>04 怎么管理指标体系</h2><h3 id="1-痛点分析"><a href="#1-痛点分析" class="headerlink" title="1. 痛点分析"></a>1. 痛点分析</h3><p>主要从业务、技术、产品三个视角来看：</p>
<ul>
<li>  业务视角</li>
<li>  业务分析场景指标、维度不明确；</li>
<li>  频繁的需求变更和反复迭代，数据报表臃肿，数据参差不齐；</li>
<li>  用户分析具体业务问题找数据、核对确认数据成本较高。</li>
<li>  技术视角</li>
<li>  指标定义，指标命名混乱，指标不唯一，指标维护口径不一致；</li>
<li>  指标生产，重复建设；数据汇算成本较高；</li>
<li>  指标消费，数据出口不统一，重复输出，输出口径不一致；</li>
<li>  产品视角</li>
<li>  缺乏系统产品化支持从生产到消费数据流没有系统产品层面打通；</li>
</ul>
<h3 id="2-管理目标"><a href="#2-管理目标" class="headerlink" title="2. 管理目标"></a>2. 管理目标</h3><ul>
<li>  技术目标</li>
<li>  统一指标和维度管理，指标命名、计算口径、统计来源唯一， 维度定义规范、维度值一致</li>
<li>  业务目标</li>
<li>  统一数据出口、场景化覆盖</li>
<li>  产品目标</li>
<li>  指标体系管理工具产品化落地；指标体系内容产品化落地支持决策、分析、运营例如决策北极星、智能运营分析产品等</li>
</ul>
<h3 id="3-模型架构"><a href="#3-模型架构" class="headerlink" title="3. 模型架构"></a>3. 模型架构</h3><p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/bc576374e7725219751285c827f132eb.png" alt="img"></p>
<p><strong>业务线</strong>：</p>
<p>业务板块定义原则：业务逻辑层面进行抽象、物理组织架构层面进行细分，可根据实际业务情况进行层级分拆细化，层级分级建议进行最多进行三级分拆，一级细分可公司层面统一规范确定，二级及后续拆分可根据业务线实际业务进行拆分。例如滴滴出行领域业务逻辑层面两轮车和四轮车都属于出行领域可抽象出行业务板块(level 一级)，根据物理组织架构层面在进行细分普惠、网约车、出租车、顺风车（level 二级），后续根据实际业务需求可在细分,网约车可细分独乘、合乘，普惠可细分单车、企业级。</p>
<p><strong>规范定义</strong>：</p>
<ol>
<li> 数据域</li>
<li> 指面向业务分析，将业务过程或者维度进行抽象的集合。其中，业务过程可以概括为一个个不拆分的行为事件，在业务过程之下，可以定义指标；维度，是度量的环境，如乘客呼单事件，呼单类型是维度。为了保障整个体系的生命力，数据域是需要抽象提炼，并且长期维护更新的，变动需执行变更流程。</li>
<li> 业务过程</li>
<li> 指公司的业务活动事件，如，呼单、支付都是业务过程。其中，业务过程不可拆分。</li>
<li> 时间周期</li>
<li> 用来明确统计的时间范围或者时间点，如最近 30 天、自然周、截止当日等。</li>
<li> 修饰类型</li>
<li> 是对修饰词的一种抽象划分。修饰类型从属于某个业务域，如日志域的访问终端类型涵盖 APP 端、PC 端等修饰词。</li>
<li> 修饰词</li>
<li> 指的是统计维度以外指标的业务场景限定抽象，修饰词属于一种修饰类型，如在日志域的访问终端类型下，有修饰词 APP、PC 端等。</li>
<li> 度量/原子指标</li>
<li> 原子指标和度量含义相同，基于某一业务事件行为下的度量，是业务定义中不可再拆分的指标，具有明确业务含义的名称，如支付金额。</li>
<li> 维度</li>
<li> 维度是度量的环境，用来反映业务的一类属性，这类属性的集合构成一个维度，也可以称为实体对象。维度属于一个数据域，如地理维度（其中包括国家、地区、省市等）、时间维度（其中包括年、季、月、周、日等级别内容）。</li>
<li> 维度属性</li>
<li> 维度属性隶属于一个维度，如地理维度里面的国家名称、国家 ID、省份名称等都属于维度属性。</li>
<li> 指标分类</li>
<li> 主要分为原子指标、派生指标、衍生指标</li>
<li> <strong>原子指标</strong></li>
<li> 基于某一业务事件行为下的度量，是业务定义中不可再拆分的指标，具有明确业务含义的名称，如呼单量、交易金额</li>
<li> <strong>派生指标</strong></li>
<li> 是 1 个原子指标+多个修饰词（可选）+时间周期，是原子指标业务统计范围的圈定。派生指标又分以下二种类型：</li>
<li> a. 事务型指标：</li>
<li> 是指对业务过程进行衡量的指标。例如，呼单量、订单支付金额，这类指标需要维护原子指标以及修饰词，在此基础上创建派生指标。</li>
<li> b. 存量型指标：</li>
<li> 是指对实体对象（如司机、乘客）某些状态的统计，例如注册司机总数、注册乘客总数，这类指标需要维护原子指标以及修饰词，在此基础上创建派生指标，对应的时间周期一般为“历史截止当前某个时间”。</li>
<li> <strong>衍生指标</strong></li>
<li> 是在事务性指标和存量型指标的基础上复合成的。主要有比率型、比例型、统计型均值</li>
</ol>
<p><strong>模型设计</strong>：</p>
<p>主要采用维度建模方法进行构建，基础业务明细事实表主要存储维度属性集合和度量/原子指标；分析业务汇总事实表按照指标类别(去重指标、非去重指标)分类存储，非去重指标汇总事实表存储统计维度集合、原子指标或派生指标，去重指标汇总事实表只存储分析实体统计标签集合。</p>
<p>指标体系在数仓物理实现层面主要是结合数仓模型分层架构进行指导建设，滴滴的指标数据主要存储在 DWM 层，作为指标的核心管理层。</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/d18f92yy4b0a24cd3d2c570706c65c63.png" alt="img"></p>
<h3 id="4-指标体系元数据管理"><a href="#4-指标体系元数据管理" class="headerlink" title="4. 指标体系元数据管理"></a>4. 指标体系元数据管理</h3><p><strong>维度管理</strong>：</p>
<p>包括基础信息和技术信息，由不同角色进行维护管理。</p>
<ul>
<li>  基础信息对应维度的业务信息，由业务管理人员、数据产品或 BI 分析师维护，主要包括维度名称、业务定义、业务分类。</li>
<li>  技术信息对应维度的数据信息，由数据研发维护，主要包括是否有维表（是枚举维度还是有独立的物理维表）、是否是日期维、对应 code 英文名称和中文名称、对应 name 英文名称和中文名称。如果维度有维度物理表，则需要和对应的维度物理表绑定，设置 code 和 name 对应的字段。如果维度是枚举维，则需要填写对应的 code 和 name。维度的统一管理，有利于以后数据表的标准化，也便于用户的查询使用。</li>
</ul>
<p><strong>指标管理</strong>：</p>
<p>包括基础信息、技术信息和衍生信息，由不同角色进行维护管理。</p>
<ul>
<li>  基础信息对应指标的业务信息，由业务管理人员、数据产品或 BI 分析师维护，主要包括归属信息(业务板块、数据域、业务过程)，基本信息(指标名称、指标英文名称、指标定义、统计算法说明、指标类型(去重、非去重))，业务场景信息(分析维度，场景描述)；</li>
<li>  技术信息对应指标的物理模型信息，由数据研发进行维护，主要包括对应物理表及字段信息；</li>
<li>  衍生信息对应关联派生或衍生指标信息、关联数据应用和业务场景信息，便于用户查询指标被哪些其它指标和数据应用使用，提供指标血缘分析追查数据来源的能力。</li>
</ul>
<p>原子指标定义归属信息 + 基本信息 + 业务场景信息</p>
<p>派生指标定义时间周期 + 修饰词集合 + 原子指标</p>
<p>修饰类型主要包含类型说明、统计算法说明、数据源(可选)</p>
<h3 id="5-指标体系建设流程"><a href="#5-指标体系建设流程" class="headerlink" title="5. 指标体系建设流程"></a>5. 指标体系建设流程</h3><p><strong>建模流程</strong>：</p>
<p>建模流程主要是从业务视角指导工程师对需求场景涉及的指标进行主题抽象，归类，统一业务术语，减少沟通成本，同时避免后续的指标重复建设。</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/ce96f73213320013a1ff423f7199536d.png" alt="img"></p>
<p>分析数据体系是模型架构中汇总事实表的物理集合，业务逻辑层面根据业务分析对象或场景进行指标体系抽象沉淀。滴滴出行主要是根据分析对象进行主题抽象的，例如司机主题、安全主题、体验主题、城市主题等。指标分类主要是根据实际业务过程进行抽象分类，例如司机交易类指标、司机注册类指标、司机增长类指标等。</p>
<p>基础数据体系是模型架构中明细事实表和基础维度表的物理集合，业务逻辑层面根据实际业务场景进行抽象例如司机合规、乘客注册等，还原业务核心业务过程。</p>
<p><strong>开发流程</strong>：</p>
<p>开发流程是从技术视角指导工程师进行指标体系生产、运维及质量管控，也是数据产品或数据分析师和数仓研发沟通协调的桥梁。</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/13fb657c37e810c26361yyda1eb781d7.png" alt="img"></p>
<h3 id="6-指标体系图谱建设"><a href="#6-指标体系图谱建设" class="headerlink" title="6. 指标体系图谱建设"></a>6. 指标体系图谱建设</h3><p><strong>指标体系图谱概述</strong>：</p>
<p>指标体系图谱也可称为数据分析图谱主要是依据实际业务场景抽象业务分析实体，整合梳理实体涉及的业务分类、分析指标和维度的集合。</p>
<p>建设方法：</p>
<p>主要是通过业务思维、用户视角去构建，把业务和数据紧密关联起来，把指标结构化分类组织</p>
<p>建设目的：</p>
<ul>
<li>  对于用户：</li>
<li>  便于用户能够快速定位所需指标和维度，同时通过业务场景化沉淀指标体系，能够快速触达用户数据诉求</li>
<li>  对于研发：</li>
<li>  利于后续指标生产模型设计、数据内容边界化、数据体系建设迭代量化和数据资产的落地</li>
</ul>
<p><strong>指标体系图谱模型</strong>：</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/ece28162d9e5b9bfcaaec85a1ab27b0a.png" alt="img"></p>
<p><strong>指标体系图谱实例</strong>：</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/4e63e8603b8f7ae920bf6fae414b635c.png" alt="img"></p>
<h2 id="05-指标体系产品化"><a href="#05-指标体系产品化" class="headerlink" title="05 指标体系产品化"></a>05 指标体系产品化</h2><p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/78044316b571e732ba84d95736a89239.png" alt="img"></p>
<p>指标体系涉及的产品集主要是依据其生命周期进行相应建设，通过产品工具打通数据流，实现指标体系统一化、自动化、规范化、流程化管理。因为指标体系建设本质目标是服务业务，实现数据驱动业务价值，所以建设的核心原则是“轻标准、重场景，从管控式到服务式”。通过工具、产品、技术和组织的融合提高用户使用数据效率，加速业务创新迭代。</p>
<p>其中和指标体系方法论强相关产品就是指标字典工具的落地，其产品的定位及价值：</p>
<ul>
<li>  支撑指标管理规范从方法到落地的工具，自动生成规范指标，解决指标名称混乱、指标不唯一的问题，消除数据的二义性</li>
<li>  统一对外提供标准的指标口径和元数据信息</li>
</ul>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/6c0de4d94db4ed845070cbdabff56044.png" alt="img"></p>
<p>工具设计流程 (方法论-&gt;定义-&gt;生产-&gt;消费)</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/2151244ac0682fe19c07530c1efebd06.png" alt="img"></p>
<p>指标定义</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/322bbeec400fb98cbe6e78fc66a84954.png" alt="img"></p>
<p>指标生产</p>
<h2 id="06-结束语"><a href="#06-结束语" class="headerlink" title="06 结束语"></a>06 结束语</h2><p>文章整体介绍了滴滴指标体系建设方法论和工具产品的建设情况，目前指标字典和开发工具已实现流程打通，与数据消费产品的打通后续会通过 DataAPI 方式提供数据服务，规划建设中。指标体系建设方法论和工具已经在滴滴集团内进行推广使用，滴滴网约车、普惠、车服等部门已经开始接入使用，截止目前共有 5000+指标进入指标体系，覆盖公司核心业务板块、88 个数据域、385 个业务过程，52 个业务场景，方法论和工具也会持续迭代实践。</p>
<p><strong>作者介绍</strong>：</p>
<p>曹雷，滴滴高级专家工程师。</p>
<p>专注数据仓库体系化建设，产品化数仓理念推广及实践者。</p>
<p><strong>本文来自 DataFunTalk</strong></p>
<p><strong>原文链接</strong>：</p>
<p>[滴滴数据指标体系建设实践](</p>
]]></content>
      <categories>
        <category>理论</category>
        <category>Bigdata</category>
      </categories>
      <tags>
        <tag>理论</tag>
        <tag>指标体系</tag>
        <tag>Bigdata</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis缓存</title>
    <url>/2019/98c81a33052b/</url>
    <content><![CDATA[<h2 id="一、缓存的使用"><a href="#一、缓存的使用" class="headerlink" title="一、缓存的使用"></a>一、缓存的使用</h2><p>为了提升系统性能，我们一般都会将部分数据放入缓存，加速访问。</p>
<p>适合放入缓存的数据：</p>
<ol>
<li><strong>即时性、数据一致性要求不高的数据</strong>（如分类信息、Cookie）</li>
<li><strong>访问量大且更新频率不高的数据</strong>（读多写少）</li>
</ol>
<p>举例：电商类应用，商品分类、商品列表、物流状态信息等适合加缓存并加一个失效时间</p>
<span id="more"></span>

<h2 id="二、缓存失效问题（缓存穿透、击穿、雪崩）"><a href="#二、缓存失效问题（缓存穿透、击穿、雪崩）" class="headerlink" title="二、缓存失效问题（缓存穿透、击穿、雪崩）"></a>二、缓存失效问题（缓存穿透、击穿、雪崩）</h2><h3 id="1-缓存穿透"><a href="#1-缓存穿透" class="headerlink" title="1. 缓存穿透"></a>1. 缓存穿透</h3><p><strong>描述</strong>：缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。</p>
<p><strong>风险</strong>：利用不存在的数据进行攻击，数据库压力瞬间增大，最终导致崩溃。</p>
<p><strong>解决</strong>：</p>
<ol>
<li><p> 接口层增加校验，如用户鉴权校验，id做基础校验，id&lt;=0的直接拦截；</p>
</li>
<li><p> null结果缓存，并加入短暂过期时间。这样可以防止攻击用户反复用同一个id暴力攻击；</p>
</li>
<li><p> 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。</p>
</li>
</ol>
<h3 id="2-缓存击穿"><a href="#2-缓存击穿" class="headerlink" title="2. 缓存击穿"></a>2. 缓存击穿</h3><p><strong>描述</strong>：缓存击穿是指缓存中的一些热点Key数据失效，这时由于瞬时并发特别高，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。</p>
<p><strong>风险</strong>：数据库压力过大甚至down机。</p>
<p><strong>解决</strong>：</p>
<ol>
<li>设置热点数据永远不过期；</li>
<li>加互斥锁：大量并发只让一个请求去查询数据库，其他请求等待，查到数据放入缓存后释放锁，其他人获取锁后先查缓存，缓存就会有数据，不用去查DB； 最好能根据Key加锁。</li>
</ol>
<p>​       加锁流程： 查询缓存 -&gt; 加锁（设置过期时间） -&gt; 查询缓存 -&gt; 查询数据库 -&gt; 放入缓存 -&gt; 释放锁 -&gt; 返回结果</p>
<h3 id="3-缓存雪崩"><a href="#3-缓存雪崩" class="headerlink" title="3.缓存雪崩"></a>3.缓存雪崩</h3><p><strong>描述</strong>：缓存雪崩是指缓存中大批量数据设置相同的过期时间，导致缓存在每一时刻同时失效，请求全部转到DB，引起数据库压力过大甚至down机。</p>
<p>和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。</p>
<p><strong>风险</strong>：数据库压力过大甚至down机。</p>
<p><strong>解决</strong>：</p>
<ol>
<li>缓存数据的过期时间基础上增加一个随机时间，防止同一时间大量数据过期现象发生。</li>
<li>如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。</li>
<li>设置热点数据（频繁使用的数据）永远不过期。</li>
</ol>
<h2 id="三、缓存数据一致性问题"><a href="#三、缓存数据一致性问题" class="headerlink" title="三、缓存数据一致性问题"></a>三、缓存数据一致性问题</h2><h3 id="1-双写模式"><a href="#1-双写模式" class="headerlink" title="1.双写模式"></a>1.双写模式</h3><p><strong>定义</strong>：数据库写完数据(新增或修改)、写缓存。</p>
<p><strong>问题</strong>：并发修改的时候可能会出现<strong>暂时性的脏数据问题</strong>，但是在数据稳定、缓存过期之后又可以得到最新的正确数据。<strong>双写模式只能保证数据最终一致性</strong>。</p>
<p><strong>例子</strong>：写数据库(线程1) -&gt; 写数据库(线程2) -&gt; 写缓存(线程2) -&gt; 写缓存(线程1)</p>
<p><strong>解决</strong>：加锁（通常加读写锁），写数据库和写缓存整个流程加上锁。并且所有缓存有过期时间。</p>
<h3 id="2-失效模式"><a href="#2-失效模式" class="headerlink" title="2.失效模式"></a>2.失效模式</h3><p><strong>定义</strong>：数据库写完数据(新增或修改)、删除缓存中的数据。</p>
<p><strong>问题</strong>：并发修改的情况下也会出现脏数据问题</p>
<p><strong>解决</strong>：加锁（通常加读写锁）</p>
<h3 id="3-解决缓存一致性问题"><a href="#3-解决缓存一致性问题" class="headerlink" title="3.解决缓存一致性问题"></a>3.解决缓存一致性问题</h3><p>无论是双写模式还是失效模式，高并发情况下都有可能导致缓存的不一致问题。</p>
<p>我们应该通过系统设计来解决。</p>
<ol>
<li>放入缓存的数据不应该是实时性、一致性要求很高的数据，所以给缓存加上过期时间，保证最一致性就行。</li>
<li>实时性、一致性要求高的数据，可以直接查数据库。实在要求放缓存可以采用canal订阅binlog的方式。</li>
</ol>
<p><strong>采用canal订阅binlog的方式可以完美解决缓存不一致问题，但会增加系统设计的复杂性。</strong></p>
<h2 id="四、缓存工具"><a href="#四、缓存工具" class="headerlink" title="四、缓存工具"></a>四、缓存工具</h2><p><strong>本地缓存</strong>：Caffeine 、 Guava Cache</p>
<p><strong>分布式缓存</strong>：redis、memcached</p>
<h2 id="五、分布式锁"><a href="#五、分布式锁" class="headerlink" title="五、分布式锁"></a>五、分布式锁</h2><p>常见实现方案： <code>zookeeper</code>、<code>redis</code></p>
<h4 id="1、zookeeper"><a href="#1、zookeeper" class="headerlink" title="1、zookeeper"></a>1、zookeeper</h4><blockquote>
<p><a href="https://www.jianshu.com/p/51b8280117ca">https://www.jianshu.com/p/51b8280117ca</a></p>
</blockquote>
<p><strong>大致思想</strong>： 每个客户端对某个方法加锁时，在 Zookeeper 上与该方法对应的指定节点的目录下，<strong>生成一个唯一的临时有序节点</strong>。判断是否获取锁的方式很简单，只需要判断有序节点中<strong>序号最小的一个</strong>。当释放锁的时候，只需将这个临时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。</p>
<p>优点：</p>
<ul>
<li>有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题</li>
<li>实现较为简单</li>
</ul>
<p>缺点：</p>
<ul>
<li>性能上不如使用缓存实现的分布式锁，因为每次在创建锁和释放锁的过程中，都要动态创建、销毁临时节点来实现锁功能</li>
<li>需要对Zookeeper的原理有所了解</li>
</ul>
<p><strong>排他锁</strong></p>
<ul>
<li><code>定义锁</code>：通过Zookeeper上的数据节点来表示一个锁。</li>
<li><code>获取锁</code>：客户端通过调用 <code>create</code> 方法创建表示锁的临时节点，可以认为创建成功的客户端获得了锁，同时可以让没有获得锁的节点在该节点上注册Watcher监听，以便实时监听到lock节点的变更情况。</li>
<li><code>释放锁</code>：以下两种情况都可以让锁释放：<pre><code>  1. 当前获得锁的客户端发生宕机或异常，那么Zookeeper上这个临时节点就会被删除；
     2. 正常执行完业务逻辑，客户端主动删除自己创建的临时节点；
</code></pre>
</li>
</ul>
<p><strong>共享锁</strong></p>
<ul>
<li><p><code>定义锁</code>：通过Zookeeper上的数据节点来表示一个锁，是一个类似于 <code>/lockpath/[hostname]-请求类型-序号</code>的临时顺序节点</p>
</li>
<li><p><code>获取锁</code>：客户端通过调用 <code>create</code> 方法创建表示锁的临时顺序节点，如果是读请求，则创建 <code>/lockpath/[hostname]-R-序号</code> 节点，如果是写请求则创建 <code>/lockpath/[hostname]-W-序号</code> 节点</p>
</li>
<li><p><code>判断读写顺序</code>：大概分为4个步骤:</p>
<ol>
<li><p>创建完节点后，获取 <code>/lockpath</code> 节点下的所有子节点，并对该节点注册子节点变更的Watcher监听</p>
</li>
<li><p>确定自己的节点序号在所有子节点中的顺序</p>
</li>
<li><p>对于读请求：1. 如果没有比自己序号更小的子节点，或者比自己序号小的子节点都是读请求，那么表明自己已经成功获取到了共享锁，同时开始执行读取逻辑 2. 如果有比自己序号小的子节点有写请求，那么等待 。</p>
<p> 对于写请求：如果自己不是序号最小的节点，那么等待。</p>
</li>
<li><p>接收到Watcher通知后，重复步骤1)</p>
</li>
</ol>
</li>
<li><p><code>释放锁</code>：与排他锁逻辑一致</p>
</li>
</ul>
<h4 id="2、redis"><a href="#2、redis" class="headerlink" title="2、redis"></a>2、redis</h4><p><strong><code>redis</code>分布式锁一般使用高级封装框架<code>Redisson</code></strong></p>
<blockquote>
<p>redis官方文档： <a href="https://redis.io/topics/distlock">https://redis.io/topics/distlock</a></p>
</blockquote>
<p>1、加锁：使用<code>SETNX</code>原子性加锁，设置过期时间、并为每个竞争锁的节点加上唯一标识（UUID、token）</p>
<p>2、解锁：使用redis官方提供的lua脚本原子性解锁</p>
<p><strong>基于缓存实现分布式锁总结</strong></p>
<p>优点：</p>
<ul>
<li>性能好</li>
</ul>
<p>缺点：</p>
<ul>
<li>实现中需要考虑的因素太多</li>
<li>通过超时时间来控制锁的失效时间并不是十分的靠谱</li>
</ul>
]]></content>
      <categories>
        <category>缓存</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>缓存</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>行列存储</title>
    <url>/2019/ea20320e825a/</url>
    <content><![CDATA[<h2 id="行存储"><a href="#行存储" class="headerlink" title="行存储"></a>行存储</h2><p>传统的关系型数据库，如 Oracle、DB2、MySQL、SQL SERVER 等采用行式存储法(Row-based)，在基于行式存储的数据库中， 数据是按照行数据为基础逻辑存储单元进行存储的， 一行中的数据在存储介质中以连续存储形式存在。</p>
<span id="more"></span>

<p>优点：</p>
<ol>
<li>  适合随机的增删改查操作;</li>
<li>  需要在行中选取所有属性的查询操作;</li>
<li>  需要频繁插入或更新的操作，其操作与索引和行的大小更为相关。</li>
<li>  适合OLTP场景</li>
</ol>
<p>缺点：</p>
<ol>
<li>  对于字段较多的表，必须读取每一条完整的行记录，从而使得读取效率大大降低。</li>
<li>  不适合海量数据分析业务</li>
</ol>
<h2 id="列存储"><a href="#列存储" class="headerlink" title="列存储"></a>列存储</h2><p>列式存储(Column-based)是相对于行式存储来说的，新兴的 Hbase、HP Vertica、EMC Greenplum 等分布式数据库均采用列式存储。在基于列式存储的数据库中， 数据是按照列为基础逻辑存储单元进行存储的，一列中的数据在存储介质中以连续存储形式存在。</p>
<p>优点：</p>
<ol>
<li>  海量数据的聚合分析场景（OLAP场景）：</li>
<li>  同一列存放在一起，数据类型相同，则更好的进行压缩，这将比行式存储更节省空间。</li>
<li>  同一列存放在一起，则排序更加方便，基于排序方便，where某一列会更加快。</li>
<li>  查询高效，无需维护索引，查询过程中能够尽量减少无关IO，避免全表扫描。</li>
</ol>
<p>不适用场景：</p>
<ol>
<li> 数据需要频繁更新的交易场景</li>
<li> 表中列属性比较少的小量数据库场景</li>
<li> 不适合做含有删除和更新的实时操作</li>
</ol>
]]></content>
      <categories>
        <category>Bigdata</category>
        <category>理论</category>
      </categories>
      <tags>
        <tag>理论</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title>Git学习</title>
    <url>/2018/21fd2dfe466a/</url>
    <content><![CDATA[<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/git-command.jpg" alt="git-command"></p>
<span id="more"></span>

<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Git 是一个开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。</p>
<p>Git 是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。</p>
<p>Git 与常用的版本控制工具 CVS, Subversion 等不同，它采用了分布式版本库的方式，不必服务器端软件支持。</p>
<h2 id="Git基本架构"><a href="#Git基本架构" class="headerlink" title="Git基本架构"></a>Git基本架构</h2><p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/git-command-20221019214513215.jpg" alt="git-command"></p>
<ul>
<li>Workspace：工作区</li>
<li>Index / Stage：暂存区</li>
<li>Repository：仓库区（或本地仓库）</li>
<li>Remote：远程仓库</li>
</ul>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>MacOS:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">brew install git</span> </span><br></pre></td></tr></table></figure>

<p>Ubuntu:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo apt-get install git</span></span><br></pre></td></tr></table></figure>

<p>Centos:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum install -y git</span></span><br></pre></td></tr></table></figure>

<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>Git 系统配置文件位置： <code>/etc/.gitconfig</code>，用户配置文件位置：<code>~/.gitconfig</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置密钥</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ssh-keygen -t rsa -C <span class="string">&quot;your_email@example.com&quot;</span></span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打开Github Account Settings &gt; Add SSH Key</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ssh -T git@github.com</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看当前生效的配置信息</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git config [--list | -l]</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置提交代码时的用户信息</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git config [--global] user.name <span class="string">&quot;[name]&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git config [--global] user.email <span class="string">&quot;[email address]&quot;</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> 配置日志打印格式，别名 lga / lg</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git config --global alias.lga <span class="string">&quot;log --graph --date=short --pretty=format:&#x27;%C(auto)%h %d %s (%Cgreen%an%Creset) %Cblue%ad%Creset&#x27; --all&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">log</span> --graph --abbrev-commit --decorate --all --format=format:<span class="string">&#x27;%C(bold blue)%h%C(reset) - %C(bold cyan)%aD%C(dim white) - %an%C(reset) %C(bold green)(%ar)%C(reset)%C(bold yellow)%d%C(reset)%n %C(white)%s%C(reset)&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git config --global alias.lg <span class="string">&quot;log --graph --abbrev-commit --decorate --all --format=format:&#x27;%C(bold blue)%h%C(reset) - %C(bold cyan)%aD%C(dim white) - %an%C(reset) %C(bold green)(%ar)%C(reset)%C(bold yellow)%d%C(reset)%n %C(white)%s%C(reset)&#x27;&quot;</span></span></span><br></pre></td></tr></table></figure>

<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在命令行上创建新的存储库</span></span><br><span class="line">echo &quot;# notes&quot; &gt;&gt; README.md</span><br><span class="line">git init</span><br><span class="line">git add README.md</span><br><span class="line">git commit -m &quot;first commit&quot;</span><br><span class="line">git branch -M main   # 分支改名</span><br><span class="line">git remote add origin &lt;URL&gt;    # 绑定</span><br><span class="line">git push -u origin main     # 推送到远程 main</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从命令行推送现有存储库</span></span><br><span class="line">git remote add origin &lt;URL&gt;</span><br><span class="line">git branch -M main</span><br><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure>

<h2 id="文件状态"><a href="#文件状态" class="headerlink" title="文件状态"></a>文件状态</h2><p>Git 文件有三种状态： <strong>已提交（Committed）</strong>、<strong>已修改（Modified）</strong> 和 <strong>已暂存（Staged）</strong>。在加一种<strong>未跟踪（Untracked）</strong>。</p>
<ul>
<li>**未跟踪(Untracked)**表示文件没有加入到git库, 不参与版本控制. 通过<code>git add</code>命令将文件状态变为<code>Staged</code>。</li>
<li>**已修改(Modified)**表示修改了文件，但还没保存到数据库中。</li>
<li>**已暂存(Staged)**表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。</li>
<li>**已提交(Committed / Unmodified)**表示数据已经安全地保存在本地数据库中。</li>
</ul>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/git1.png" alt="git1"></p>
]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes实战</title>
    <url>/2022/af154dba2892/</url>
    <content><![CDATA[<h1 id="一、Kubernetes概述"><a href="#一、Kubernetes概述" class="headerlink" title="一、Kubernetes概述"></a>一、Kubernetes概述</h1><h3 id="1、K8s介绍"><a href="#1、K8s介绍" class="headerlink" title="1、K8s介绍"></a>1、K8s介绍</h3><p>Kubernetes 是一个可移植、可扩展的开源平台，用于管理容器化的工作负载和服务，方便进行声明式配置和自动化。Kubernetes 拥有一个庞大且快速增长的生态系统，其服务、支持和工具的使用范围广泛。</p>
<span id="more"></span>

<h3 id="2、K8s能做什么"><a href="#2、K8s能做什么" class="headerlink" title="2、K8s能做什么"></a>2、K8s能做什么</h3><p>Kubernetes 为你提供了一个可弹性运行分布式系统的框架。 Kubernetes 会满足你的扩展要求、故障转移你的应用、提供部署模式等。 例如，Kubernetes 可以轻松管理系统的 Canary 部署。</p>
<blockquote>
<p>应用部署架构分类：</p>
<ol>
<li>无中心节点架构：GlusterFS</li>
<li>有中心节点架构：HDFS(Yarn) 和 K8S</li>
</ol>
</blockquote>
<p>Kubernetes 为你提供：</p>
<ul>
<li><p><strong>服务发现和负载均衡</strong></p>
<p>  Kubernetes 可以使用 DNS 名称或自己的 IP 地址来曝露容器。 如果进入容器的流量很大， Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。</p>
</li>
<li><p><strong>存储编排</strong></p>
<p>  Kubernetes 允许你自动挂载你选择的存储系统，例如本地存储、公共云提供商等。</p>
</li>
<li><p><strong>自动部署和回滚</strong></p>
<p>  你可以使用 Kubernetes 描述已部署容器的所需状态， 它可以以受控的速率将实际状态更改为期望状态。 例如，你可以自动化 Kubernetes 来为你的部署创建新容器， 删除现有容器并将它们的所有资源用于新容器。</p>
</li>
<li><p><strong>自动完成装箱计算</strong></p>
<p>  你为 Kubernetes 提供许多节点组成的集群，在这个集群上运行容器化的任务。 你告诉 Kubernetes 每个容器需要多少 CPU 和内存 (RAM)。 Kubernetes 可以将这些容器按实际情况调度到你的节点上，以最佳方式利用你的资源。</p>
</li>
<li><p><strong>自我修复</strong></p>
<p>  Kubernetes 将重新启动失败的容器、替换容器、杀死不响应用户定义的运行状况检查的容器， 并且在准备好服务之前不将其通告给客户端。</p>
</li>
<li><p><strong>密钥与配置管理</strong></p>
<p>  Kubernetes 允许你存储和管理敏感信息，例如密码、OAuth 令牌和 ssh 密钥。 你可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。</p>
</li>
</ul>
<blockquote>
</blockquote>
<h3 id="3、K8s不能做什么"><a href="#3、K8s不能做什么" class="headerlink" title="3、K8s不能做什么"></a>3、K8s不能做什么</h3><p><strong>Kubernetes 不是传统的、包罗万象的 PaaS（平台即服务）系统</strong>。 由于 Kubernetes 是在容器级别运行，而非在硬件级别，它提供了 PaaS 产品共有的一些普遍适用的功能， 例如部署、扩展、负载均衡，允许用户集成他们的日志记录、监控和警报方案。 但是，Kubernetes 不是单体式（monolithic）系统，那些默认解决方案都是可选、可插拔的。 Kubernetes 为构建开发人员平台提供了基础，但是在重要的地方保留了用户选择权，能有更高的灵活性。</p>
<p>Kubernetes：</p>
<ul>
<li><p><strong>不限制支持的应用程序类型</strong>。 Kubernetes 旨在支持极其多种多样的工作负载，包括无状态、有状态和数据处理工作负载。 如果应用程序可以在容器中运行，那么它应该可以在 Kubernetes 上很好地运行。</p>
</li>
<li><p><strong>不部署源代码，也不构建你的应用程序</strong>。 持续集成（CI）、交付和部署（CI/CD）工作流取决于组织的文化和偏好以及技术要求。</p>
</li>
<li><p><strong>不提供应用程序级别的服务作为内置服务</strong>，例如中间件（例如消息中间件）、 数据处理框架（例如 Spark）、数据库（例如 MySQL）、缓存、集群存储系统 （例如 Ceph）。这样的组件可以在 Kubernetes 上运行，并且/或者可以由运行在 Kubernetes 上的应用程序通过可移植机制 （例如<a href="https://openservicebrokerapi.org/">开放服务代理</a>）来访问。</p>
</li>
<li><p><strong>不是日志记录、监视或警报的解决方案</strong>。 它集成了一些功能作为概念证明，并提供了收集和导出指标的机制。</p>
</li>
<li><p><strong>不提供也不要求配置用的语言、系统</strong>（例如 jsonnet），它提供了声明性 API， 该声明性 API 可以由任意形式的声明性规范所构成。</p>
</li>
<li><p><strong>不提供也不采用任何全面的机器配置、维护、管理或自我修复系统</strong>。</p>
</li>
<li><p>此外，<strong>Kubernetes 不仅仅是一个编排系统</strong>，实际上它消除了编排的需要。 编排的技术定义是执行已定义的工作流程：首先执行 A，然后执行 B，再执行 C。 而 Kubernetes 包含了一组独立可组合的控制过程，可以连续地将当前状态驱动到所提供的预期状态。 你不需要在乎如何从 A 移动到 C，也不需要集中控制，这使得系统更易于使用 且功能更强大、系统更健壮，更为弹性和可扩展。</p>
</li>
</ul>
<h3 id="4、K8s集群节点主要组件和功能"><a href="#4、K8s集群节点主要组件和功能" class="headerlink" title="4、K8s集群节点主要组件和功能"></a>4、K8s集群节点主要组件和功能</h3><h4 id="4-1-控制平面组件（Control-Plane-Components）"><a href="#4-1-控制平面组件（Control-Plane-Components）" class="headerlink" title="4.1 控制平面组件（Control Plane Components）"></a>4.1 控制平面组件（Control Plane Components）</h4><p>控制平面组件也叫Master组件，对集群进行<strong>资源调度</strong>、以及<strong>检测</strong>和<strong>响应</strong>集群事件。</p>
<p>Master节点主要由<code>kube-apiserver</code>、<code>etcd</code>、<code>kube-scheduler</code>、<code>kube-controller-manager</code>、<code>cloud-controller-manager</code>所组成。</p>
<h4 id="4-2-Node-组件"><a href="#4-2-Node-组件" class="headerlink" title="4.2 Node 组件"></a>4.2 Node 组件</h4><p>集群工作节点，负责维护运行的 Pod 并提供 Kubernetes 运行环境。</p>
<p>Node节点主要由<code>kubelet</code>、<code>kube-proxy</code>、容器运行时环境（Container Runtime）组成。</p>
<h1 id="二、K8s集群搭建"><a href="#二、K8s集群搭建" class="headerlink" title="二、K8s集群搭建"></a>二、K8s集群搭建</h1><blockquote>
<p>K8s常见安装方式有工具部署和二进制包部署，本教程以官方部署工具Kubeadm进行部署。</p>
<ol>
<li>工具部署：Kubeadm（官方工具）、Kops、Kubespray</li>
<li>二进制包部署：官方下载二进制包手动编译部署。</li>
</ol>
</blockquote>
<h3 id="1、搭建准备"><a href="#1、搭建准备" class="headerlink" title="1、搭建准备"></a>1、搭建准备</h3><ul>
<li>准备多台机器（操作系统Centos7）</li>
<li>配置好网络（可以翻墙，国内太慢）</li>
<li>禁止swap分区</li>
</ul>
<h3 id="2、系统初始化"><a href="#2、系统初始化" class="headerlink" title="2、系统初始化"></a>2、系统初始化</h3><h4 id="2-1-关闭防火墙"><a href="#2-1-关闭防火墙" class="headerlink" title="2.1 关闭防火墙"></a>2.1 关闭防火墙</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl stop firewalld</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl <span class="built_in">disable</span> firewalld</span></span><br></pre></td></tr></table></figure>

<h4 id="2-2-关闭selinux"><a href="#2-2-关闭selinux" class="headerlink" title="2.2 关闭selinux"></a>2.2 关闭selinux</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sed -i <span class="string">&#x27;s/enforcing/disabled/&#x27;</span> /etc/selinux/config  <span class="comment"># 永久关闭</span></span> </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">setenforce 0  <span class="comment"># 临时关闭</span></span></span><br></pre></td></tr></table></figure>

<h4 id="2-3-关闭swap"><a href="#2-3-关闭swap" class="headerlink" title="2.3 关闭swap"></a>2.3 关闭swap</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vim /etc/fstab  <span class="comment"># 永久</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">swapoff -a  <span class="comment"># 临时</span></span></span><br></pre></td></tr></table></figure>

<h4 id="2-4-设置主机名"><a href="#2-4-设置主机名" class="headerlink" title="2.4 设置主机名"></a>2.4 设置主机名</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hostnamectl set-hostname &lt;hostname&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="2-5-添加hosts"><a href="#2-5-添加hosts" class="headerlink" title="2.5 添加hosts"></a>2.5 添加hosts</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &gt;&gt; /etc/hosts &lt;&lt; <span class="string">EOF</span></span></span><br><span class="line">192.168.31.61 k8s-master</span><br><span class="line">192.168.31.62 k8s-node1</span><br><span class="line">192.168.31.63 k8s-node2</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h4 id="2-6-将桥接的-IPv4-流量传递到-iptables-的链"><a href="#2-6-将桥接的-IPv4-流量传递到-iptables-的链" class="headerlink" title="2.6 将桥接的 IPv4 流量传递到 iptables 的链"></a>2.6 将桥接的 IPv4 流量传递到 iptables 的链</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &gt; /etc/sysctl.d/k8s.conf &lt;&lt; <span class="string">EOF</span></span> </span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1 </span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sysctl --system # 生效</span></span></span><br></pre></td></tr></table></figure>

<h4 id="2-7-时间同步"><a href="#2-7-时间同步" class="headerlink" title="2.7 时间同步"></a>2.7 时间同步</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install ntpdate -y</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ntpdate time.windows.com</span></span><br></pre></td></tr></table></figure>

<h3 id="3、安装Docker、Kubeadm、Kubelet"><a href="#3、安装Docker、Kubeadm、Kubelet" class="headerlink" title="3、安装Docker、Kubeadm、Kubelet"></a>3、安装Docker、Kubeadm、Kubelet</h3><blockquote>
<p>所有机器都需要安装</p>
</blockquote>
<h4 id="3-1-安装Docker"><a href="#3-1-安装Docker" class="headerlink" title="3.1 安装Docker"></a>3.1 安装Docker</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Step 1: 卸载旧版本</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum remove docker  docker-client docker-client-latest docker-common docker-latest \</span></span><br><span class="line"><span class="language-bash">                  docker-latest-logrotate docker-logrotate \</span></span><br><span class="line"><span class="language-bash">                  docker-engine</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Step 2: 安装依赖包并设置仓库源</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum install -y yum-utils \</span></span><br><span class="line"><span class="language-bash">  device-mapper-persistent-data \</span></span><br><span class="line"><span class="language-bash">  lvm2</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum-config-manager --add-repo \</span></span><br><span class="line"><span class="language-bash">    http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo                <span class="comment"># 阿里云源</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum-config-manager --add-repo \</span></span><br><span class="line"><span class="language-bash">    https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo     <span class="comment"># 清华源</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Step 3：安装Docker CE</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum install -y docker-ce docker-ce-cli containerd.io</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Step 4: 设置开机自启</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl <span class="built_in">enable</span> docker</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl start docker</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Step 5: 验证是否安装成功</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker --version</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置阿里云Docker加速（可选）</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cat</span> &gt; /etc/docker/daemon.json &lt;&lt; <span class="string">EOF &#123;</span></span></span><br><span class="line">&quot;registry-mirrors&quot;: [&quot;https://xxx.mirror.aliyuncs.com&quot;] &#125;         # 登陆自己的阿里云复制链接</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sudo systemctl daemon-reload</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sudo systemctl restart docker</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">配置阿里云yum源（可选）</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sudo cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF</span></span> </span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 </span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg</span><br><span class="line">https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h4 id="3-2-安装kubeadm，kubelet-和-kubectl"><a href="#3-2-安装kubeadm，kubelet-和-kubectl" class="headerlink" title="3.2 安装kubeadm，kubelet 和 kubectl"></a>3.2 安装kubeadm，kubelet 和 kubectl</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install -y kubelet kubeadm kubectl</span>     </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl <span class="built_in">enable</span> kubelet</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl start kubelet</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>  Mac 部署K8s注意调大Docker Desktop资源，网速不好可以手动拉取K8s镜像，但需要注意版本。</p>
</blockquote>
<h3 id="4、部署K8s-Master"><a href="#4、部署K8s-Master" class="headerlink" title="4、部署K8s Master"></a>4、部署K8s Master</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Step 1：在Master节点安装</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果直接执行命令出错或者太慢，可以先手动把镜像拉下来在执行的命令</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubeadm init \</span></span><br><span class="line"><span class="language-bash">--apiserver-advertise-address=10.0.2.15 \                          <span class="comment"># 注意apiserver地址</span></span></span><br><span class="line">--image-repository registry.aliyuncs.com/google_containers \       # aliyun源</span><br><span class="line">--kubernetes-version v1.17.3 \</span><br><span class="line">--service-cidr=10.96.0.0/16 \ </span><br><span class="line">--pod-network-cidr=10.244.0.0/16</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Step 2：启用kubectl</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p <span class="variable">$HOME</span>/.kube</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span> </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">chown</span> $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) <span class="variable">$HOME</span>/.kube/config</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Step 3：安装Pod网站插件（CNI）</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply –f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">watch kubectl get pod -n kube-system -o wide   <span class="comment"># 监控pod进度</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Step 4：使用kubectl工具</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get nodes                          <span class="comment"># 获取所有节点</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get namespaces                     <span class="comment"># 获取所有namespaces</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pods -n &lt;namespaces&gt;           <span class="comment"># 获取所有Pod，可以添加 &lt;--all-namespaces&gt; 参数。</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">手动拉取镜像</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">images=(</span><br><span class="line">	kube-apiserver:v1.17.3</span><br><span class="line">    kube-proxy:v1.17.3</span><br><span class="line">	kube-controller-manager:v1.17.3</span><br><span class="line">	kube-scheduler:v1.17.3</span><br><span class="line">	coredns:1.6.5</span><br><span class="line">	etcd:3.4.3-0</span><br><span class="line">    pause:3.1</span><br><span class="line">)</span><br><span class="line">for imageName in $&#123;images[@]&#125; ; do</span><br><span class="line">    docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/<span class="variable">$imageName</span>  k8s.gcr.io/<span class="variable">$imageName</span></span></span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果直接执行Step 1 命令出错或者太慢，可以先手动把镜像拉下来在执行Step 1 的命令；</p>
<p>更多拓展插件：<a href="https://kubernetes.io/zh-cn/docs/concepts/cluster-administration/addons/">https://kubernetes.io/zh-cn/docs/concepts/cluster-administration/addons/</a>  ；</p>
<p>Step 3安装网络插件如果image拉不下来可以取Docker hub上找一个并修改kube-flannel.yml文件地址；</p>
</blockquote>
<h3 id="5、部署Node节点，并加入K8s集群"><a href="#5、部署Node节点，并加入K8s集群" class="headerlink" title="5、部署Node节点，并加入K8s集群"></a>5、部署Node节点，并加入K8s集群</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">部署Node节点，并将新节点添加到K8s集群，注意修改 IP地址</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubeadm <span class="built_in">join</span> &lt;Master节点IP&gt;:6443 --token esce21.q6hetwm8si29qxwn \</span></span><br><span class="line"><span class="language-bash">--discovery-token-ca-cert-hash sha256:00603a05805807501d7181c3d60b478788408cfe6cedefedb1f97569708be9c5</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果token过期，手动生成token</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubeadm token create --print-join-command</span></span><br></pre></td></tr></table></figure>

<h3 id="6、测试集群-部署一个应用"><a href="#6、测试集群-部署一个应用" class="headerlink" title="6、测试集群(部署一个应用)"></a>6、测试集群(部署一个应用)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Step 1：使用 kubectl 创建Deployment</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl create deployment tomcat6 --image=tomcat:6.0.53-jre8</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Step 2：查看Pods和Nodes</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pods &lt;namespaces&gt;</span>   </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get nodes -o wide      <span class="comment"># -o wide 打印详细信息</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Step 3：使用Service暴露应用</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl expose deployment tomcat6 --port=80 --target-port=8080 --<span class="built_in">type</span>=NodePort</span>   </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get service       <span class="comment"># 查看访问端口</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Step 4：应用伸缩</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl scale --replicas=3 deployment tomcat6</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Step 5：应用更新</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl <span class="built_in">set</span> image deployment.apps/&lt;deployment名称&gt; &lt;容器名称&gt;=&lt;镜像&gt;:&lt;版本&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl <span class="built_in">set</span> image deployment.apps/tomcat7 tomcat7=tomcat:7.0.53-jre8</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Step 6：回滚应用</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get deployment</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl rollout <span class="built_in">history</span> deployment tomcat7                       <span class="comment"># 查看deployment记录</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl rollout <span class="built_in">history</span> deployment tomcat7 --revision=&lt;版本号&gt;    <span class="comment"># 查看版本详细信息</span></span>  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl rollout undo deployment tomcat7 --to-revision=&lt;版本号&gt;    <span class="comment"># 回退到某个版本</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Step 7：其他命令</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl create deployment tomcat6 --image=tomcat:6.0.53-jre8 --dry-run -o yaml    <span class="comment"># 预执行并打印yaml</span></span></span><br></pre></td></tr></table></figure>

<h3 id="7、常用命令"><a href="#7、常用命令" class="headerlink" title="7、常用命令"></a>7、常用命令</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get node -o wide                           <span class="comment"># 获取集群节点</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get ns                                     <span class="comment"># 获取namespaces</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get all --all-namespaces</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pods --all-namespaces                  <span class="comment"># 获取pod</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pod -n kube-system</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get svc -n kube-system                     <span class="comment"># 获取services</span></span></span><br></pre></td></tr></table></figure>

<p>到此K8s集群已经搭建完成。</p>
<h1 id="TUDO"><a href="#TUDO" class="headerlink" title="TUDO"></a>TUDO</h1><p>部署可视化界面、部署helm、部署KubeSphere</p>
<h1 id="三、核心架构"><a href="#三、核心架构" class="headerlink" title="三、核心架构"></a>三、核心架构</h1><blockquote>
<p>K8s 中文文档： <a href="http://docs.kubernetes.org.cn/251.html">http://docs.kubernetes.org.cn/251.html</a></p>
</blockquote>
<h2 id="1、K8s架构"><a href="#1、K8s架构" class="headerlink" title="1、K8s架构"></a>1、K8s架构</h2><p><strong>Kubernetes 协调一个高可用计算机集群，每个计算机作为独立单元互相连接工作。</strong> Kubernetes 中的抽象允许你将容器化的应用部署到集群，而无需将它们绑定到某个特定的独立计算机。为了使用这种新的部署模型，应用需要以将应用与单个主机分离的方式打包：它们需要被容器化。与过去的那种应用直接以包的方式深度与主机集成的部署模型相比，容器化应用更灵活、更可用。 <strong>Kubernetes 以更高效的方式跨集群自动分发和调度应用容器。</strong> Kubernetes 是一个开源平台，并且可应用于生产环境。</p>
<p>一个 Kubernetes 集群包含两种类型的资源:</p>
<ul>
<li><strong>Master</strong> 调度整个集群</li>
<li><strong>Nodes</strong> 负责运行应用</li>
</ul>
<p><img src="../Img/architecture.png" alt="architecture"></p>
<p>Kubernetes主要由以下几个核心组件组成：</p>
<ul>
<li>etcd保存了整个集群的状态；</li>
<li>apiserver提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制；</li>
<li>controller manager负责维护集群的状态，比如故障检测、自动扩展、滚动更新等；</li>
<li>scheduler负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上；</li>
<li>kubelet负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理；</li>
<li>Container runtime负责镜像管理以及Pod和容器的真正运行（CRI）；</li>
<li>kube-proxy负责为Service提供cluster内部的服务发现和负载均衡；</li>
</ul>
<p>除了核心组件，还有一些推荐的Add-ons：</p>
<ul>
<li>kube-dns负责为整个集群提供DNS服务</li>
<li>Ingress Controller为服务提供外网入口</li>
<li>Heapster提供资源监控</li>
<li>Dashboard提供GUI</li>
<li>Federation提供跨可用区的集群</li>
<li>Fluentd-elasticsearch提供集群日志采集、存储与查询</li>
</ul>
<p><img src="../Img/14791969222306.png" alt="img"></p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/14791969311297.png" alt="img"></p>
<p><strong>分层架构</strong></p>
<p>Kubernetes设计理念和功能其实就是一个类似Linux的分层架构，如下图所示</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/14937095836427.jpg" alt="img"></p>
<ul>
<li>核心层：Kubernetes最核心的功能，对外提供API构建高层的应用，对内提供插件式应用执行环境</li>
<li>应用层：部署（无状态应用、有状态应用、批处理任务、集群应用等）和路由（服务发现、DNS解析等）</li>
<li>管理层：系统度量（如基础设施、容器和网络的度量），自动化（如自动扩展、动态Provision等）以及策略管理（<a href="http://docs.kubernetes.org.cn/148.html">RBAC</a>、Quota、PSP、NetworkPolicy等）</li>
<li>接口层：<a href="http://docs.kubernetes.org.cn/61.html">kubectl命令行工具</a>、客户端SDK以及集群联邦</li>
<li>生态系统：在接口层之上的庞大容器集群管理调度的生态系统，可以划分为两个范畴<ul>
<li>Kubernetes外部：日志、监控、配置管理、CI、CD、Workflow、FaaS、OTS应用、ChatOps等</li>
<li>Kubernetes内部：CRI、CNI、CVI、镜像仓库、Cloud Provider、集群自身的配置和管理等</li>
</ul>
</li>
</ul>
<h2 id="2、部署一个应用"><a href="#2、部署一个应用" class="headerlink" title="2、部署一个应用"></a>2、部署一个应用</h2><p>在K8s中部署一个应用的整个过程</p>
<blockquote>
<p>官方文档教学： <a href="https://kubernetes.io/zh-cn/docs/tutorials/kubernetes-basics/">https://kubernetes.io/zh-cn/docs/tutorials/kubernetes-basics/</a></p>
</blockquote>
<h3 id="1、使用-kubectl-创建Deployment"><a href="#1、使用-kubectl-创建Deployment" class="headerlink" title="1、使用 kubectl 创建Deployment"></a>1、使用 kubectl 创建Deployment</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建Deployment</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl create deployment &lt;deployment名称&gt; --image=&lt;镜像名称&gt;:&lt;镜像版本&gt;</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看Deployment</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get deployment</span></span><br></pre></td></tr></table></figure>

<h4 id="Kubernetes-Deployments"><a href="#Kubernetes-Deployments" class="headerlink" title="Kubernetes Deployments"></a>Kubernetes Deployments</h4><p>一旦运行了 Kubernetes 集群，就可以在其上部署容器化应用程序。 为此，你需要创建 Kubernetes <strong>Deployment</strong> 配置。Deployment 指挥 Kubernetes 如何创建和更新应用程序的实例。创建 Deployment 后，Kubernetes master 将应用程序实例调度到集群中的各个节点上。</p>
<p>创建应用程序实例后，Kubernetes Deployment 控制器会持续监视这些实例。 如果托管实例的节点关闭或被删除，则 Deployment 控制器会将该实例替换为集群中另一个节点上的实例。 <strong>这提供了一种自我修复机制来解决机器故障维护问题。</strong></p>
<p>在没有 Kubernetes 这种编排系统之前，安装脚本通常用于启动应用程序，但它们不允许从机器故障中恢复。通过创建应用程序实例并使它们在节点之间运行， Kubernetes Deployments 提供了一种与众不同的应用程序管理方法。</p>
<h4 id="在Kubernetes上部署第一个应用程序"><a href="#在Kubernetes上部署第一个应用程序" class="headerlink" title="在Kubernetes上部署第一个应用程序"></a>在Kubernetes上部署第一个应用程序</h4><p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/module_02_first_app.svg" alt="img"></p>
<p><strong>Master 负责管理整个集群。</strong> Master 协调集群中的所有活动，例如调度应用、维护应用的所需状态、应用扩容以及推出新的更新。</p>
<p><strong>Node 是一个虚拟机或者物理机，它在 Kubernetes 集群中充当工作机器的角色</strong> 每个Node都有 Kubelet , 它管理 Node 而且是 Node 与 Master 通信的代理。 Node 还应该具有用于处理容器操作的工具，例如 Docker 或 rkt 。处理生产级流量的 Kubernetes 集群至少应具有三个 Node，因为如果一个 Node 出现故障其对应的 etcd 成员和控制平面实例都会丢失，并且冗余会受到影响。 你可以通过添加更多控制平面节点来降低这种风险 。</p>
<p><em>Master 管理集群，Node 用于托管正在运行的应用。</em></p>
<p>在 Kubernetes 上部署应用时，你告诉 Master 启动应用容器。 Master 就编排容器在集群的 Node 上运行。 <strong>Node 使用 Master 暴露的 Kubernetes API 与 Master 通信。</strong>终端用户也可以使用 Kubernetes API 与集群交互。</p>
<p>Kubernetes 既可以部署在物理机上也可以部署在虚拟机上。你可以使用 Minikube 开始部署 Kubernetes 集群。 Minikube 是一种轻量级的 Kubernetes 实现，可在本地计算机上创建 VM 并部署仅包含一个节点的简单集群。 Minikube 可用于 Linux ， macOS 和 Windows 系统。Minikube CLI 提供了用于引导集群工作的多种操作，包括启动、停止、查看状态和删除。</p>
<h3 id="2、Pod和Node"><a href="#2、Pod和Node" class="headerlink" title="2、Pod和Node"></a>2、Pod和Node</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f pod.yaml</span></span><br></pre></td></tr></table></figure>

<h4 id="Kubernetes-Pods"><a href="#Kubernetes-Pods" class="headerlink" title="Kubernetes Pods"></a>Kubernetes Pods</h4><p>在创建 Deployment 时, Kubernetes 添加了一个 <strong>Pod</strong> 来托管你的应用实例。Pod 是 Kubernetes 抽象出来的，表示一组一个或多个应用程序容器（如 Docker），以及这些容器的一些共享资源。这些资源包括:</p>
<ul>
<li>共享存储，当作卷</li>
<li>网络，作为唯一的集群 IP 地址</li>
<li>有关每个容器如何运行的信息，例如容器镜像版本或要使用的特定端口。</li>
</ul>
<p>Pod 为特定于应用程序的“逻辑主机”建模，并且可以包含相对紧耦合的不同应用容器。例如，Pod 可能既包含带有 Node.js 应用的容器，也包含另一个不同的容器，用于提供 Node.js 网络服务器要发布的数据。Pod 中的容器共享 IP 地址和端口，始终位于同一位置并且共同调度，并在同一工作节点上的共享上下文中运行。</p>
<p>Pod是 Kubernetes 平台上的原子单元。 当我们在 Kubernetes 上创建 Deployment 时，该 Deployment 会在其中创建包含容器的 Pod （而不是直接创建容器）。每个 Pod 都与调度它的工作节点绑定，并保持在那里直到终止（根据重启策略）或删除。 如果工作节点发生故障，则会在集群中的其他可用工作节点上调度相同的 Pod。</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/module_03_pods.svg" alt="img"></p>
<h4 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h4><p>一个Pod总是在一个<strong>Node节点</strong>上运行，Node是Kubernetes中的工作节点，可以是虚拟机或物理机。每个Node由 Master管理，Node上可以有多个pod，Kubernetes Master会自动处理群集中Node的pod调度，同时Master的自动调度会考虑每个Node上的可用资源。</p>
<p>每个Kubernetes Node上至少运行着：</p>
<ul>
<li>Kubelet，管理Kubernetes Master和Node之间的通信; 管理机器上运行的Pods和containers容器。</li>
<li>container runtime（如Docker，rkt）。</li>
</ul>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/module_03_nodes.svg" alt="img"></p>
<h4 id="使用-kubectl-进行故障排除"><a href="#使用-kubectl-进行故障排除" class="headerlink" title="使用 kubectl 进行故障排除"></a>使用 kubectl 进行故障排除</h4><p>使用了Kubectl 命令管理工具。我们继续在模块3中使用它来获取有关Deployment的应用及其环境信息。常见的操作可以通过以下kubectl命令完成：</p>
<ul>
<li><strong>kubectl get -</strong> 列出资源</li>
<li><strong>kubectl describe</strong> - 显示资源的详细信息</li>
<li><strong>kubectl logs</strong> - 打印pod中的容器日志</li>
<li><strong>kubectl exec</strong> - pod中容器内部执行命令</li>
</ul>
<p>可以使用这些命令来查看应用程序何时部署、它们当前的状态是什么、它们在哪里运行以及它们的配置是什么。</p>
<h3 id="3、Service"><a href="#3、Service" class="headerlink" title="3、Service"></a>3、Service</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建一个service</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f service.yaml</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看service</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get service</span></span><br></pre></td></tr></table></figure>

<p>Kubernetes <a href="https://kubernetes.io/zh-cn/docs/concepts/workloads/pods/">Pod</a> 是转瞬即逝的。 Pod 实际上拥有 <a href="https://kubernetes.io/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/">生命周期</a>。 当一个工作 Node 挂掉后, 在 Node 上运行的 Pod 也会消亡。 <a href="https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/replicaset/">ReplicaSet</a> 会自动地通过创建新的 Pod 驱动集群回到目标状态，以保证应用程序正常运行。 换一个例子，考虑一个具有3个副本数的用作图像处理的后端程序。这些副本是可替换的; 前端系统不应该关心后端副本，即使 Pod 丢失或重新创建。也就是说，Kubernetes 集群中的每个 Pod (即使是在同一个 Node 上的 Pod )都有一个唯一的 IP 地址，因此需要一种方法自动协调 Pod 之间的变更，以便应用程序保持运行。</p>
<p>Kubernetes 中的服务(Service)是一种抽象概念，它定义了 Pod 的逻辑集和访问 Pod 的协议。Service 使从属 Pod 之间的松耦合成为可能。 和其他 Kubernetes 对象一样, Service 用 YAML <a href="https://kubernetes.io/zh-cn/docs/concepts/configuration/overview/#general-configuration-tips">(更推荐)</a> 或者 JSON 来定义. Service 下的一组 Pod 通常由 <em>LabelSelector</em> (请参阅下面的说明为什么你可能想要一个 spec 中不包含<code>selector</code>的服务)来标记。</p>
<p>尽管每个 Pod 都有一个唯一的 IP 地址，但是如果没有 Service ，这些 IP 不会暴露在集群外部。Service 允许你的应用程序接收流量。Service 也可以用在 ServiceSpec 标记<code>type</code>的方式暴露</p>
<ul>
<li><em>ClusterIP</em> (默认) - 在集群的内部 IP 上公开 Service 。这种类型使得 Service 只能从集群内访问。</li>
<li><em>NodePort</em> - 使用 NAT 在集群中每个选定 Node 的相同端口上公开 Service 。使用<code>&lt;NodeIP&gt;:&lt;NodePort&gt;</code> 从集群外部访问 Service。是 ClusterIP 的超集。</li>
<li><em>LoadBalancer</em> - 在当前云中创建一个外部负载均衡器(如果支持的话)，并为 Service 分配一个固定的外部IP。是 NodePort 的超集。</li>
<li><em>ExternalName</em> - 通过返回带有该名称的 CNAME 记录，使用任意名称(由 spec 中的<code>externalName</code>指定)公开 Service。不使用代理。这种类型需要<code>kube-dns</code>的v1.7或更高版本。</li>
</ul>
<p>更多关于不同 Service 类型的信息可以在<a href="https://kubernetes.io/zh-cn/docs/tutorials/services/source-ip/">使用源 IP</a> 教程。 也请参阅 <a href="https://kubernetes.io/zh-cn/docs/concepts/services-networking/connect-applications-service">连接应用程序和 Service </a>。</p>
<p>另外，需要注意的是有一些 Service 的用例没有在 spec 中定义<code>selector</code>。 一个没有<code>selector</code>创建的 Service 也不会创建相应的端点对象。这允许用户手动将服务映射到特定的端点。没有 selector 的另一种可能是你严格使用<code>type: ExternalName</code>来标记。</p>
<blockquote>
<p> <em>Kubernetes 的 Service 是一个抽象层，它定义了一组 Pod 的逻辑集，并为这些 Pod 支持外部流量暴露、负载平衡和服务发现。</em></p>
</blockquote>
<h4 id="Services和Labels"><a href="#Services和Labels" class="headerlink" title="Services和Labels"></a>Services和Labels</h4><p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/module_04_services.svg" alt="img"></p>
<p>如上图，A中Service 路由一组Pods的流量。Service允许pod在Kubernetes中被销毁并复制pod而不影响应用。相关Pod之间的发现和路由（如应用中的前端和后端组件）由Kubernetes Services处理。</p>
<p>Service 使用<a href="http://docs.kubernetes.org.cn/247.html">label selectors</a>来匹配一组Pod，允许对Kubernetes中的对象进行逻辑运算，Label以key/value 键/值对附加到对象上。以多种方式使用：</p>
<ul>
<li>指定用于开发，测试和生产的对象</li>
<li>嵌入版本Label</li>
<li>使用Label分类对象</li>
</ul>
<blockquote>
<p><em>你可以在使用<code>--expose</code>kubectl 创建 Deployment 的同时创建 Service 。</em></p>
</blockquote>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/module_04_labels-20220921215509387.svg" alt="img"></p>
<p>标签(Label)可以在创建时或之后附加到对象上。他们可以随时被修改。现在使用 Service 发布我们的应用程序并添加一些 Label 。</p>
<h3 id="4、扩缩应用程序"><a href="#4、扩缩应用程序" class="headerlink" title="4、扩缩应用程序"></a>4、扩缩应用程序</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl <span class="built_in">set</span> image deployment.apps/&lt;deployment名称&gt; &lt;容器名称&gt;=&lt;镜像&gt;:&lt;版本&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl <span class="built_in">set</span> image deployment.apps/tomcat7 tomcat6=tomcat:6.0.53-jre8</span></span><br></pre></td></tr></table></figure>

<p>在之前的模块中，我们创建了一个 <a href="https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/deployment/">Deployment</a>，然后通过 <a href="https://kubernetes.io/zh-cn/docs/concepts/services-networking/service/">Service</a>让其可以开放访问。Deployment 仅为跑这个应用程序创建了一个 Pod。 当流量增加时，我们需要扩容应用程序满足用户需求。</p>
<p><strong>扩缩</strong> 是通过改变 Deployment 中的副本数量来实现的。</p>
<blockquote>
<p><em>在运行 kubectl run 命令时，你可以通过设置 –replicas 参数来设置 Deployment 的副本数。</em></p>
</blockquote>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/module_05_scaling1.svg" alt="img"></p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/module_05_scaling2.svg" alt="img"></p>
<p>扩展 Deployment 将创建新的 Pods，并将资源调度请求分配到有可用资源的节点上，收缩 会将 Pods 数量减少至所需的状态。Kubernetes 还支持 Pods 的<a href="https://kubernetes.io/zh-cn/docs/tasks/run-application/horizontal-pod-autoscale/">自动缩放</a>，但这并不在本教程的讨论范围内。将 Pods 数量收缩到0也是可以的，但这会终止 Deployment 上所有已经部署的 Pods。</p>
<p>运行应用程序的多个实例需要在它们之间分配流量。服务 (Service)有一种负载均衡器类型，可以将网络流量均衡分配到外部可访问的 Pods 上。服务将会一直通过端点来监视 Pods 的运行，保证流量只分配到可用的 Pods 上。</p>
<p> 一旦有了多个应用实例，就可以没有宕机地滚动更新。</p>
<blockquote>
<p><em>扩缩是通过改变 Deployment 中的副本数量来实现的。</em></p>
</blockquote>
<h3 id="5、更新应用程序"><a href="#5、更新应用程序" class="headerlink" title="5、更新应用程序"></a>5、更新应用程序</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get deployment</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl rollout <span class="built_in">history</span> deployment tomcat7                       <span class="comment"># 查看deployment记录</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl rollout <span class="built_in">history</span> deployment tomcat7 --revision=&lt;版本号&gt;    <span class="comment"># 查看版本详细信息</span></span>  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl rollout undo deployment tomcat7 --to-revision=&lt;版本号&gt;    <span class="comment"># 回退到某个版本</span></span></span><br></pre></td></tr></table></figure>

<p>用户希望应用程序始终可用，而开发人员则需要每天多次部署它们的新版本（一个简单例子，大家在玩游戏时常常碰到这类公告：8月8日凌晨：2点-6点服务升级，暂停所有服务…..）*。在 Kubernetes 中，这些是通过<strong>滚动更新</strong>（Rolling Updates）完成的。 <strong>滚动更新</strong> 允许通过使用新的实例逐步更新 Pod 实例，零停机进行 Deployment 更新。新的 Pod 将在具有可用资源的节点上进行调度。</p>
<p>在前面的模块中，我们将应用程序扩展为运行多个实例。这是在不影响应用程序可用性的情况下执行更新的要求。默认情况下，更新期间不可用的 pod 的最大值和可以创建的新 pod 数都是 1。这两个选项都可以配置为（pod）数字或百分比。 在 Kubernetes 中，更新是经过版本控制的，任何 Deployment 更新都可以恢复到以前的（稳定）版本，支持升级 / 回滚（恢复）更新。</p>
<blockquote>
<p><em>滚动更新允许通过使用新的实例逐步更新 Pod 实例从而实现 Deployments 更新，停机时间为零。</em></p>
</blockquote>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/module_06_rollingupdates1.svg" alt="img"></p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/module_06_rollingupdates2.svg" alt="img"></p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/module_06_rollingupdates3.svg" alt="img"></p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/module_06_rollingupdates4.svg" alt="img"></p>
<p>与应用程序扩展类似，如果 Deployment 是公开的，服务将在更新期间仅对可用的 pod 进行负载均衡。可用 Pod 是应用程序用户可用的实例。</p>
<p>滚动更新允许以下操作：</p>
<ul>
<li>将应用程序从一个环境提升到另一个环境（通过容器镜像更新）</li>
<li>回滚到以前的版本</li>
<li>持续集成和持续交付应用程序，无需停机</li>
</ul>
<blockquote>
<p><em>如果 Deployment 是公开的，则服务将仅在更新期间对可用的 pod 进行负载均衡。</em></p>
</blockquote>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><p>  K8s官方文档：<a href="https://kubernetes.io/zh-cn/docs/home/">https://kubernetes.io/zh-cn/docs/home/</a></p>
</li>
<li><p>  K8s中文社区文档：<a href="http://docs.kubernetes.org.cn/">http://docs.kubernetes.org.cn/</a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux目录结构</title>
    <url>/2019/52ce3ee60b28/</url>
    <content><![CDATA[<h2 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h2><p>树状目录结构：</p>
<p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/d0c50-linux2bfile2bsystem2bhierarchy.jpg" alt="img"></p>
<span id="more"></span>

<p><strong>常用目录</strong>：</p>
<table>
<thead>
<tr>
<th>目录</th>
<th>解释</th>
<th>详情</th>
</tr>
</thead>
<tbody><tr>
<td><code>/etc</code></td>
<td>系统中的配置文件</td>
<td>如果你更改了该目录下的某个文件可能会导致系统不能启动。</td>
</tr>
<tr>
<td>/bin</td>
<td>存放着最常用的程序和指令</td>
<td></td>
</tr>
<tr>
<td>/sbin</td>
<td>只有系统管理员能使用的程序和指令</td>
<td>英文翻译就是 Super User 的意思，超级用户</td>
</tr>
<tr>
<td>/usr/bin、/usr/sbin</td>
<td>系统用户使用的指令</td>
<td></td>
</tr>
<tr>
<td>/usr/local</td>
<td>用户级的程序目录</td>
<td>用户编译的软件默认会安装到这个目录下</td>
</tr>
<tr>
<td><code>/var</code></td>
<td>存放经常修改的数据</td>
<td>比如程序运行的日志文件（/var/log 目录下</td>
</tr>
<tr>
<td><code>/opt</code></td>
<td>拓展目录</td>
<td>默认是空的，我们安装额外软件可以放在这个里面。</td>
</tr>
</tbody></table>
<blockquote>
<p>  <strong>/bin, /sbin, /usr/bin, /usr/sbin</strong>: 这是系统预设的执行文件的放置目录，比如 <strong>ls</strong> 就是在 <strong>/bin/ls</strong> 目录下的。</p>
<p>  值得提出的是 <strong>/bin</strong>、**/usr/bin** 是给系统用户使用的指令（除 root 外的通用用户），而/sbin, /usr/sbin 则是给 root 使用的指令。</p>
</blockquote>
<h2 id="目录分类："><a href="#目录分类：" class="headerlink" title="目录分类："></a>目录分类：</h2><p><strong>系统启动必须：</strong></p>
<ul>
<li><p>  <strong>/boot：</strong>存放的启动Linux 时使用的内核文件，包括连接文件以及镜像文件。</p>
</li>
<li><p>  <strong>/etc：</strong>存放<strong>所有</strong>的系统需要的<strong>配置文件</strong>和<strong>子目录列表，</strong>更改目录下的文件可能会导致系统不能启动。</p>
</li>
<li><p>  <strong>/lib</strong>：存放基本代码库（比如c++库），其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。</p>
</li>
<li><p>  <strong>/sys</strong>： 这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统 sysfs 。sysfs文件系统集成了下面3种文件系统的信息：针对进程信息的proc文件系统、针对设备的devfs文件系统以及针对伪终端的devpts文件系统。该文件系统是内核设备树的一个直观反映。当一个内核对象被创建的时候，对应的文件和目录也在内核对象子系统中</p>
</li>
</ul>
<p><strong>指令集合：</strong></p>
<ul>
<li><p>  <strong>/bin：</strong>存放着最常用的程序和指令</p>
</li>
<li><p>  <strong>/sbin：</strong>只有系统管理员能使用的程序和指令。</p>
</li>
</ul>
<p><strong>外部文件管理：</strong></p>
<ul>
<li><p>  <strong>/dev ：</strong>Device(设备)的缩写, 存放的是Linux的外部设备。<strong>注意：</strong>在Linux中访问设备和访问文件的方式是相同的。</p>
</li>
<li><p>  <strong>/media</strong>：类windows的<strong>其他设备，</strong>例如U盘、光驱等等，识别后linux会把设备放到这个目录下。</p>
</li>
<li><p>  <strong>/mnt</strong>：临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。</p>
</li>
</ul>
<p><strong>临时文件：</strong></p>
<ul>
<li><p>  <strong>/run</strong>：是一个临时文件系统，存储系统启动以来的信息。当系统重启时，这个目录下的文件应该被删掉或清除。如果你的系统上有 /var/run 目录，应该让它指向 run。</p>
</li>
<li><p>  <strong>/lost+found</strong>：一般情况下为空的，系统非法关机后，这里就存放一些文件。</p>
</li>
<li><p>  <strong>/tmp</strong>：这个目录是用来存放一些临时文件的。</p>
</li>
</ul>
<p><strong>账户：</strong></p>
<ul>
<li><p>  <strong>/root</strong>：系统管理员的用户主目录。</p>
</li>
<li><p>  <strong>/home</strong>：用户的主目录，以用户的账号命名的。</p>
</li>
<li><p>  <strong>/usr</strong>：用户的很多应用程序和文件都放在这个目录下，类似于windows下的program files目录。</p>
</li>
<li><p>  <strong>/usr/bin：</strong>系统用户使用的应用程序与指令。</p>
</li>
<li><p>  <strong>/usr/sbin：</strong>超级用户使用的比较高级的管理程序和系统守护程序。</p>
</li>
<li><p>  <strong>/usr/src：</strong>内核源代码默认的放置目录。</p>
</li>
<li><p>  <strong>/usr/local：</strong> 用户级的程序目录，用户编译的软件默认会安装到这个目录下。</p>
</li>
</ul>
<p><strong>运行过程中要用：</strong></p>
<ul>
<li><p>  <strong>/var</strong>：存放经常修改的数据，比如程序运行的日志文件（/var/log 目录下）。</p>
</li>
<li><p>  <strong>/proc</strong>：管理<strong>内存空间！</strong>虚拟的目录，是系统内存的映射，我们可以直接访问这个目录来，获取系统信息。这个目录的内容不在硬盘上而是在内存里，我们也可以直接修改里面的某些文件来做修改。</p>
</li>
</ul>
<p><strong>扩展用的：</strong></p>
<ul>
<li><p>  <strong>/opt</strong>：默认是空的，我们安装额外软件可以放在这个里面。</p>
</li>
<li><p>  <strong>/srv</strong>：存放服务启动后需要提取的数据<strong>（不用服务器就是空）</strong></p>
</li>
</ul>
<blockquote>
<p>  菜鸟教程： <a href="https://www.runoob.com/linux/linux-tutorial.html">https://www.runoob.com/linux/linux-tutorial.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Cglib和Jdk动态代理</title>
    <url>/2018/1181fa23a35f/</url>
    <content><![CDATA[<h2 id="一、Cglib"><a href="#一、Cglib" class="headerlink" title="一、Cglib"></a>一、Cglib</h2><blockquote>
<p> CGLIB 呢, 相对于Java的代理来说, 更加灵活和富有弹性, 他的功能提供的更加的强大, 依靠callback实现的功能的增强.</p>
<p> 通过这篇文章我相信你对于CGLIB的了解会提升一个档次的 . 本文开始从快速开始上手体验, 理解其核心模块,到源码分析其启动流程, 然后分析一些存在的问题.</p>
<p> 官网地址: <a href="https://github.com/cglib/cglib">https://github.com/cglib/cglib</a></p>
</blockquote>
<h3 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h3><h4 id="被增强的类"><a href="#被增强的类" class="headerlink" title="被增强的类"></a>被增强的类</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserServiceImp</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">(<span class="type">int</span> id)</span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;getName()&quot;</span>+id);</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Tom&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getAge</span><span class="params">(<span class="type">int</span> id)</span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;getAge()&quot;</span>+id);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="增强"><a href="#增强" class="headerlink" title="增强"></a>增强</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">App</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 设置字节码保存的地方.</span></span><br><span class="line">        System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, <span class="string">&quot;D:/test&quot;</span>);</span><br><span class="line">        <span class="comment">//实例化Enhancer类生成器</span></span><br><span class="line">        Enhancer enhancer=<span class="keyword">new</span> <span class="title class_">Enhancer</span>();</span><br><span class="line">        <span class="comment">//设置Enhancer要生成的目标类的父类</span></span><br><span class="line">        enhancer.setSuperclass(UserServiceImp.class);</span><br><span class="line">        <span class="comment">//设置目标类执行方法的拦截器</span></span><br><span class="line">        enhancer.setCallback(<span class="keyword">new</span> <span class="title class_">MethodInterceptor</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Object <span class="title function_">intercept</span><span class="params">(Object obj, Method method, Object[] args, MethodProxy proxy)</span> <span class="keyword">throws</span> Throwable &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="string">&quot;proxy&quot;</span> + proxy.invokeSuper(obj, args);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//利用enhancer生成目标类 UserServiceImp$$EnhancerByCGLIB$$b2b12b83@6df97b55</span></span><br><span class="line">        UserServiceImp userService1=(UserServiceImp) enhancer.create();</span><br><span class="line">        <span class="comment">//生成的目标类调用方法，此时会被userServiceMethodInterceptor拦截，执行其中的intercept方法</span></span><br><span class="line">        userService1.getName(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//生成的目标类调用方法，此时会被userServiceMethodInterceptor拦截，执行其中的intercept方法</span></span><br><span class="line">        userService1.getAge(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="二、Jdk动态代理"><a href="#二、Jdk动态代理" class="headerlink" title="二、Jdk动态代理"></a>二、Jdk动态代理</h2><blockquote>
<p>JDK动态代理基于拦截器和反射来实现。</p>
<p>JDK代理是不需要第三方库支持的，只需要JDK环境就可以进行代理，使用条件：</p>
<p>​    1）必须实现InvocationHandler接口；</p>
<p>​    2）使用Proxy.newProxyInstance产生代理对象；</p>
<p>​    3）被代理的对象必须要实现接口；</p>
</blockquote>
<h3 id="Demo-1"><a href="#Demo-1" class="headerlink" title="Demo"></a>Demo</h3><h4 id="1-接口"><a href="#1-接口" class="headerlink" title="1.接口"></a>1.接口</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">IHello</span> &#123;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">sayHello</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="2-实现类"><a href="#2-实现类" class="headerlink" title="2.实现类"></a>2.实现类</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HelloImpl</span> <span class="keyword">implements</span> <span class="title class_">IHello</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sayHello</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Hello world!&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="3-InvocationHandler"><a href="#3-InvocationHandler" class="headerlink" title="3. InvocationHandler"></a>3. InvocationHandler</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.lang.reflect.InvocationHandler;</span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Method;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JdkInvocationHandler</span> <span class="keyword">implements</span> <span class="title class_">InvocationHandler</span> &#123;</span><br><span class="line">    <span class="comment">/** 目标对象 */</span></span><br><span class="line">    <span class="keyword">private</span> Object target;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">JdkInvocationHandler</span><span class="params">(Object target)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.target = target;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">invoke</span><span class="params">(Object proxy, Method method, Object[] args)</span> <span class="keyword">throws</span> Throwable &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;------插入前置通知代码-------------&quot;</span>);</span><br><span class="line">        <span class="type">Object</span> <span class="variable">rs</span> <span class="operator">=</span> method.invoke(target,args); <span class="comment">// 执行相应的目标方法</span></span><br><span class="line">        System.out.println(<span class="string">&quot;------插入后置处理代码-------------&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> rs;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="4-Test"><a href="#4-Test" class="headerlink" title="4.Test"></a>4.Test</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.lang.reflect.Constructor;</span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.InvocationHandler;</span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.InvocationTargetException;</span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Proxy;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用JDK动态代理的五大步骤:</span></span><br><span class="line"><span class="comment"> * 1.通过实现InvocationHandler接口来自定义自己的InvocationHandler;</span></span><br><span class="line"><span class="comment"> * 2.通过Proxy.getProxyClass获得动态代理类</span></span><br><span class="line"><span class="comment"> * 3.通过反射机制获得代理类的构造方法，方法签名为getConstructor(InvocationHandler.class)</span></span><br><span class="line"><span class="comment"> * 4.通过构造函数获得代理对象并将自定义的InvocationHandler实例对象传为参数传入</span></span><br><span class="line"><span class="comment"> * 5.通过代理对象调用目标方法</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JdkProxyTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span></span><br><span class="line">            <span class="keyword">throws</span> NoSuchMethodException, IllegalAccessException, InstantiationException, InvocationTargetException &#123;</span><br><span class="line">        <span class="comment">// =========================第一种==========================</span></span><br><span class="line">        <span class="comment">// 1、生成$Proxy0的class文件</span></span><br><span class="line">        System.getProperties().put(<span class="string">&quot;sun.misc.ProxyGenerator.saveGeneratedFiles&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">        <span class="comment">// 2、获取动态代理类</span></span><br><span class="line">        <span class="type">Class</span> <span class="variable">proxyClazz</span> <span class="operator">=</span> Proxy.getProxyClass(IHello.class.getClassLoader(),IHello.class);</span><br><span class="line">        <span class="comment">// 3、获得代理类的构造函数，并传入参数类型InvocationHandler.class</span></span><br><span class="line">        <span class="type">Constructor</span> <span class="variable">constructor</span> <span class="operator">=</span> proxyClazz.getConstructor(InvocationHandler.class);</span><br><span class="line">        <span class="comment">// 4、通过构造函数来创建动态代理对象，将自定义的InvocationHandler实例传入</span></span><br><span class="line">        <span class="type">IHello</span> <span class="variable">iHello1</span> <span class="operator">=</span> (IHello) constructor.newInstance(<span class="keyword">new</span> <span class="title class_">JdkInvocationHandler</span>(<span class="keyword">new</span> <span class="title class_">HelloImpl</span>()));</span><br><span class="line">        <span class="comment">// 5、通过代理对象调用目标方法</span></span><br><span class="line">        iHello1.sayHello();</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// ==========================第二种=============================</span></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * Proxy类中还有个将2~4步骤封装好的简便方法来创建动态代理对象，</span></span><br><span class="line"><span class="comment">         *其方法签名为：newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] instance, InvocationHandler h)</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">IHello</span>  <span class="variable">iHello2</span> <span class="operator">=</span> (IHello) Proxy.newProxyInstance(IHello.class.getClassLoader(), <span class="comment">// 加载接口的类加载器</span></span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">Class</span>[]&#123;IHello.class&#125;, <span class="comment">// 一组接口</span></span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">JdkInvocationHandler</span>(<span class="keyword">new</span> <span class="title class_">HelloImpl</span>())); <span class="comment">// 自定义的InvocationHandler</span></span><br><span class="line">        iHello2.sayHello();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>动态代理</tag>
      </tags>
  </entry>
  <entry>
    <title>iTerm2+ohmyzsh美化终端</title>
    <url>/2019/13fcd58ee04d/</url>
    <content><![CDATA[<h2 id="一、安装homebrew"><a href="#一、安装homebrew" class="headerlink" title="一、安装homebrew"></a>一、安装homebrew</h2><p>Homebrew 由开发者 Max Howell 开发，并基于 BSD 开源，是一个非常方便的<strong>包管理器工具</strong>。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">官方安装方式</span></span><br><span class="line">/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">中科大源安装</span></span><br><span class="line">/usr/bin/ruby -e &quot;$(curl -fsSL https://cdn.jsdelivr.net/gh/ineo6/homebrew-install/install)&quot;</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<p>下载 <code>zsh</code>终端：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">brew install zsh</span><br></pre></td></tr></table></figure>

<p>切换成 <code>zsh</code>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo $SHELL                  # 查看当前使用的终端</span><br><span class="line">chsh -s /bin/zsh             # 切换终端</span><br></pre></td></tr></table></figure>

<p>如果想改回默认，直接使用<code>chsh</code>命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chsh -s /bin/bash</span><br></pre></td></tr></table></figure>

<h2 id="二、安装iTerm2"><a href="#二、安装iTerm2" class="headerlink" title="二、安装iTerm2"></a>二、安装iTerm2</h2><h3 id="1、下载安装"><a href="#1、下载安装" class="headerlink" title="1、下载安装"></a>1、下载安装</h3><p><a href="https://www.iterm2.com/">iterm2</a> 是 MAC 下最好的终端工具。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">brew search iterm                  </span><br><span class="line">brew cask install iterm2   </span><br></pre></td></tr></table></figure>

<h3 id="2、修改配色"><a href="#2、修改配色" class="headerlink" title="2、修改配色"></a>2、修改配色</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找一个目录存放 iterm2 相关的文件</span></span><br><span class="line">mkdir ~/Desktop/iterm2/themes</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下载 iTerm2-Color-Schemes</span></span><br><span class="line">git clone https://github.com/mbadolato/iTerm2-Color-Schemes</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">schemes 文件夹就是真实存放配色方案的目录</span></span><br><span class="line">cd iTerm2-Color-Schemes/schemes</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  <a href="https://iterm2colorschemes.com/">https://iterm2colorschemes.com/</a>  这里有非常多的配色方案</p>
</blockquote>
<p><strong>导入所有配色方案</strong>：</p>
<p>菜单栏 -&gt; Profiles -&gt; Open Profiles -&gt; Edit Profiles -&gt; 选择 Colors -&gt; 右下角 Color Presets -&gt; Import…</p>
<h2 id="三、安装-oh-my-zsh"><a href="#三、安装-oh-my-zsh" class="headerlink" title="三、安装 oh my zsh"></a>三、安装 oh my zsh</h2><p><a href="https://github.com/ohmyzsh/ohmyzsh">Oh My Zsh</a> 是一款社区驱动的命令行工具，它基于 <code>zsh</code> 命令行，提供了主题配置，插件机制，已经内置的便捷操作。</p>
<p><strong>安装oh my zsh</strong>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot;</span><br></pre></td></tr></table></figure>

<p><strong>安装成功</strong>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Time to change your default shell to zsh:</span><br><span class="line">Do you want to change your default shell to zsh? [Y/n] y</span><br><span class="line">Changing your shell to /bin/zsh...</span><br><span class="line">Changing shell for root.</span><br><span class="line">Shell changed.</span><br><span class="line">Shell successfully changed to &#x27;/bin/zsh&#x27;.</span><br><span class="line"></span><br><span class="line">         __                                     __</span><br><span class="line">  ____  / /_     ____ ___  __  __   ____  _____/ /_</span><br><span class="line"> / __ \/ __ \   / __ `__ \/ / / /  /_  / / ___/ __ \</span><br><span class="line">/ /_/ / / / /  / / / / / / /_/ /    / /_(__  ) / / /</span><br><span class="line">\____/_/ /_/  /_/ /_/ /_/\__, /    /___/____/_/ /_/</span><br><span class="line">                        /____/                       ....is now installed!</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Before you scream Oh My Zsh! look over the `.zshrc` file to select plugins, themes, and options.</span><br><span class="line"></span><br><span class="line">• Follow us on Twitter: https://twitter.com/ohmyzsh</span><br><span class="line">• Join our Discord community: https://discord.gg/ohmyzsh</span><br><span class="line">• Get stickers, t-shirts, coffee mugs and more: https://shop.planetargon.com/collections/oh-my-zsh</span><br></pre></td></tr></table></figure>

<h2 id="四、配置oh-my-zsh"><a href="#四、配置oh-my-zsh" class="headerlink" title="四、配置oh my zsh"></a>四、配置oh my zsh</h2><p>打开<code>oh my zsh</code>的配置文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim  ~/.zshrc</span><br></pre></td></tr></table></figure>

<h3 id="设置主题"><a href="#设置主题" class="headerlink" title="设置主题"></a>设置主题</h3><p><code>oh-my-zsh</code> 提供了很多内置的配色方案，<a href="https://github.com/ohmyzsh/ohmyzsh/wiki/Themes">官方主题列表</a>，可以通过命令来查看：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls ~/.oh-my-zsh/themes</span><br></pre></td></tr></table></figure>

<p>配置项<code>ZSH_THEME</code> 即可配置主题。<code>ZSH_THEME=&quot;random&quot;</code> 表示使用随机主题，每次打开终端会随机选择一种主题。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ZSH_THEME=&quot;random&quot;</span><br></pre></td></tr></table></figure>

<p>使主题生效：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zsh           # 作用跟 source .zshrc 一样</span><br></pre></td></tr></table></figure>

<p>非官方主题</p>
<h3 id="添加插件"><a href="#添加插件" class="headerlink" title="添加插件"></a>添加插件</h3><p>修改<code>plugins</code>项：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">plugins=(</span><br><span class="line">      git </span><br><span class="line">      autojump </span><br><span class="line">      zsh-autosuggestions </span><br><span class="line">      zsh-syntax-highlighting</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>插件说明</strong>：</p>
<p>autojump： 快速跳转的效率工具，它会记录之前访问过的目录，支持模糊匹配。</p>
<p>zsh-autosuggestions：自动提示插件</p>
<p>zsh-syntax-highlighting：语法高亮插件</p>
<h3 id="其他配置"><a href="#其他配置" class="headerlink" title="其他配置"></a>其他配置</h3><p><strong>禁用每次下载自动更新</strong>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export HOMEBREW_NO_AUTO_UPDATE=true</span><br></pre></td></tr></table></figure>

<p><strong>设置命令行中文</strong>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export LANG=zh_CN.UTF-8</span><br><span class="line">export LC_ALL=zh_CN.UTF-8</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>工具</category>
        <category>zsh</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>Java线程池</title>
    <url>/2018/fa8bf4108648/</url>
    <content><![CDATA[<h2 id="一、ThreadPoolExecutor的重要参数"><a href="#一、ThreadPoolExecutor的重要参数" class="headerlink" title="一、ThreadPoolExecutor的重要参数"></a>一、ThreadPoolExecutor的重要参数</h2><ul>
<li><p>corePoolSize：核心线程数</p>
</li>
<li><ul>
<li>核心线程会一直存活，及时没有任务需要执行<ul>
<li>当线程数小于核心线程数时，即使有线程空闲，线程池也会优先创建新线程处理</li>
<li>设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭</li>
</ul>
</li>
</ul>
</li>
<li><p>queueCapacity：任务队列容量（阻塞队列）</p>
</li>
<li><p>当核心线程数达到最大时，新任务会放在队列中排队等待执行</p>
</li>
<li><p>maxPoolSize：最大线程数</p>
</li>
<li><p>当线程数&gt;=corePoolSize，且任务队列已满时。线程池会创建新线程来处理任务</p>
<p>  当线程数=maxPoolSize，且任务队列已满时，线程池会拒绝处理任务而抛出异常</p>
</li>
<li><p>keepAliveTime：线程空闲时间</p>
</li>
<li><p>当线程空闲时间达到keepAliveTime时，线程会退出，直到线程数量=corePoolSize</p>
<p>  如果allowCoreThreadTimeout=true，则会直到线程数量=0</p>
</li>
<li><p>allowCoreThreadTimeout：允许核心线程超时</p>
</li>
<li><p>rejectedExecutionHandler：任务拒绝处理器</p>
</li>
<li><p>两种情况会拒绝处理任务：</p>
<ul>
<li>当线程数已经达到maxPoolSize，切队列已满，会拒绝新任务</li>
</ul>
<ul>
<li><p>当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务</p>
</li>
<li><p>线程池会调用rejectedExecutionHandler来处理这个任务。如果没有设置默认是AbortPolicy，会抛出异常</p>
</li>
<li><p>ThreadPoolExecutor类有几个内部实现类来处理这类情况：</p>
<ul>
<li>AbortPolicy 丢弃任务，抛运行时异常</li>
</ul>
<ul>
<li>CallerRunsPolicy 执行任务</li>
<li>DiscardPolicy 忽视，什么都不会发生</li>
<li>DiscardOldestPolicy 从队列中踢出最先进入队列（最后一个执行）的任务</li>
</ul>
</li>
<li><p>实现RejectedExecutionHandler接口，可自定义处理器</p>
</li>
</ul>
</li>
</ul>
<h2 id="二、ThreadPoolExecutor执行顺序："><a href="#二、ThreadPoolExecutor执行顺序：" class="headerlink" title="二、ThreadPoolExecutor执行顺序："></a>二、ThreadPoolExecutor执行顺序：</h2><p>   线程池按以下行为执行任务</p>
<ol>
<li>当线程数小于核心线程数时，创建线程。</li>
<li>当线程数大于等于核心线程数，且任务队列未满时，将任务放入任务队列。</li>
<li>当线程数大于等于核心线程数，且任务队列已满<ol>
<li>若线程数小于最大线程数，创建线程</li>
<li>若线程数等于最大线程数，抛出异常，拒绝任务</li>
</ol>
</li>
</ol>
<h2 id="三、如何设置参数"><a href="#三、如何设置参数" class="headerlink" title="三、如何设置参数"></a>三、如何设置参数</h2><ul>
<li>默认值</li>
<li><ul>
<li>corePoolSize=1<ul>
<li>queueCapacity=Integer.MAX_VALUE</li>
<li>maxPoolSize=Integer.MAX_VALUE</li>
<li>keepAliveTime=60s</li>
<li>allowCoreThreadTimeout=false</li>
<li>rejectedExecutionHandler=AbortPolicy()</li>
</ul>
</li>
</ul>
</li>
<li>如何来设置</li>
<li><ul>
<li>需要根据几个值来决定<ul>
<li><ul>
<li>tasks ：每秒的任务数，假设为500~1000<ul>
<li>taskcost：每个任务花费时间，假设为0.1s</li>
<li>responsetime：系统允许容忍的最大响应时间，假设为1s</li>
</ul>
</li>
</ul>
</li>
<li>做几个计算</li>
<li><ul>
<li>corePoolSize = 每秒需要多少个线程处理？ <ul>
<li><ul>
<li>threadcount = tasks/(1/taskcost) =tasks*taskcout =  (500<del>1000)*0.1 = 50</del>100 个线程。corePoolSize设置应该大于50<ul>
<li>根据8020原则，如果80%的每秒任务数小于800，那么corePoolSize设置为80即可</li>
</ul>
</li>
</ul>
</li>
<li>queueCapacity = (coreSizePool/taskcost)*responsetime</li>
<li><ul>
<li>计算可得 queueCapacity = 80/0.1*1 = 80。意思是队列里的线程可以等待1s，超过了的需要新开线程来执行<ul>
<li>切记不能设置为Integer.MAX_VALUE，这样队列会很大，线程数只会保持在corePoolSize大小，当任务陡增时，不能新开线程来执行，响应时间会随之陡增。</li>
</ul>
</li>
</ul>
</li>
<li>maxPoolSize = (max(tasks)- queueCapacity)/(1/taskcost)</li>
<li><ul>
<li>计算可得 maxPoolSize = (1000-80)/10 = 92<ul>
<li>（最大任务数-队列容量）/每个线程每秒处理能力 = 最大线程数</li>
</ul>
</li>
</ul>
</li>
<li>rejectedExecutionHandler：根据具体情况来决定，任务不重要可丢弃，任务重要则要利用一些缓冲机制来处理<ul>
<li>AbortPolicy     – 当任务添加到线程池中被拒绝时，它将抛出 RejectedExecutionException 异常。</li>
<li>CallerRunsPolicy   – 当任务添加到线程池中被拒绝时，会在线程池当前正在运行的Thread线程池中处理被拒绝的任务。</li>
<li>DiscardOldestPolicy – 当任务添加到线程池中被拒绝时，线程池会放弃等待队列中最旧的未处理任务，然后将被拒绝的任务添加到等待队列中。</li>
<li>DiscardPolicy    – 当任务添加到线程池中被拒绝时，线程池将丢弃被拒绝的任务。</li>
</ul>
</li>
<li>keepAliveTime和allowCoreThreadTimeout采用默认通常能满足</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>以上都是理想值，实际情况下要根据机器性能来决定。如果在未达到最大线程数的情况机器cpu load已经满了，则需要通过升级硬件（呵呵）和优化代码，降低taskcost来处理。</li>
</ul>
<h2 id="四、创建线程池方式"><a href="#四、创建线程池方式" class="headerlink" title="四、创建线程池方式"></a>四、创建线程池方式</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@Description</span>    线程池的初始化  jdk方式  二选一</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="meta">@Bean</span></span><br><span class="line"> <span class="keyword">public</span> ThreadPoolExecutor <span class="title function_">threadPoolExecutor</span><span class="params">()</span> &#123;</span><br><span class="line">     <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>(corePoolSize,  <span class="comment">//核心线程数</span></span><br><span class="line">             maxPoolSize,   <span class="comment">//最大线程数</span></span><br><span class="line">             keepAliveSeconds,  <span class="comment">//空闲线程存活时间</span></span><br><span class="line">             TimeUnit.SECONDS,  <span class="comment">//时间单位</span></span><br><span class="line">             <span class="keyword">new</span> <span class="title class_">LinkedBlockingQueue</span>&lt;Runnable&gt;(queueCapacity),  <span class="comment">//等待队列长度</span></span><br><span class="line">             <span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>.CallerRunsPolicy() &#123; <span class="comment">//拒绝策略</span></span><br><span class="line">                 <span class="meta">@Override</span></span><br><span class="line">                 <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">rejectedExecution</span><span class="params">(Runnable r, ThreadPoolExecutor executor)</span> &#123;</span><br><span class="line">                     log.warn(<span class="string">&quot;注意,有任务超过线程池配置&quot;</span>);</span><br><span class="line">                     <span class="keyword">if</span>(!executor.isShutdown()) &#123; r.run(); &#125;</span><br><span class="line">                 &#125;</span><br><span class="line">             &#125;);</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@description</span> 线程池的初始化  采用spring线程池   二选一</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> ThreadPoolTaskExecutor</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="meta">@Bean</span></span><br><span class="line"> <span class="keyword">public</span> ThreadPoolTaskExecutor <span class="title function_">threadPoolTaskExecutor</span><span class="params">()</span>&#123;</span><br><span class="line">   <span class="type">ThreadPoolTaskExecutor</span> <span class="variable">poolTask</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolTaskExecutor</span>();</span><br><span class="line">   poolTask.setCorePoolSize(loader.getCorePoolSize()); <span class="comment">//核心线程数</span></span><br><span class="line">   poolTask.setMaxPoolSize(loader.getMaxPoolSize()); <span class="comment">//最大线程数</span></span><br><span class="line">   poolTask.setQueueCapacity(loader.getQueueCapacity()); <span class="comment">//等待队列长度</span></span><br><span class="line">   poolTask.setKeepAliveSeconds(loader.getKeepAliveSeconds()); <span class="comment">//空闲线程存活时间</span></span><br><span class="line">   <span class="comment">//拒绝策略</span></span><br><span class="line">   poolTask.setRejectedExecutionHandler(<span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>.CallerRunsPolicy() &#123;</span><br><span class="line">     <span class="meta">@Override</span></span><br><span class="line">     <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">rejectedExecution</span><span class="params">(Runnable r, ThreadPoolExecutor executor)</span> &#123;</span><br><span class="line">       log.warn(<span class="string">&quot;注意,有任务超过线程池配置&quot;</span>);</span><br><span class="line">       <span class="keyword">if</span>(!executor.isShutdown()) &#123;</span><br><span class="line">         r.run();</span><br><span class="line">       &#125;</span><br><span class="line">     &#125;</span><br><span class="line">       &#125;);</span><br><span class="line">   <span class="keyword">return</span> poolTask;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<h2 id="五、ThreadPool工具类（单例）"><a href="#五、ThreadPool工具类（单例）" class="headerlink" title="五、ThreadPool工具类（单例）"></a>五、ThreadPool工具类（单例）</h2> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.ThreadPoolExecutor;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 线程池执行类  单例</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ThreadPoolManager</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">ThreadPoolManager</span><span class="params">()</span> &#123; &#125;</span><br><span class="line">    <span class="comment">//线程池</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">ThreadPoolExecutor</span> <span class="variable">threadPoolExecutor</span> <span class="operator">=</span>  SpringContextUtils.getBean(ThreadPoolExecutor.class);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">ThreadPoolManager</span> <span class="variable">me</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolManager</span>();</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> ThreadPoolManager <span class="title function_">me</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> me;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">execute</span><span class="params">(Runnable runnable)</span> &#123;</span><br><span class="line">        threadPoolExecutor.execute(runnable);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Description</span> 关闭线程池，不再接受新的任务，之前提交的任务等执行结束再关闭线程池</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> void</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">shutdown</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(!threadPoolExecutor.isShutdown()) &#123;</span><br><span class="line">            threadPoolExecutor.shutdown();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker教程</title>
    <url>/2021/e5328a360b66/</url>
    <content><![CDATA[<h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><p>Docker是一款针对程序开发人员和系统管理员来开发、部署、运行应用的一款虚拟化平台。Docker 可以让你像使用集装箱一样快速的组合成应用，并且可以像运输标准集装箱一样，尽可能的屏蔽代码层面的差异。Docker 会尽可能的缩短从代码测试到产品部署的时间。</p>
<span id="more"></span>

<h2 id="二、架构"><a href="#二、架构" class="headerlink" title="二、架构"></a>二、架构</h2><p>Docker 包括三个基本概念:</p>
<ul>
<li><strong>镜像（Image）</strong>：Docker 镜像（Image），就相当于是一个 root 文件系统。镜像是<strong>无状态的、只读的</strong> 。</li>
<li><strong>容器（Container）</strong>：镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。</li>
<li><strong>仓库（Repository）</strong>：仓库可看成一个代码控制中心，用来保存镜像。</li>
</ul>
<p>使用 <code>--link</code> 参数可以让容器之间安全的进行交互。</p>
<p><code>--link</code> 参数的格式为 <code>--link name:alias</code>，其中 <code>name</code> 是要链接的容器的名称，<code>alias</code> 是这个连接的别名（可选项）。</p>
<h2 id="三、网络模式"><a href="#三、网络模式" class="headerlink" title="三、网络模式"></a>三、网络模式</h2><p>docker的网络配置分为四种, <code>host</code>、<code>Container</code>、<code>None</code>、<code>Bridge(默认)</code>。</p>
<ul>
<li><p>  Bridge：为每一个容器分配、设置 IP 等，并将容器连接到一个 <code>docker0</code> 虚拟网桥，默认为该模式</p>
</li>
<li><p>  host：容器将不会虚拟出自己的网卡，配置自己的 IP 等，而是使用宿主机的 IP 和端口。</p>
</li>
<li><p>  Container：新创建的容器不会创建自己的网卡和配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。</p>
</li>
<li><p>  None： 容器有独立的 Network namespace，但并没有对其进行任何网络设置，如分配 veth pair 和网桥连接，IP 等。</p>
</li>
</ul>
<p>查看所有网络模式：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker network <span class="built_in">ls</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker network inspect bridge      <span class="comment"># 查看bridge 有哪些正在运行的容器</span></span></span><br></pre></td></tr></table></figure>



<h3 id="1、Bridge模式"><a href="#1、Bridge模式" class="headerlink" title="1、Bridge模式"></a>1、Bridge模式</h3><p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/4f5206a75a884cc2968ceb1f6c14acb6~tplv-k3u1fbpfcp-zoom-1.png" alt="img"></p>
<p>在该模式中，Docker 守护进程创建了一个虚拟以太网桥 <code>docker0</code>，新建的容器会自动桥接到这个接口，附加在其上的任何网卡之间都能自动转发数据包。</p>
<p>简单来说，这个模式容器通过docker0连接外网，外部需要通过映射端口连接容器，容器之前通过docker0访问。</p>
<p>缺点：docker0随机分配IP，容器IP不固定。</p>
<h3 id="2、host模式"><a href="#2、host模式" class="headerlink" title="2、host模式"></a>2、host模式</h3><p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/32ab62e6be9d4b4dbe9280ca3b9206f9~tplv-k3u1fbpfcp-zoom-1.png" alt="img"></p>
<p>采用 host 网络模式的 Docker Container，可以直接使用<strong>宿主机的 IP 地址</strong>与外界进行通信，若宿主机的 eth0 是一个公有 IP，那么容器也拥有这个公有 IP。同时容器内服务的端口也可以使用宿主机的端口，无需额外进行 NAT 转换；</p>
<p>host 网络模式可以让容器共享宿主机网络栈，这样的好处是外部主机与容器直接通信，但是容器的网络缺少隔离性，安全性降低。且会出现端口冲突，这个模式使用较少。</p>
<h3 id="3、none模式"><a href="#3、none模式" class="headerlink" title="3、none模式"></a>3、none模式</h3><p>none 网络模式是指禁用网络功能，只有 lo 接口 local 的简写，代表 127.0.0.1，即 localhost 本地环回接口。在创建容器时通过参数 <code>--net none</code> 或者 <code>--network none</code> 指定；</p>
<p>简单来说就是这个容器不联网。</p>
<h3 id="4、Container模式"><a href="#4、Container模式" class="headerlink" title="4、Container模式"></a>4、Container模式</h3><p><img src="https://jeremyhzf-blog.oss-cn-hongkong.aliyuncs.com/905bc296603243ad8ee09e13b651e5ba~tplv-k3u1fbpfcp-zoom-1.png" alt="img"></p>
<p><strong>Container 网络模式即新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等</strong>。</p>
<p>Docker 容器会共享一个网络栈，这样两个容器之间可以使用 localhost 高效快速通信。</p>
<blockquote>
<p>  参考： <a href="https://www.cnblogs.com/mrhelloworld/p/docker11.html">https://www.cnblogs.com/mrhelloworld/p/docker11.html</a></p>
</blockquote>
<h2 id="四、Docker命令"><a href="#四、Docker命令" class="headerlink" title="四、Docker命令"></a>四、Docker命令</h2><h3 id="容器生命周期管理"><a href="#容器生命周期管理" class="headerlink" title="容器生命周期管理"></a>容器生命周期管理</h3><h4 id="1、run-命令"><a href="#1、run-命令" class="headerlink" title="1、run 命令"></a>1、run 命令</h4><p>创建一个新的容器并运行一个命令</p>
<p><strong>语法:</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run [OPTIONS] IMAGE [COMMAND] [ARG...]</span></span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  <strong>-a stdin:</strong> 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项；</li>
<li>  <strong>-d:</strong> 后台运行容器，并返回容器ID；</li>
<li>  <strong>-i:</strong> 以交互模式运行容器，通常与 -t 同时使用；</li>
<li>  <strong>-P:</strong> 随机端口映射，容器内部端口<strong>随机</strong>映射到主机的端口</li>
<li>  <strong>-p:</strong> 指定端口映射，格式为：<strong>主机(宿主)端口:容器端口</strong></li>
<li>  <strong>-t:</strong> 为容器重新分配一个伪输入终端，通常与 -i 同时使用；</li>
<li>  <strong>–name=”nginx-lb”:</strong> 为容器指定一个名称；</li>
<li>  <strong>–dns 8.8.8.8:</strong> 指定容器使用的DNS服务器，默认和宿主一致；</li>
<li>  <strong>–dns-search example.com:</strong> 指定容器DNS搜索域名，默认和宿主一致；</li>
<li>  <strong>-h “mars”:</strong> 指定容器的hostname；</li>
<li>  <strong>-e username=”ritchie”:</strong> 设置环境变量；</li>
<li>  <strong>–env-file=[]:</strong> 从指定文件读入环境变量；</li>
<li>  <strong>–cpuset=”0-2” or –cpuset=”0,1,2”:</strong> 绑定容器到指定CPU运行；</li>
<li>  **-m :**设置容器使用内存最大值；</li>
<li>  <strong>–net=”bridge”:</strong> 指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型；</li>
<li>  <strong>–link=[]:</strong> 添加链接到另一个容器，可以让容器之间安全的进行交互。；</li>
<li>  <strong>–expose=[]:</strong> 开放一个端口或一组端口；</li>
<li>  <strong>–volume , -v:</strong> 绑定一个卷</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">运行一个wordpress容器</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run -p 8080:80 --name wordpress \                   <span class="comment"># 映射端口 本机端口:容器端口</span></span> </span><br><span class="line">-v /Users/zhengfa.hu/Docker/wordpress:/var/www/html \        # 绑定本机卷</span><br><span class="line">-e WORDPRESS_DB_PASSWORD=root \                              # 设置环境变量</span><br><span class="line">-e WORDPRESS_DB_HOST=mysql:3306 \                            # 设置环境变量</span><br><span class="line">--link mysql \                                               # 连接到mysql容器</span><br><span class="line">-d wordpress                                                 # -d 后台运行，镜像:&lt;版本&gt;</span><br></pre></td></tr></table></figure>

<h4 id="2、start-stop-restart-命令"><a href="#2、start-stop-restart-命令" class="headerlink" title="2、start/stop/restart 命令"></a>2、start/stop/restart 命令</h4><p>启动/停止/重启一个或多个容器。</p>
<p>实例：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker start $(docker ps -a | awk <span class="string">&#x27;&#123; print $1&#125;&#x27;</span> | <span class="built_in">tail</span> -n +2)     <span class="comment"># docker 启动所有的容器</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker stop $(docker ps -a | awk <span class="string">&#x27;&#123; print $1&#125;&#x27;</span> | <span class="built_in">tail</span> -n +2)      <span class="comment"># docker 关闭所有的容器</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker stop $(docker ps | awk <span class="string">&#x27;&#123; print $1&#125;&#x27;</span> | <span class="built_in">tail</span> -n +2)         <span class="comment"># 暂停所有正在运行的容器</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker restart $(docker ps | awk <span class="string">&#x27;&#123; print $1&#125;&#x27;</span> | <span class="built_in">tail</span> -n +2)      <span class="comment"># 重启所有正在运行的容器</span></span></span><br></pre></td></tr></table></figure>

<h4 id="3、kill-命令"><a href="#3、kill-命令" class="headerlink" title="3、kill 命令"></a>3、kill 命令</h4><p>杀掉一个运行中的容器。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker kill [OPTIONS] CONTAINER [CONTAINER...]</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **-s :**向容器发送一个信号</li>
</ul>
<p>实例：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker <span class="built_in">kill</span> -s KILL nginx</span></span><br></pre></td></tr></table></figure>

<h4 id="4、rm-命令"><a href="#4、rm-命令" class="headerlink" title="4、rm 命令"></a>4、rm 命令</h4><p>删除一个或多个容器。</p>
<p><strong>语法：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker <span class="built_in">rm</span> [OPTIONS] CONTAINER [CONTAINER...]</span></span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **-f :**通过 SIGKILL 信号强制删除一个运行中的容器。</li>
<li>  **-l :**移除容器间的网络连接，而非容器本身。</li>
<li>  **-v :**删除与容器关联的卷，容器也会删除。</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker <span class="built_in">rm</span> $(docker ps -a | awk <span class="string">&#x27;&#123; print $1&#125;&#x27;</span> | <span class="built_in">tail</span> -n +2)   <span class="comment"># docker 删除所有的容器</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker rmi $(docker images | awk <span class="string">&#x27;&#123;print $3&#125;&#x27;</span> |<span class="built_in">tail</span> -n +2)   <span class="comment"># docker 删除所有的镜像</span></span></span><br></pre></td></tr></table></figure>

<h4 id="5、pause-unpause-命令"><a href="#5、pause-unpause-命令" class="headerlink" title="5、pause/unpause 命令"></a>5、pause/unpause 命令</h4><p><strong>docker pause</strong> :暂停容器中所有的进程。</p>
<p><strong>docker unpause</strong> :恢复容器中所有的进程。</p>
<p><strong>语法：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker pause CONTAINER [CONTAINER...]</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker unpause CONTAINER [CONTAINER...]</span></span><br></pre></td></tr></table></figure>

<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker pause nginx            <span class="comment"># 暂停容器nginx提供服务</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker unpause nginx          <span class="comment"># 恢复容器nginx提供服务</span></span></span><br></pre></td></tr></table></figure>

<h4 id="6、create-命令"><a href="#6、create-命令" class="headerlink" title="6、create 命令"></a>6、create 命令</h4><p>创建一个新的容器但不启动它。用法同 [docker run](#1、run 命令) 。</p>
<h4 id="7、exec-命令"><a href="#7、exec-命令" class="headerlink" title="7、exec 命令"></a>7、exec 命令</h4><p>在运行的容器中执行命令</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec [OPTIONS] CONTAINER COMMAND [ARG...]</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **-d :**分离模式: 在后台运行</li>
<li>  **-i :**即使没有附加也保持STDIN 打开</li>
<li>  **-t :**分配一个伪终端</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker <span class="built_in">exec</span> -it &lt;容器ID或者容器name&gt; /bin/bash      <span class="comment"># 进入容器</span></span></span><br></pre></td></tr></table></figure>

<h4 id="8、commit-命令"><a href="#8、commit-命令" class="headerlink" title="8、commit 命令"></a>8、commit 命令</h4><p>从容器创建一个新的镜像。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **-a :**提交的镜像作者；</li>
<li>  **-c :**使用Dockerfile指令来创建镜像；</li>
<li>  **-m :**提交时的说明文字；</li>
<li>  **-p :**在commit时，将容器暂停。</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker commit -a <span class="string">&quot;runoob.com&quot;</span> -m <span class="string">&quot;my apache&quot;</span> mysql  mysql:v1    <span class="comment"># 将容器mysql 保存为新的镜像</span></span></span><br></pre></td></tr></table></figure>

<h3 id="容器操作"><a href="#容器操作" class="headerlink" title="容器操作"></a>容器操作</h3><h4 id="1、ps-命令"><a href="#1、ps-命令" class="headerlink" title="1、ps 命令"></a>1、ps 命令</h4><p>列出容器</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker ps [OPTIONS]</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **-a :**显示所有的容器，包括未运行的。</li>
<li>  **-f :**根据条件过滤显示的内容。</li>
<li>  **–format :**指定返回值的模板文件。</li>
<li>  **-l :**显示最近创建的容器。</li>
<li>  **-n :**列出最近创建的n个容器。</li>
<li>  **–no-trunc :**不截断输出。</li>
<li>  **-q :**静默模式，只显示容器编号。</li>
<li>  **-s :**显示总的文件大小。</li>
</ul>
<p>输出：</p>
<p>容器ID、镜像、启动容器时运行的命令、容器创建时间、容器状态、端口信息、容器名称</p>
<p>容器状态（七种）：</p>
<p>created已创建、restarting重启中、running运行中、removing迁移中、paused暂停、exited停止、dead死亡</p>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker ps -f <span class="string">&quot;name=nginx&quot;</span>             <span class="comment"># 根据名称过滤</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker ps -f status=running           <span class="comment"># 根据容器状态过滤</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker ps --filter ancestor=nginx     <span class="comment"># 根据镜像名称过滤</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker ps --filter ancestor=&lt;ID&gt;      <span class="comment"># 根据容器ID过滤</span></span></span><br></pre></td></tr></table></figure>

<h4 id="2、inspect-命令"><a href="#2、inspect-命令" class="headerlink" title="2、inspect 命令"></a>2、inspect 命令</h4><p>获取容器/镜像的元数据。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker inspect [OPTIONS] NAME|ID [NAME|ID...]</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **-f :**指定返回值的模板文件。</li>
<li>  **-s :**显示总的文件大小。</li>
<li>  **–type :**为指定类型返回JSON。</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取容器元数据，默认输出格式为JSON  --format 过滤输出ip</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker inspect --format=<span class="string">&#x27;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&#x27;</span> mysql</span></span><br></pre></td></tr></table></figure>

<h4 id="3、top-命令"><a href="#3、top-命令" class="headerlink" title="3、top 命令"></a>3、top 命令</h4><p>查看容器中运行的进程信息，支持 ps 命令参数。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker top [OPTIONS] CONTAINER [ps OPTIONS]</span><br></pre></td></tr></table></figure>

<p>参数支持<code>docker ps</code>。</p>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker top mysql</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker top ea59b5ae9693</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> i <span class="keyword">in</span>  `docker ps |grep Up|awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>`;<span class="keyword">do</span> <span class="built_in">echo</span> \ &amp;&amp;docker top <span class="variable">$i</span>; <span class="keyword">done</span></span></span><br></pre></td></tr></table></figure>

<h4 id="4、attach-命令"><a href="#4、attach-命令" class="headerlink" title="4、attach 命令"></a>4、attach 命令</h4><p>连接到正在运行中的容器。一般用不着，可以使用<code>exec</code> 。</p>
<h4 id="5、events-命令"><a href="#5、events-命令" class="headerlink" title="5、events 命令"></a>5、events 命令</h4><p>从服务器获取实时事件。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker events [OPTIONS]</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  <strong>-f ：</strong>根据条件过滤事件；</li>
<li>  <strong>–since ：</strong>从指定的时间戳后显示所有事件;</li>
<li>  <strong>–until ：</strong>流水时间显示到指定的时间为止；</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker events  --since=<span class="string">&quot;1467302400&quot;</span></span>            </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker events -f <span class="string">&quot;image&quot;</span>=<span class="string">&quot;mysql:5.6&quot;</span> --since=<span class="string">&quot;1467302400&quot;</span>  <span class="comment"># 显示mysql镜像相关的事件</span></span></span><br></pre></td></tr></table></figure>

<h4 id="6、logs-命令"><a href="#6、logs-命令" class="headerlink" title="6、logs 命令"></a>6、logs 命令</h4><p>获取容器的日志。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker logs [OPTIONS] CONTAINER</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  <strong>-f :</strong> 跟踪日志输出</li>
<li>  **–since :**显示某个开始时间的所有日志</li>
<li>  <strong>-t :</strong> 显示时间戳</li>
<li>  **–tail :**仅列出最新N条容器日志</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker logs -f mysql</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker logs --since=<span class="string">&quot;2016-07-01&quot;</span> --<span class="built_in">tail</span>=10 mysql</span></span><br></pre></td></tr></table></figure>

<h4 id="7、wait-命令"><a href="#7、wait-命令" class="headerlink" title="7、wait 命令"></a>7、wait 命令</h4><p>阻塞运行直到容器停止，然后打印出它的退出代码。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker <span class="built_in">wait</span> mysql</span></span><br></pre></td></tr></table></figure>

<h4 id="8、export-命令"><a href="#8、export-命令" class="headerlink" title="8、export 命令"></a>8、export 命令</h4><p>将文件系统作为一个tar归档文件导出到STDOUT。导出的是一个容器的快照。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker export [OPTIONS] CONTAINER</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **-o :**将输入内容写到文件。</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker <span class="built_in">export</span> -o mysql-`<span class="built_in">date</span> +%Y%m%d`.tar a404c6c174a2  <span class="comment"># 将容器按日期保存为tar文件</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> mysql-`<span class="built_in">date</span> +%Y%m%d`.tar</span></span><br><span class="line">mysql-20160711.tar</span><br></pre></td></tr></table></figure>

<h4 id="9、import-命令"><a href="#9、import-命令" class="headerlink" title="9、import 命令"></a>9、import 命令</h4><p>从归档文件来载入容器包，但会恢复为镜像。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **-c :**应用docker 指令创建镜像；</li>
<li>  **-m :**提交时的说明文字；</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker import  my_ubuntu_v3.tar runoob/ubuntu:v4</span>  </span><br></pre></td></tr></table></figure>

<blockquote>
<p>  export 和 import 导出的是一个容器的快照, 不是镜像本身, 也就是说没有 layer。</p>
<p>  你的 dockerfile 里的 workdir, entrypoint 之类的所有东西都会丢失，commit 过的话也会丢失。</p>
<p>  快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也更大。</p>
</blockquote>
<h4 id="10、port-命令"><a href="#10、port-命令" class="headerlink" title="10、port 命令"></a>10、port 命令</h4><p>列出指定的容器的端口映射，或者查找将PRIVATE_PORT NAT到面向公众的端口。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker port mysql             <span class="comment"># 查看容器的端口映射情况</span></span></span><br></pre></td></tr></table></figure>

<h4 id="11、stats-命令"><a href="#11、stats-命令" class="headerlink" title="11、stats 命令"></a>11、stats 命令</h4><p>显示容器资源的使用情况，包括：CPU、内存、网络 I/O 等。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker stats [OPTIONS] [CONTAINER...]</span><br></pre></td></tr></table></figure>

<p>OPTIONS 说明：</p>
<ul>
<li>  **–all , -a :**显示所有的容器，包括未运行的。</li>
<li>  **–format :**指定返回值的模板文件。</li>
<li>  **–no-stream :**展示当前状态就直接退出了，不再实时更新。</li>
<li>  **–no-trunc :**不截断输出。</li>
</ul>
<p>输出：</p>
<p>容器ID、容器name、CPU使用率、容器内存使用信息、内存使用率、网络IO发送/接收、容器-本机数据读取和写入数据量、容器创建的进程或线程数</p>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker stats mysql</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker stats &lt;ID&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker stats mysql --no-stream --format <span class="string">&quot;&#123;&#123; json . &#125;&#125;&quot;</span>    <span class="comment"># 以JSON格式输出</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker stats --all --no-stream --format <span class="string">&quot;table &#123;&#123;.Container&#125;&#125;\t&#123;&#123;.CPUPerc&#125;&#125;\t&#123;&#123;.MemUsage&#125;&#125;&quot;</span> mysql wordpress</span></span><br></pre></td></tr></table></figure>

<h4 id="12、cp-命令"><a href="#12、cp-命令" class="headerlink" title="12、cp 命令"></a>12、cp 命令</h4><p>用于容器与主机之间的数据拷贝。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker cp [OPTIONS]  CONTAINER:SRC_PATH   DEST_PATH  </span><br><span class="line">docker cp [OPTIONS]  SRC_PATH   CONTAINER:DEST_PATH</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **-L :**保持源目标中的链接</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将本机 ndnav 文件夹，拷贝到容器 themes/ 文件夹下</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker <span class="built_in">cp</span> /Downloads/ndnav wordpress:/var/www/html/wp-content/themes/</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将本机 ndnav 文件夹，拷贝到容器中并重命名为 ndnav-v1</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker <span class="built_in">cp</span> /Downloads/ndnav wordpress:/var/www/html/wp-content/themes/ndnav-v1</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将容器 themes 目录下的文件拷贝到主机的Downloads/目录下中。</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker <span class="built_in">cp</span> wordpress:/var/www/html/wp-content/themes/ /Downloads/</span> </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> /Downloads/themes/</span></span><br></pre></td></tr></table></figure>

<h4 id="13、diff-命令"><a href="#13、diff-命令" class="headerlink" title="13、diff 命令"></a>13、diff 命令</h4><p>检查容器里文件结构的更改。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker diff mysql       <span class="comment"># 查看容器mysql的文件结构更改</span></span></span><br></pre></td></tr></table></figure>

<h3 id="镜像仓库"><a href="#镜像仓库" class="headerlink" title="镜像仓库"></a>镜像仓库</h3><h4 id="1、login-logout-命令"><a href="#1、login-logout-命令" class="headerlink" title="1、login/logout 命令"></a>1、login/logout 命令</h4><p>登陆和登出Docker镜像仓库。如果未指定镜像仓库地址，默认是Docker Hub。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker login [OPTIONS] [SERVER]</span><br><span class="line">docker logout [OPTIONS] [SERVER]</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **-u :**登陆的用户名</li>
<li>  **-p :**登陆的密码</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker login -u 用户名 -p 密码 &lt;server&gt;           <span class="comment"># 登陆指定的镜像仓库</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker login -u 用户名 -p 密码</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker <span class="built_in">logout</span></span></span><br></pre></td></tr></table></figure>

<h4 id="2、pull-命令"><a href="#2、pull-命令" class="headerlink" title="2、pull 命令"></a>2、pull 命令</h4><p>从镜像仓库中拉取或者更新指定镜像。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker pull [OPTIONS] NAME[:TAG|@DIGEST]</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **-a :**拉取所有 tagged 镜像</li>
<li>  **–disable-content-trust :**忽略镜像的校验,默认开启</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker pull mysql:5.7</span></span><br></pre></td></tr></table></figure>

<h4 id="3、push-命令"><a href="#3、push-命令" class="headerlink" title="3、push 命令"></a>3、push 命令</h4><p>将本地的镜像上传到镜像仓库,要先登陆到镜像仓库。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker push [OPTIONS] NAME[:TAG]</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **–disable-content-trust :**忽略镜像的校验,默认开启</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker push mysql:5.7</span></span><br></pre></td></tr></table></figure>

<h4 id="4、search-命令"><a href="#4、search-命令" class="headerlink" title="4、search 命令"></a>4、search 命令</h4><p>从Docker Hub查找镜像</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker search [OPTIONS] TERM</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **–automated :**只列出 automated build类型的镜像；</li>
<li>  **–no-trunc :**显示完整的镜像描述；</li>
<li>  **-f &lt;过滤条件&gt;:**列出收藏数不小于指定值的镜像。</li>
</ul>
<p>参数：</p>
<p>NAME、DESCRIPTION描述、STARS、OFFICIAL是否是官方发布、AUTOMATED自动构建</p>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker search -f stars=10 java   <span class="comment"># 从Docker Hub查找所有镜像名包含 java，并且收藏数大于 10 的镜像</span></span></span><br></pre></td></tr></table></figure>

<h3 id="本地镜像操作"><a href="#本地镜像操作" class="headerlink" title="本地镜像操作"></a>本地镜像操作</h3><h4 id="1、images"><a href="#1、images" class="headerlink" title="1、images"></a>1、images</h4><p>列出本地镜像。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker images [OPTIONS] [REPOSITORY[:TAG]]</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **-a :**列出本地所有的镜像（含中间映像层，默认情况下，过滤掉中间映像层）；</li>
<li>  **–digests :**显示镜像的摘要信息；</li>
<li>  **-f :**显示满足条件的镜像；</li>
<li>  **–format :**指定返回值的模板文件；</li>
<li>  **–no-trunc :**显示完整的镜像信息；</li>
<li>  **-q :**只显示镜像ID。</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker images mysql           <span class="comment"># 查看mysql的本地镜像</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker images                 <span class="comment"># 查看所有本地镜像</span></span></span><br></pre></td></tr></table></figure>

<h4 id="2、rmi-命令"><a href="#2、rmi-命令" class="headerlink" title="2、rmi 命令"></a>2、rmi 命令</h4><p>删除本地一个或多个镜像。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker rmi [OPTIONS] IMAGE [IMAGE...]</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **-f :**强制删除；</li>
<li>  **–no-prune :**不移除该镜像的过程镜像，默认移除；</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker rmi -f mysql      <span class="comment"># 强制移除本地mysql镜像</span></span></span><br></pre></td></tr></table></figure>

<h4 id="3、tag-命令"><a href="#3、tag-命令" class="headerlink" title="3、tag 命令"></a>3、tag 命令</h4><p>用于给镜像打标签。不会产生新的镜像。</p>
<blockquote>
<p>  tag 打标签就是多了一个引用，镜像ID相同，所以删除的时候不能用ID去删除，需要按照Tag去删除引用。</p>
</blockquote>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG]</span><br></pre></td></tr></table></figure>

<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker tag nginx:latest  nginx:v1       <span class="comment"># TAG 标签v1</span></span></span><br></pre></td></tr></table></figure>

<h4 id="4、build-命令"><a href="#4、build-命令" class="headerlink" title="4、build 命令"></a>4、build 命令</h4><p>命令用于使用 Dockerfile 创建镜像。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker build [OPTIONS] PATH | URL | -</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **–build-arg=[] :**设置镜像创建时的变量；</li>
<li>  **–cpu-shares :**设置 cpu 使用权重；</li>
<li>  **–cpu-period :**限制 CPU CFS周期；</li>
<li>  **–cpu-quota :**限制 CPU CFS配额；</li>
<li>  **–cpuset-cpus :**指定使用的CPU id；</li>
<li>  **–cpuset-mems :**指定使用的内存 id；</li>
<li>  **–disable-content-trust :**忽略校验，默认开启；</li>
<li>  **-f :**指定要使用的Dockerfile路径；</li>
<li>  **–force-rm :**设置镜像过程中删除中间容器；</li>
<li>  **–isolation :**使用容器隔离技术；</li>
<li>  **–label=[] :**设置镜像使用的元数据；</li>
<li>  **-m :**设置内存最大值；</li>
<li>  **–memory-swap :**设置Swap的最大值为内存+swap，”-1”表示不限swap；</li>
<li>  **–no-cache :**创建镜像的过程不使用缓存；</li>
<li>  **–pull :**尝试去更新镜像的新版本；</li>
<li>  **–quiet, -q :**安静模式，成功后只输出镜像 ID；</li>
<li>  **–rm :**设置镜像成功后删除中间容器；</li>
<li>  **–shm-size :**设置/dev/shm的大小，默认值是64M；</li>
<li>  **–ulimit :**Ulimit配置。</li>
<li>  **–squash :**将 Dockerfile 中所有的操作压缩为一层。</li>
<li>  <strong>–tag, -t:</strong> 镜像的名字及标签，通常 name:tag 或者 name 格式；可以在一次构建中为一个镜像设置多个标签。</li>
<li>  <strong>–network:</strong> 默认 default。在构建期间设置RUN指令的网络模式</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker build -t runoob/ubuntu:v1 .          <span class="comment"># 使用当前目录的 Dockerfile 创建镜像，注意 .  符号</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker build github.com/creack/docker-firefox    <span class="comment"># 使用远程Dockerfile 文件创建镜像</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker build -f /path/to/a/Dockerfile .          <span class="comment"># -f 指定Dockerfile 的位置</span></span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>  在 Docker 守护进程执行 Dockerfile 中的指令前，首先会对 Dockerfile 进行语法检查，有语法错误时会返回</p>
</blockquote>
<h4 id="5、history-命令"><a href="#5、history-命令" class="headerlink" title="5、history 命令"></a>5、history 命令</h4><p>查看指定镜像的创建历史。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker history [OPTIONS] IMAGE</span><br></pre></td></tr></table></figure>

<p>OPTIONS说明：</p>
<ul>
<li>  **-H :**以可读的格式打印镜像大小和日期，默认为true；</li>
<li>  **–no-trunc :**显示完整的提交记录；</li>
<li>  **-q :**仅列出提交记录ID。</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker <span class="built_in">history</span> mysql:5.6</span></span><br></pre></td></tr></table></figure>

<h4 id="6、save-命令"><a href="#6、save-命令" class="headerlink" title="6、save 命令"></a>6、save 命令</h4><p>将指定镜像保存成 tar 归档文件。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker save [OPTIONS] IMAGE [IMAGE...]</span><br></pre></td></tr></table></figure>

<p>OPTIONS 说明：</p>
<ul>
<li>  **-o :**输出到的文件。</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将镜像 runoob/ubuntu:v3 生成 my_ubuntu_v3.tar</span> </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker save -o my_ubuntu_v3.tar runoob/ubuntu:v3</span></span><br></pre></td></tr></table></figure>

<h4 id="7、load-命令"><a href="#7、load-命令" class="headerlink" title="7、load 命令"></a>7、load 命令</h4><p>导入使用 <code>docker save</code> 命令导出的镜像。</p>
<p><strong>语法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker load [OPTIONS]</span><br></pre></td></tr></table></figure>

<p>OPTIONS 说明：</p>
<ul>
<li>  <strong>–input , -i :</strong> 指定导入的文件，代替 STDIN。</li>
<li>  <strong>–quiet , -q :</strong> 精简输出信息。</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker load &lt; busybox.tar.gz</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>  save 和 load 命令作用对象是镜像，export 和 import 命令作用对象是容器。</p>
</blockquote>
<h3 id="系统操作"><a href="#系统操作" class="headerlink" title="系统操作"></a>系统操作</h3><blockquote>
<p>  docker system [cmd]</p>
</blockquote>
<h4 id="1、info命令"><a href="#1、info命令" class="headerlink" title="1、info命令"></a>1、info命令</h4><p>显示 Docker 系统信息，包括镜像和容器数。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker system info</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker system info --format    <span class="comment"># 定义输出格式</span></span></span><br></pre></td></tr></table></figure>

<h4 id="2、df-命令"><a href="#2、df-命令" class="headerlink" title="2、df 命令"></a>2、df 命令</h4><p>整体磁盘的使用情况.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker system <span class="built_in">df</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker system <span class="built_in">df</span> -v        <span class="comment"># 显示详细信息</span></span></span><br></pre></td></tr></table></figure>

<h4 id="3、prune-命令"><a href="#3、prune-命令" class="headerlink" title="3、prune 命令"></a>3、prune 命令</h4><p>清理没有使用的数据，包括镜像数据，已经停止的容器。<strong>操作需谨慎</strong>。</p>
<p>语法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker system prune</span><br></pre></td></tr></table></figure>

<p>OPTIONS 说明：</p>
<ul>
<li>  <strong>–all</strong>  :删除所有未使用的图像，而不仅仅是悬垂的图像。</li>
<li>  <strong>–filter  :</strong> 筛选(e.g. ‘label=<key>=<value>‘)。</li>
<li>  <strong>–force，-f ：</strong> 不提示确认，强制删除。</li>
<li>  <strong>–volumes：</strong>  删除卷。</li>
</ul>
<p><strong>实例：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker system prune         <span class="comment"># 一次性清理多种类型的资源</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker image prune          <span class="comment"># 删除所有未被 tag 标记和未被容器使用的镜像</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker image prune -a       <span class="comment"># 删除所有未被容器使用的镜像</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker container prune      <span class="comment"># 删除所有停止运行的容器</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker volume prune         <span class="comment"># 删除所有未被挂载的卷</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker network prune        <span class="comment"># 删除 docker 所有资源</span></span></span><br></pre></td></tr></table></figure>

<h2 id="四、DockerFile"><a href="#四、DockerFile" class="headerlink" title="四、DockerFile"></a>四、DockerFile</h2><h3 id="1、概述"><a href="#1、概述" class="headerlink" title="1、概述"></a>1、概述</h3><p>Dockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。</p>
<p>Dockerfile 分为四部分：</p>
<ul>
<li>基础镜像信息</li>
<li>维护者信息</li>
<li>镜像操作指令</li>
<li>容器启动时执行指令</li>
</ul>
<h3 id="2、docker-build"><a href="#2、docker-build" class="headerlink" title="2、docker build"></a>2、docker build</h3><h4 id="2-1构建"><a href="#2-1构建" class="headerlink" title="2.1构建"></a>2.1构建</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker build [选项] &lt;上下文路径/URL/-&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker build -t nginx:v3 .      <span class="comment"># -t 指定镜像标签信息</span></span></span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>注意</strong>：该命令将读取指定路径下（包括子目录）的 Dockerfile，并将该路径下所有内容发送给 Docker 服务端，由服务端来创建镜像。因此<strong>一般建议放置 Dockerfile 的目录为空目录</strong>。也可以通过 <code>.dockerignore</code> 文件（每一行添加一条匹配模式）来让 Docker 忽略路径下的目录和文件。</p>
</blockquote>
<h4 id="2-2-docker-build的用法"><a href="#2-2-docker-build的用法" class="headerlink" title="2.2 docker build的用法"></a>2.2 docker build的用法</h4><p>直接用 Git repo 进行构建:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker build -t hello-world https://github.com/docker-library/hello-world.git  <span class="comment">#master:amd64/hello-world</span></span></span><br></pre></td></tr></table></figure>

<p>用给定的 tar 压缩包构建</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker build http://server/context.tar.gz</span></span><br></pre></td></tr></table></figure>

<p>从标准输入中读取 Dockerfile 进行构建</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker build - &lt; Dockerfile</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或者</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> Dockerfile | docker build -</span></span><br></pre></td></tr></table></figure>

<p>从标准输入中读取上下文压缩包进行构建</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker build - &lt; context.tar.gz</span></span><br></pre></td></tr></table></figure>

<h3 id="3、指令"><a href="#3、指令" class="headerlink" title="3、指令"></a>3、指令</h3><h4 id="2-1-FROM"><a href="#2-1-FROM" class="headerlink" title="2.1 FROM"></a>2.1 FROM</h4><p><strong>功能</strong>：构建镜像基于哪个镜像。</p>
<p>格式：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> &lt;image&gt; </span><br><span class="line"><span class="keyword">FROM</span> &lt;image&gt;:&lt;tag&gt;</span><br></pre></td></tr></table></figure>

<p>DockerFile第一条指令必须是FROM，同一个dockerfile中创建多个镜像时可以有多个FROM，但是不建议。</p>
<h4 id="2-2-EXPOSE"><a href="#2-2-EXPOSE" class="headerlink" title="2.2  EXPOSE"></a>2.2  EXPOSE</h4><p>暴露端口，但不映射到宿主机，只被连接的服务访问。</p>
<p>作用：</p>
<ul>
<li>帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射。</li>
<li>在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。</li>
</ul>
<p>格式：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">EXPOSE</span> &lt;port1&gt; [&lt;port2&gt;...]</span><br></pre></td></tr></table></figure>

<h4 id="2-3-LABEL"><a href="#2-3-LABEL" class="headerlink" title="2.3 LABEL"></a>2.3 LABEL</h4><p><strong>功能</strong>：指令用来给镜像以键值对的形式添加一些元数据。</p>
<p>格式： </p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">LABEL</span><span class="language-bash"> &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>可以给镜像添加多个 <em>LABEL</em>，<strong>需要注意的是：每条 LABEL 指令都会生成一个新的层</strong>。所以最好是把添加的多个 <em>LABEL</em> 合并为一条命令</p>
</blockquote>
<h4 id="2-4-ENV"><a href="#2-4-ENV" class="headerlink" title="2.4 ENV"></a>2.4 ENV</h4><p><strong>功能</strong>：设置环境变量，定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。</p>
<p>格式：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ENV</span> &lt;key&gt; &lt;value&gt;</span><br><span class="line"><span class="keyword">ENV</span> &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;...</span><br></pre></td></tr></table></figure>

<p>设置环境变量，定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ENV</span> NODE_VERSION <span class="number">7.2</span>.<span class="number">0</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> curl -SLO <span class="string">&quot;https://nodejs.org/dist/v<span class="variable">$NODE_VERSION</span>/node-v<span class="variable">$NODE_VERSION</span>-linux-x64.tar.xz&quot;</span> \</span></span><br><span class="line"><span class="language-bash">  &amp;&amp; curl -SLO <span class="string">&quot;https://nodejs.org/dist/v<span class="variable">$NODE_VERSION</span>/SHASUMS256.txt.asc&quot;</span></span></span><br></pre></td></tr></table></figure>

<h4 id="2-5-ARG"><a href="#2-5-ARG" class="headerlink" title="2.5 ARG"></a>2.5 ARG</h4><p><strong>功能</strong>：构建参数，与 ENV 作用一致。不过作用域不一样。ARG 设置的环境变量仅对 Dockerfile 内有效，也就是说只有 docker build 的过程中有效，构建好的<strong>镜像内不存在此环境变量</strong>。</p>
<p>构建命令 docker build 中可以用 –build-arg &lt;参数名&gt;=&lt;值&gt; 来覆盖。</p>
<p>格式：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ARG</span> &lt;参数名&gt;[=&lt;默认值&gt;]</span><br></pre></td></tr></table></figure>

<h4 id="2-6-WORKDIR"><a href="#2-6-WORKDIR" class="headerlink" title="2.6 WORKDIR"></a>2.6 WORKDIR</h4><p><strong>功能</strong>：指定工作目录（进入容器时的目录）。用 WORKDIR 指定的工作目录，会在构建镜像的每一层中都存在。（WORKDIR 指定的工作目录，必须是提前创建好的）。</p>
<p>docker build 构建镜像过程中的，每一个 RUN 命令都是新建的一层。只有通过 WORKDIR 创建的目录才会一直存在。</p>
<p>格式：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> &lt;工作目录路径&gt;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>通过WORKDIR设置工作目录后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT、ADD、COPY  等命令都会在该目录下执行。在使用docker run运行容器时，可以通过-w参数覆盖构建时所设置的工作目录。</p>
</blockquote>
<h4 id="2-7-COPY"><a href="#2-7-COPY" class="headerlink" title="2.7 COPY"></a>2.7 COPY</h4><p><strong>功能</strong>：复制指令，从上下文目录中复制文件或者目录到容器里指定路径。</p>
<p>格式：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">COPY</span><span class="language-bash"> [--<span class="built_in">chown</span>=&lt;user&gt;:&lt;group&gt;] &lt;源路径1&gt;...  &lt;目标路径&gt;</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> [--<span class="built_in">chown</span>=&lt;user&gt;:&lt;group&gt;] [<span class="string">&quot;&lt;源路径1&gt;&quot;</span>,...  <span class="string">&quot;&lt;目标路径&gt;&quot;</span>]</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>**[–chown=<user>:<group>]**：可选参数，用户改变复制到容器内文件的拥有者和属组。</p>
</blockquote>
<p>**&lt;源路径&gt;**：源文件或者源目录，这里可以是通配符表达式，其通配符规则要满足 Go 的 filepath.Match 规则。</p>
<p><strong>&lt;目标路径&gt;<strong>：容器内的指定路径，该路径不用事先建好，路径不存在的话，</strong>会自动创建</strong>。</p>
<h4 id="2-8-ADD"><a href="#2-8-ADD" class="headerlink" title="2.8  ADD"></a>2.8  ADD</h4><p>ADD 指令和 COPY 的使用格类似（同样需求下，<strong>官方推荐使用 COPY</strong>）。功能也类似，不同之处如下：</p>
<ul>
<li>ADD 的优点：在执行 &lt;源文件&gt; 为 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，会<strong>自动复制并解压</strong>到 &lt;目标路径&gt;。</li>
<li>ADD 的缺点：在不解压的前提下，无法复制 tar 压缩文件。会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。具体是否使用，可以根据是否需要自动解压来决定。</li>
</ul>
<h4 id="2-9-VOLUME"><a href="#2-9-VOLUME" class="headerlink" title="2.9  VOLUME"></a>2.9  VOLUME</h4><p><strong>功能</strong>：定义匿名数据卷。在启动容器时忘记挂载数据卷，会自动挂载到匿名卷。</p>
<p>作用：</p>
<ul>
<li>避免重要的数据，因容器重启而丢失，这是非常致命的。</li>
<li>避免容器不断变大。</li>
</ul>
<p>格式：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">VOLUME</span><span class="language-bash"> [<span class="string">&quot;&lt;path1&gt;&quot;</span>, <span class="string">&quot;&lt;path2&gt;&quot;</span>...]</span></span><br><span class="line"><span class="keyword">VOLUME</span><span class="language-bash"> &lt;path&gt;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p> <path>指定的是容器内的目录。本地目录是：/var/lib/docker/volumes/{容器ID} 。    </p>
</blockquote>
<p>在启动容器 docker run 的时候，我们可以通过 -v 参数修改挂载点。   </p>
<blockquote>
<p><strong>总结</strong>： volume只是指定了一个目录，用以在用户忘记启动时指定 -v 参数也可以保证容器的正常运行。比如mysql，你不能说用户启动时没有指定 -v ，然后删了容器，就把mysql的数据文件都删了，那样生产上是会出大事故的，所以mysql的dockerfile里面就需要配置 volume，这样即使用户没有指定 -v ，容器被删后也不会导致数据文件都不在了。还是可以恢复的。</p>
</blockquote>
<h4 id="2-10-RUN"><a href="#2-10-RUN" class="headerlink" title="2.10 RUN"></a>2.10 RUN</h4><p><strong>功能</strong>：为构建的镜像指定要运行的<strong>命令行命令</strong>，而这些命令是在 <code>docker build</code> 时执行的。</p>
<p>格式：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># shell格式</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> &lt;<span class="built_in">command</span>&gt;</span></span><br><span class="line"><span class="comment"># exec格式</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> [<span class="string">&quot;executable&quot;</span>, <span class="string">&quot;param1&quot;</span>, <span class="string">&quot;param2&quot;</span>, ...]</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>每条 RUN 指令将在当前镜像的基础上执行指定命令，并提交为新的镜像，而 <strong>Dockerfile 的指令每执行一次都会在 docker 上新建一层，过多无意义的层，会造成镜像膨胀过大</strong>，所以建议将多个命令合并到同一个 <em>RUN</em> 指令上</p>
</blockquote>
<h4 id="2-11-CMD"><a href="#2-11-CMD" class="headerlink" title="2.11 CMD"></a>2.11 CMD</h4><p>类似于 RUN 指令，用于运行程序，但二者运行的时间点不同:</p>
<ul>
<li>CMD 在docker run 时运行。</li>
<li>RUN 是在 docker build。</li>
</ul>
<p><strong>作用</strong>：为启动的容器指定默认要运行的程序，程序运行结束，容器也就结束。CMD 指令指定的程序可被 docker run 命令行参数中指定要运行的程序所覆盖。</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1、shell 命令格式</span></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> &lt;shell <span class="built_in">command</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、exec 命令格式：推荐 ,默认执行文件是 sh。</span></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> [<span class="string">&quot;&lt;可执行文件或命令&gt;&quot;</span>,<span class="string">&quot;&lt;param1&gt;&quot;</span>,<span class="string">&quot;&lt;param2&gt;&quot;</span>,...] </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、该写法是为 ENTRYPOINT 指令指定的程序提供默认参数</span></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> [<span class="string">&quot;&lt;param1&gt;&quot;</span>,<span class="string">&quot;&lt;param2&gt;&quot;</span>,...]  </span></span><br></pre></td></tr></table></figure>

<p><strong>注意</strong>：</p>
<ul>
<li>如果 Dockerfile 中如果存在多个 CMD 指令，仅最后一个生效。</li>
<li>如果 <code>docker run</code> 命令行参数中指定了要运行的程序命令，则会覆盖<em>CMD</em> 指令指定的程序命令。</li>
</ul>
<h4 id="2-12-ENTRYPOINT"><a href="#2-12-ENTRYPOINT" class="headerlink" title="2.12 ENTRYPOINT"></a>2.12 ENTRYPOINT</h4><p><strong>功能</strong>：类似于 CMD 指令，但其不会被 docker run 的命令行参数指定的指令所覆盖，而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序。</p>
<p>但是, 如果运行 docker run 时使用了 –entrypoint 选项，将覆盖 ENTRYPOINT 指令指定的程序。</p>
<p><strong>优点</strong>：在执行 docker run 的时候可以指定 ENTRYPOINT 运行所需的参数。</p>
<p> <strong>注意</strong>：如果 Dockerfile 中如果存在多个 ENTRYPOINT 指令，仅最后一个生效。</p>
<p>格式：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ENTRYPOINT</span><span class="language-bash"> [<span class="string">&quot;&lt;executeable&gt;&quot;</span>,<span class="string">&quot;&lt;param1&gt;&quot;</span>,<span class="string">&quot;&lt;param2&gt;&quot;</span>,...]</span></span><br></pre></td></tr></table></figure>

<p>可以搭配 CMD 命令使用：一般是变参才会使用 CMD ，这里的 CMD 等于是在给 ENTRYPOINT 传参，以下示例会提到。</p>
<p>示例：</p>
<p>假设已通过 Dockerfile 构建了 nginx:test 镜像：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> nginx</span><br><span class="line"></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="language-bash"> [<span class="string">&quot;nginx&quot;</span>, <span class="string">&quot;-c&quot;</span>] <span class="comment"># 定参</span></span></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> [<span class="string">&quot;/etc/nginx/nginx.conf&quot;</span>] <span class="comment"># 变参 </span></span></span><br></pre></td></tr></table></figure>

<p>1、不传参运行</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run  nginx:<span class="built_in">test</span></span></span><br></pre></td></tr></table></figure>

<p>容器内会默认运行以下命令，启动主进程。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">nginx -c /etc/nginx/nginx.conf</span></span><br></pre></td></tr></table></figure>

<p>2、传参运行</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run  nginx:<span class="built_in">test</span> -c /etc/nginx/new.conf</span></span><br></pre></td></tr></table></figure>

<p>容器内会默认运行以下命令，启动主进程(/etc/nginx/new.conf:假设容器内已有此文件)</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">nginx -c /etc/nginx/new.conf</span></span><br></pre></td></tr></table></figure>

<h4 id="2-13-HEALTHCHECK"><a href="#2-13-HEALTHCHECK" class="headerlink" title="2.13 HEALTHCHECK"></a>2.13 HEALTHCHECK</h4><p><strong>功能</strong>：用于指定某个程序或者指令来监控 docker 容器服务的运行状态。</p>
<p>格式：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">HEALTHCHECK</span><span class="language-bash"> [选项] CMD &lt;命令&gt;：设置检查容器健康状况的命令</span></span><br><span class="line"><span class="keyword">HEALTHCHECK</span><span class="language-bash"> NONE：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令</span></span><br><span class="line"><span class="keyword">HEALTHCHECK</span><span class="language-bash"> [选项] CMD &lt;命令&gt; : 这边 CMD 后面跟随的命令使用，可以参考 CMD 的用法。</span></span><br></pre></td></tr></table></figure>

<h4 id="2-14-USER"><a href="#2-14-USER" class="headerlink" title="2.14 USER"></a>2.14 USER</h4><p><strong>功能</strong>：用于指定执行后续命令的用户和用户组，这边只是切换后续命令执行的用户（用户和用户组必须提前已经存在）。</p>
<p>可以使用用户名、UID或GID。</p>
<p>格式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">USER &lt;user&gt;[:&lt;group&gt;]</span><br></pre></td></tr></table></figure>

<h4 id="2-15-ONBUILD"><a href="#2-15-ONBUILD" class="headerlink" title="2.15 ONBUILD"></a>2.15 ONBUILD</h4><p><strong>功能：</strong>触发器。 用于延迟构建命令的执行。简单的说，就是 Dockerfile 里用 ONBUILD 指定的命令，在本次构建镜像的过程中不会执行（假设镜像为 test-build）。当有新的 Dockerfile 使用了之前构建的镜像 FROM test-build ，这时执行新镜像的 Dockerfile 构建时候，会执行 test-build 的 Dockerfile 里的 ONBUILD 指定的命令。</p>
<p>格式：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ONBUILD</span> [INSTRUCTION]</span><br></pre></td></tr></table></figure>

<h3 id="3-DockerFile模版"><a href="#3-DockerFile模版" class="headerlink" title="3. DockerFile模版"></a>3. DockerFile模版</h3><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> node:<span class="number">7</span>-alpine  </span><br><span class="line"><span class="keyword">LABEL</span><span class="language-bash"> maintainer <span class="string">&quot;jakub.skalecki@example.com&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> PROJECT_DIR=/app  </span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> <span class="variable">$PROJECT_DIR</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> package.json <span class="variable">$PROJECT_DIR</span>  </span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> npm install  </span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> . <span class="variable">$PROJECT_DIR</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> MEDIA_DIR=/media \  </span><br><span class="line">    NODE_ENV=production \</span><br><span class="line">    APP_PORT=<span class="number">3000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">VOLUME</span><span class="language-bash"> <span class="variable">$MEDIA_DIR</span>  </span></span><br><span class="line"><span class="keyword">EXPOSE</span> $APP_PORT  </span><br><span class="line"><span class="comment"># 健康检查， 如果一切正常的话返回 0，否则返回 1：</span></span><br><span class="line"><span class="keyword">HEALTHCHECK</span><span class="language-bash"> CMD curl --fail http://localhost:<span class="variable">$APP_PORT</span> || <span class="built_in">exit</span> 1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="language-bash"> [<span class="string">&quot;./entrypoint.sh&quot;</span>]  </span></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> [<span class="string">&quot;start&quot;</span>]</span></span><br></pre></td></tr></table></figure>

<h2 id="五、Docker-Compose"><a href="#五、Docker-Compose" class="headerlink" title="五、Docker Compose"></a>五、Docker Compose</h2><h3 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h3><p>Compose 是用于定义和运行多容器 Docker 应用程序的工具。通过 Compose，您可以使用 YML 文件来配置应用程序需要的所有服务。然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。</p>
<p><code>Compose</code> 中有两个重要的概念：</p>
<ul>
<li>服务 (<code>service</code>)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。</li>
<li>项目 (<code>project</code>)：由一组关联的应用容器组成的一个完整业务单元，在 <code>docker-compose.yml</code> 文件中定义。</li>
</ul>
<h3 id="2、命令说明"><a href="#2、命令说明" class="headerlink" title="2、命令说明"></a>2、命令说明</h3><h4 id="2-1-基本格式"><a href="#2-1-基本格式" class="headerlink" title="2.1 基本格式"></a>2.1 基本格式</h4><p><code>docker-compose</code> 命令的基本的使用格式是</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker-compose [-f=&lt;arg&gt;...] [options] [COMMAND] [ARGS...]</span></span><br></pre></td></tr></table></figure>

<h4 id="2-2-命令选项"><a href="#2-2-命令选项" class="headerlink" title="2.2 命令选项"></a>2.2 命令选项</h4><ul>
<li><code>-f, --file FILE</code> 指定使用的 Compose 模板文件，默认为 <code>docker-compose.yml</code>，可以多次指定。</li>
<li><code>-p, --project-name NAME</code> 指定项目名称，默认将使用所在目录名称作为项目名。</li>
<li><code>--verbose</code> 输出更多调试信息。</li>
<li><code>-v, --version</code> 打印版本并退出。</li>
</ul>
<h4 id="2-3-常用命令"><a href="#2-3-常用命令" class="headerlink" title="2.3 常用命令"></a>2.3 常用命令</h4><blockquote>
<p>  基本跟docker 容器操作命令类似，基本都有</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker-compose --<span class="built_in">help</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker-compose up        <span class="comment"># -d 后台启动应用，推荐生产环境后台启动</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">链接的服务都将会被自动启动，除非已经处于运行状态。</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker-compose down      <span class="comment"># 此命令将会停止 up 命令所启动的容器，并容器、网络、卷、镜像</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker-compose ps        <span class="comment"># 列出项目中的所有容器。</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker-compose config    <span class="comment"># 检验compose文件</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker-compose port      <span class="comment"># 打印某个容器所映射的公共端口</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-f 可以指定不同yml文件模板用于构建镜像</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker-compose build     <span class="comment"># 服务容器一旦构建后，将会带上一个标记名</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">指定服务运行的数量</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker-compose scale web=3 db=2    <span class="comment"># 启动3个web服务，2个db服务</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">一般的，当指定数目多于该服务当前实际运行容器，将新创建并启动容器；反之，将停止容器。</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>  默认情况，如果服务容器已经存在，<code>docker-compose up</code> 将会尝试停止容器，然后重新创建（保持使用 <code>volumes-from</code> 挂载的卷），以保证新启动的服务匹配 <code>docker-compose.yml</code> 文件的最新内容。如果用户不希望容器被停止并重新创建，可以使用 <code>docker-compose up --no-recreate</code>。这样将只会启动处于停止状态的容器，而忽略已经运行的服务。如果用户只想重新部署某个服务，可以使用 <code>docker-compose up --no-deps -d &lt;SERVICE_NAME&gt;</code> 来重新创建服务并后台停止旧服务，启动新服务，并不会影响到其所依赖的服务。</p>
</blockquote>
<h3 id="3、使用"><a href="#3、使用" class="headerlink" title="3、使用"></a>3、使用</h3><p>Compose 使用的三个步骤：</p>
<ul>
<li>使用 Dockerfile 定义应用程序的环境。</li>
<li>使用 docker-compose.yml 定义构成应用程序的服务，这样它们可以在隔离环境中一起运行。</li>
<li>最后，执行 docker-compose up 命令来启动并运行整个应用程序。</li>
</ul>
<h3 id="Compose-模板文件"><a href="#Compose-模板文件" class="headerlink" title="Compose 模板文件"></a>Compose 模板文件</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&quot;3&quot;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">web1:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">bc-mall</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">server1</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">on-failure</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;./config/config.env:/root/config/config.env&quot;</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;8093:8093&quot;</span></span><br><span class="line">    <span class="attr">network_mode:</span> <span class="string">bridge</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">web2:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">bc-mall</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">server2</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">on-failure</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;./config/config1.env:/root/config/config.env&quot;</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;8094:8094&quot;</span></span><br><span class="line">    <span class="attr">network_mode:</span> <span class="string">bridge</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">web3:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">bc-mall</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">server3</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">on-failure</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;./config/config2.env:/root/config/config.env&quot;</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;8095:8095&quot;</span></span><br><span class="line">    <span class="attr">network_mode:</span> <span class="string">bridge</span></span><br></pre></td></tr></table></figure>

<h3 id="Docker-compose-yml配置文件"><a href="#Docker-compose-yml配置文件" class="headerlink" title="Docker-compose.yml配置文件"></a>Docker-compose.yml配置文件</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"> <span class="comment"># 第一部分: Building(构建镜像)</span></span><br><span class="line"> <span class="attr">web:</span></span><br><span class="line">  <span class="comment"># 使用当前目录下的Dockerfile</span></span><br><span class="line">  <span class="attr">build:</span> <span class="string">.</span></span><br><span class="line">  <span class="attr">args:</span> <span class="comment"># 增加额外参数</span></span><br><span class="line">    <span class="attr">APP_HOME:</span> <span class="string">app</span></span><br><span class="line">  <span class="attr">volumes:</span> <span class="comment"># 目录挂载</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">.:/code</span></span><br><span class="line">  <span class="attr">depends_on:</span> <span class="comment"># 依赖db和redis</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">db</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">redis</span></span><br><span class="line">    </span><br><span class="line">  <span class="comment"># 使用定制化的Dockerfile，指定新目录相对路径和文件名</span></span><br><span class="line">  <span class="attr">build:</span></span><br><span class="line">    <span class="attr">context:</span> <span class="string">./dir</span> </span><br><span class="line">    <span class="attr">dockerfile:</span> <span class="string">Dockerfile.dev</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">app</span> <span class="comment"># 自定义容器名</span></span><br><span class="line">    </span><br><span class="line">  <span class="comment"># 基于现有镜像构建</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">ubuntu</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">ubuntu:14.04</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">remote-registry:4000/postgresql</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">bcbc65fd</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 第二部分: Ports(端口)</span></span><br><span class="line">  <span class="attr">ports:</span> <span class="comment"># 指定端口映射，HOST:Container</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;6379&quot;</span> <span class="comment"># 指定容器的端口6379，宿主机会随机映射端口</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;8080:80&quot;</span>  <span class="comment"># 宿主机端口8080，对应容器80</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 暴露端口给-link或处于同一网络的容器，不暴露给宿主机。</span></span><br><span class="line">  <span class="attr">expose:</span> [<span class="string">&quot;3000&quot;</span>]</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 第三部分: Environment Variables(环境变量)</span></span><br><span class="line">  <span class="attr">environment:</span></span><br><span class="line">    <span class="attr">MODE:</span> <span class="string">development</span></span><br><span class="line">    <span class="attr">SHOW:</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">    </span><br><span class="line">  <span class="comment"># 等同于</span></span><br><span class="line">  <span class="attr">environment:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">MODE=development</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">SHOW:</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 使用环境变量.env文件</span></span><br><span class="line">  <span class="attr">env_file:</span> <span class="string">.env</span></span><br><span class="line">  <span class="attr">env_file:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">./common.env</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">./apps/web.env</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 第四部分：commands (命令)</span></span><br><span class="line">  <span class="comment"># 容器启动后默认执行命令</span></span><br><span class="line">  <span class="attr">command:</span> <span class="string">bundle</span> <span class="string">exec</span> <span class="string">thin</span> <span class="string">-p</span> <span class="number">3000</span></span><br><span class="line">  <span class="attr">command:</span> [<span class="string">&#x27;/bin/bash/&#x27;</span>, <span class="string">&#x27;start.sh&#x27;</span>]</span><br><span class="line"> </span><br><span class="line">  <span class="comment"># 容器启动后程序入口</span></span><br><span class="line">  <span class="attr">entrypoint:</span> <span class="string">/code/entrypoint.sh</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 第五部分：Networks(网络)</span></span><br><span class="line">  <span class="attr">networks:</span> <span class="comment"># 使用bridge驱动创建名为frontend的网络</span></span><br><span class="line">    <span class="attr">frontend:</span></span><br><span class="line">      <span class="attr">driver:</span> <span class="string">bridge</span></span><br><span class="line">    </span><br><span class="line">    <span class="attr">networks:</span> <span class="comment"># 使用创建的网络进行通信</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">frontend</span></span><br><span class="line">      </span><br><span class="line">    <span class="comment"># 加入已经存在的外部网络</span></span><br><span class="line">    <span class="attr">networks:</span> </span><br><span class="line">      <span class="attr">default:</span></span><br><span class="line">        <span class="attr">external:</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">my-pre-existing-network</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 第六部分：Volumes(数据卷)</span></span><br><span class="line">  <span class="attr">volumes:</span> <span class="comment"># 创建名为postgres_data的数据卷</span></span><br><span class="line">    <span class="attr">postgres_data:</span></span><br><span class="line">    </span><br><span class="line">    <span class="attr">db:</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">postgres:latest</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">postgres_data:/var/lib/postgresql/data</span></span><br><span class="line">      </span><br><span class="line">  <span class="comment"># 第七部分：External Links(外部链接)</span></span><br><span class="line">  <span class="comment"># 目的是让Compose能够连接那些不在docker-compose.yml中定义的单独运行容器</span></span><br><span class="line">  <span class="attr">services:</span></span><br><span class="line">    <span class="attr">web:</span></span><br><span class="line">      <span class="attr">external_links:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">redis_1</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">project_db_1:mysql</span></span><br></pre></td></tr></table></figure>

<h2 id="六、etcd"><a href="#六、etcd" class="headerlink" title="六、etcd"></a>六、etcd</h2><blockquote>
<p><a href="https://www.kancloud.cn/roeslys/linux/1593364">https://www.kancloud.cn/roeslys/linux/1593364</a></p>
</blockquote>
<p>简介：Etcd 是什么</p>
<ul>
<li>etcd是一个分布式可靠的键值存储，用于分布式系统的最关键数据，重点是：</li>
</ul>
<p>1.<em>简单</em>：定义明确，面向用户的API（gRPC）</p>
<p>2.<em>安全</em>：具有可选客户端证书身份验证的自动TLS</p>
<p>3.<em>快速</em>：基准测试10,000次/秒</p>
<p>4.<em>可靠</em>：使用Raft一致性算法分布集群</p>
<ul>
<li>etcd是用Go编写的，使用<a href="https://raft.github.io/">Raft</a>一致性算法来管理高度可用的复制日志。</li>
<li>etcd被<a href="https://github.com/coreos/etcd/blob/master/Documentation/production-users.md">许多公司</a>用于<a href="https://github.com/coreos/etcd/blob/master/Documentation/production-users.md">生产</a>，开发团队在关键部署场景中支持它，其中etcd经常与<a href="http://kubernetes.io/">Kubernetes</a>，<a href="https://github.com/coreos/locksmith">locksmith</a>，<a href="https://github.com/vulcand/vulcand">vulcand</a>，<a href="https://github.com/youtube/doorman">Doorman</a>等许多应用程序配合使用。通过<strong>严格的测试</strong>进一步确保可靠性。</li>
<li>有关简单的命令行客户端，请参阅<a href="https://github.com/coreos/etcd/tree/master/etcdctl">etcdctl</a>(etcdctl –helper)</li>
</ul>
<h3 id="一、ETCD单机部署"><a href="#一、ETCD单机部署" class="headerlink" title="一、ETCD单机部署"></a>一、ETCD单机部署</h3><h5 id="1、下载二进制包"><a href="#1、下载二进制包" class="headerlink" title="1、下载二进制包"></a>1、下载二进制包</h5><p><a href="https://github.com/coreos/etcd/releases">https://github.com/coreos/etcd/releases</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://github.com/etcd-io/etcd/releases/download/v3.3.12/etcd-v3.3.12-linux-arm64.tar.gz</span><br></pre></td></tr></table></figure>

<h5 id="2、解压缩"><a href="#2、解压缩" class="headerlink" title="2、解压缩"></a>2、解压缩</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tar -zxvf etcd-v3.3.12-linux-arm64.tar.gz</span><br></pre></td></tr></table></figure>

<h5 id="3、设置环境变量"><a href="#3、设置环境变量" class="headerlink" title="3、设置环境变量"></a>3、设置环境变量</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export ETCDPATH=&quot;/home/etcd/etcd-v3.3.12-linux-amd64&quot;</span><br><span class="line"></span><br><span class="line">export ETCDCTL_API=3</span><br><span class="line"></span><br><span class="line">export PATH=&quot;$PATH:$ETCDPATH&quot;</span><br></pre></td></tr></table></figure>

<h5 id="4、启动etcd"><a href="#4、启动etcd" class="headerlink" title="4、启动etcd"></a>4、启动etcd</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">etcd --data-dir $ETCDPATH/test_data</span><br></pre></td></tr></table></figure>

<h5 id="5、客户端测试"><a href="#5、客户端测试" class="headerlink" title="5、客户端测试"></a>5、客户端测试</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">etcdctl --endpoints=http://127.0.0.1:2379 put foo bar</span><br><span class="line"></span><br><span class="line">etcdctl --endpoints=http://127.0.0.1:2379 get foo</span><br><span class="line">[root@bogon /]# etcdctl --endpoints=http://127.0.0.1:2379 put foo bar</span><br><span class="line">OK</span><br><span class="line">[root@bogon /]# etcdctl --endpoints=http://127.0.0.1:2379 get foo</span><br><span class="line">foo</span><br><span class="line">bar</span><br></pre></td></tr></table></figure>

<h3 id="二、docker单机部署ETCD"><a href="#二、docker单机部署ETCD" class="headerlink" title="二、docker单机部署ETCD"></a>二、docker单机部署ETCD</h3><h5 id="1、拉取etcd镜像"><a href="#1、拉取etcd镜像" class="headerlink" title="1、拉取etcd镜像"></a>1、拉取etcd镜像</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker pull quay.io/coreos/etcd:v3.3.9</span><br></pre></td></tr></table></figure>

<h5 id="2、设置环境变量和监听地址"><a href="#2、设置环境变量和监听地址" class="headerlink" title="2、设置环境变量和监听地址"></a>2、设置环境变量和监听地址</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-e ETCDCTL_API=3</span><br><span class="line"></span><br><span class="line">-p 2379:2379 -p 2380:2380</span><br></pre></td></tr></table></figure>

<h5 id="3、运行etcd容器"><a href="#3、运行etcd容器" class="headerlink" title="3、运行etcd容器"></a>3、运行etcd容器</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d -it --rm \</span><br><span class="line">--name etcd_test \</span><br><span class="line">-e ETCDCTL_API=3 \</span><br><span class="line">-p 2379:2379 \</span><br><span class="line">-p 2380:2380 \</span><br><span class="line">quay.io/coreos/etcd:v3.3.9 \</span><br><span class="line">etcd \</span><br><span class="line">--advertise-client-urls http://0.0.0.0:2379 \</span><br><span class="line">--listen-client-urls http://0.0.0.0:2379</span><br></pre></td></tr></table></figure>

<p>容器退出自动删除rm</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@bogon etcd]# docker run -d -it --rm --name etcd_test -e ETCDCTL_API=3 -p 2379:2379 -p 2380:2380 quay.io/coreos/etcd:v3.3.9 etcd --advertise-client-urls http://0.0.0.0:2379 --listen-client-urls http://0.0.0.0:2379</span><br><span class="line">ca444c094b6bf00b47726b0dee600620d3962cd0fb78d224db9fae12da94dc13</span><br></pre></td></tr></table></figure>

<p>容器停止总是重启</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ansible-server ~]# docker run -d -it --restart=always --name etcd1 -e ETCDCTL_API=3 -p 2379:2379 -p 2380:2380 quay.io/coreos/etcd:v3.3.9 etcd --advertise-client-urls http://0.0.0.0:2379 --listen-client-urls http://0.0.0.0:2379</span><br><span class="line">199b521dcdd1a742701350c8024dd76c179db2ded0d05a40dd44adfd14f2fb27</span><br></pre></td></tr></table></figure>

<p>其他状态：</p>
<ul>
<li>no，默认策略，在容器退出时不重启容器</li>
<li>on-failure，在容器非正常退出时（退出状态非0），才会重启容器</li>
<li>on-failure:3，在容器非正常退出时重启容器，最多重启3次</li>
<li>always，在容器退出时总是重启容器</li>
<li>unless-stopped，在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的容器</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@bogon etcd]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE                        COMMAND                  CREATED             STATUS              PORTS                              NAMES</span><br><span class="line">ca444c094b6b        quay.io/coreos/etcd:v3.3.9   &quot;etcd --advertise-...&quot;   4 seconds ago       Up 3 seconds        0.0.0.0:2379-2380-&gt;2379-2380/tcp   etcd_test</span><br></pre></td></tr></table></figure>

<h5 id="4、客户端测试"><a href="#4、客户端测试" class="headerlink" title="4、客户端测试"></a>4、客户端测试</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">etcdctl --endpoints=http://127.0.0.1:2379 put foo bar</span><br><span class="line"></span><br><span class="line">etcdctl --endpoints=http://127.0.0.1:2379 get foo</span><br><span class="line">[root@bogon etcd]# etcdctl --endpoints=http://127.0.0.1:2379 put foo bar</span><br><span class="line">OK</span><br><span class="line">[root@bogon etcd]# etcdctl --endpoints=http://127.0.0.1:2379 get foo</span><br><span class="line">foo</span><br><span class="line">bar</span><br><span class="line">[root@bogon etcd]# etcdctl --endpoints=http://127.0.0.1:2379 put foo bar1</span><br><span class="line">OK</span><br><span class="line">[root@bogon etcd]# etcdctl --endpoints=http://127.0.0.1:2379 get foo</span><br><span class="line">foo</span><br><span class="line">bar1</span><br></pre></td></tr></table></figure>

<h3 id="三、Etcd本地集群（使用goreman管理）"><a href="#三、Etcd本地集群（使用goreman管理）" class="headerlink" title="三、Etcd本地集群（使用goreman管理）"></a>三、Etcd本地集群（使用goreman管理）</h3><h4 id="1、下载etcd二进制包-amp-amp-设置环境变量-amp-amp-参考Etcd单机部署"><a href="#1、下载etcd二进制包-amp-amp-设置环境变量-amp-amp-参考Etcd单机部署" class="headerlink" title="1、下载etcd二进制包&amp;&amp;设置环境变量&amp;&amp;参考Etcd单机部署"></a>1、下载etcd二进制包&amp;&amp;设置环境变量&amp;&amp;参考Etcd单机部署</h4><h4 id="2、安装goreman，安装goreman前需要安装go环境和git。"><a href="#2、安装goreman，安装goreman前需要安装go环境和git。" class="headerlink" title="2、安装goreman，安装goreman前需要安装go环境和git。"></a>2、安装goreman，安装goreman前需要安装go环境和git。</h4><h4 id="3、安装go环境"><a href="#3、安装go环境" class="headerlink" title="3、安装go环境"></a>3、安装go环境</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://studygolang.com/dl/golang/go1.10.1.linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">tar -xvf go1.10.1.linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">export GOROOT=/home/go/go</span><br><span class="line">export GOPATH=/home/go/data</span><br><span class="line">export PATH=$PATH:$GOROOT/bin:$GOPATH/bin</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<h4 id="4、安装git"><a href="#4、安装git" class="headerlink" title="4、安装git"></a>4、安装git</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum -y install git</span><br></pre></td></tr></table></figure>

<h4 id="5、安装-goreman"><a href="#5、安装-goreman" class="headerlink" title="5、安装 goreman"></a>5、安装 goreman</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">go get github.com/mattn/goreman</span><br></pre></td></tr></table></figure>

<p>下载后的文件在<code>export GOPATH=/home/go/data</code>设置的路径中</p>
<h4 id="6、编写Procfile（管理集群）"><a href="#6、编写Procfile（管理集群）" class="headerlink" title="6、编写Procfile（管理集群）"></a>6、编写Procfile（管理集群）</h4><p><a href="https://github.com/coreos/etcd/blob/master/Procfile">https://github.com/coreos/etcd/blob/master/Procfile</a></p>
<h4 id="7、启动etcd（goreman-runlist）"><a href="#7、启动etcd（goreman-runlist）" class="headerlink" title="7、启动etcd（goreman runlist）"></a>7、启动etcd（goreman runlist）</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">goreman -f Procfile start</span><br></pre></td></tr></table></figure>

<h3 id="四、docker-cluster（集群）"><a href="#四、docker-cluster（集群）" class="headerlink" title="四、docker cluster（集群）"></a>四、docker cluster（集群）</h3><h4 id="8、etcd集群"><a href="#8、etcd集群" class="headerlink" title="8、etcd集群"></a>8、etcd集群</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker pull busybox</span><br></pre></td></tr></table></figure>

<h5 id="docker-netword"><a href="#docker-netword" class="headerlink" title="docker netword"></a>docker netword</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#docker network create etcd_cluster</span><br><span class="line"></span><br><span class="line">docker network create --subnet 172.16.3.0/16 etcd_cluster</span><br><span class="line"></span><br><span class="line">docker network inspect etcd_cluster</span><br><span class="line"></span><br><span class="line">#docker network rm etcd_cluster</span><br><span class="line"></span><br><span class="line">docker run -itd --rm --network etcd_cluster --ip 172.16.3.0 --name test busybox</span><br><span class="line">docker network ls</span><br><span class="line">docker network rm etcd_cluster</span><br></pre></td></tr></table></figure>

<h4 id="9、etcd-cluster"><a href="#9、etcd-cluster" class="headerlink" title="9、etcd cluster"></a>9、etcd cluster</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># etcd1</span><br><span class="line">docker run -itd --restart=always \</span><br><span class="line">    --network etcd_cluster \</span><br><span class="line">    --ip 172.16.3.31 \</span><br><span class="line">    --hostname etcd1 \</span><br><span class="line">    --name etcd1 \</span><br><span class="line">    -e ETCDCTL_API=3 \</span><br><span class="line">    -p 12379:2379 \</span><br><span class="line">    -p 12380:2380 \</span><br><span class="line">    quay.io/coreos/etcd:v3.3.9 \</span><br><span class="line">    etcd --name etcd1 \</span><br><span class="line">    --initial-advertise-peer-urls http://172.16.3.31:2380 \</span><br><span class="line">    --listen-peer-urls http://172.16.3.31:2380 \</span><br><span class="line">    --listen-client-urls http://172.16.3.31:2379,http://127.0.0.1:2379 \</span><br><span class="line">    --advertise-client-urls http://172.16.3.31:2379 \</span><br><span class="line">    --initial-cluster-token etcd-cluster-1 \</span><br><span class="line">    --initial-cluster etcd1=http://172.16.3.31:2380,etcd2=http://172.16.3.32:2380,etcd3=http://172.16.3.33:2380 \</span><br><span class="line">    --initial-cluster-state new</span><br><span class="line">    </span><br><span class="line">  # etcd2  </span><br><span class="line">    docker run -itd --restart=always \</span><br><span class="line">    --network etcd_cluster \</span><br><span class="line">    --ip 172.16.3.32 \</span><br><span class="line">    --hostname etcd2 \</span><br><span class="line">    --name etcd2 \</span><br><span class="line">    -e ETCDCTL_API=3 \</span><br><span class="line">    -p 22379:2379 \</span><br><span class="line">    -p 22380:2380 \</span><br><span class="line">    quay.io/coreos/etcd:v3.3.9 \</span><br><span class="line">    etcd --name etcd2 \</span><br><span class="line">    --initial-advertise-peer-urls http://172.16.3.32:2380 \</span><br><span class="line">    --listen-peer-urls http://172.16.3.32:2380 \</span><br><span class="line">    --listen-client-urls http://172.16.3.32:2379,http://127.0.0.1:2379 \</span><br><span class="line">    --advertise-client-urls http://172.16.3.32:2379 \</span><br><span class="line">    --initial-cluster-token etcd-cluster-1 \</span><br><span class="line">    --initial-cluster etcd1=http://172.16.3.31:2380,etcd2=http://172.16.3.32:2380,etcd3=http://172.16.3.33:2380 \</span><br><span class="line">    --initial-cluster-state new</span><br><span class="line">  </span><br><span class="line">  # etcd3</span><br><span class="line">    docker run -itd --restart=always \</span><br><span class="line">    --network etcd_cluster \</span><br><span class="line">    --ip 172.16.3.33 \</span><br><span class="line">    --hostname etcd3 \</span><br><span class="line">    --name etcd3 \</span><br><span class="line">    -e ETCDCTL_API=3 \</span><br><span class="line">    -p 32379:2379 \</span><br><span class="line">    -p 32380:2380 \</span><br><span class="line">    quay.io/coreos/etcd:v3.3.9 \</span><br><span class="line">    etcd --name etcd3 \</span><br><span class="line">    --initial-advertise-peer-urls http://172.16.3.33:2380 \</span><br><span class="line">    --listen-peer-urls http://172.16.3.33:2380 \</span><br><span class="line">    --listen-client-urls http://172.16.3.33:2379,http://127.0.0.1:2379 \</span><br><span class="line">    --advertise-client-urls http://172.16.3.33:2379 \</span><br><span class="line">    --initial-cluster-token etcd-cluster-1 \</span><br><span class="line">    --initial-cluster etcd1=http://172.16.3.31:2380,etcd2=http://172.16.3.32:2380,etcd3=http://172.16.3.33:2380 \</span><br><span class="line">    --initial-cluster-state new</span><br><span class="line">    </span><br><span class="line"> # client</span><br><span class="line"> #进入容器 </span><br><span class="line">docker exec -it etcd1 bin/sh</span><br><span class="line">#客户端测试</span><br><span class="line">etcdctl --write-out=table --endpoints=http://127.0.0.1:2379 member list</span><br><span class="line">etcdctl --endpoints=http://127.0.0.1:2379 put foo bar</span><br><span class="line">etcdctl --endpoints=http://127.0.0.1:2379 get foo</span><br><span class="line"></span><br><span class="line">#测试结果如下</span><br><span class="line">[root@bogon ~]# docker exec -it etcd1 bin/sh</span><br><span class="line">/ # etcdctl --write-out=table --endpoints=http://127.0.0.1:2379 member list</span><br><span class="line">+------------------+---------+-------+-------------------------+-------------------------+</span><br><span class="line">|        ID        | STATUS  | NAME  |       PEER ADDRS        |      CLIENT ADDRS       |</span><br><span class="line">+------------------+---------+-------+-------------------------+-------------------------+</span><br><span class="line">|  c26d6ba798c079c | started | etcd3 | http://172.16.3.33:2380 | http://172.16.3.33:2379 |</span><br><span class="line">| 4631df2115e1ef72 | started | etcd2 | http://172.16.3.32:2380 | http://172.16.3.32:2379 |</span><br><span class="line">| a92fe5422902bc40 | started | etcd1 | http://172.16.3.31:2380 | http://172.16.3.31:2379 |</span><br><span class="line">+------------------+---------+-------+-------------------------+-------------------------+</span><br><span class="line">/ # etcdctl --endpoints=http://127.0.0.1:2379 put foo bar</span><br><span class="line">OK</span><br><span class="line">/ # etcdctl --endpoints=http://127.0.0.1:2379 get foo</span><br><span class="line">foo</span><br><span class="line">bar</span><br><span class="line">#docker ps</span><br><span class="line">[root@bogon docker]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE                        COMMAND                  CREATED             STATUS              PORTS                                              NAMES</span><br><span class="line">5988c4443eb5        quay.io/coreos/etcd:v3.3.9   &quot;etcd --name etcd3...&quot;   37 seconds ago      Up 36 seconds       0.0.0.0:32379-&gt;2379/tcp, 0.0.0.0:32380-&gt;2380/tcp   etcd3</span><br><span class="line">d4fdda6400cc        quay.io/coreos/etcd:v3.3.9   &quot;etcd --name etcd2...&quot;   44 seconds ago      Up 44 seconds       0.0.0.0:22379-&gt;2379/tcp, 0.0.0.0:22380-&gt;2380/tcp   etcd2</span><br><span class="line">af86e5fd2ae5        quay.io/coreos/etcd:v3.3.9   &quot;etcd --name etcd1...&quot;   53 seconds ago      Up 52 seconds       0.0.0.0:2379-2380-&gt;2379-2380/tcp                   etcd1</span><br></pre></td></tr></table></figure>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li>  <a href="http://www.dockerinfo.net/document">Docker中文文档</a></li>
<li>  <a href="https://docs.docker.com/">Docker官方文档</a></li>
<li>  <a href="https://www.runoob.com/docker/docker-tutorial.html">菜鸟教程</a></li>
</ul>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
</search>
